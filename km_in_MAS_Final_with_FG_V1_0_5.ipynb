{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tdopsmang/Colab-projects/blob/main/km_in_MAS_Final_with_FG_V1_0_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did not work on RR path, rather added bus details upto DP, in consolidated report, also batch processing done in few cases"
      ],
      "metadata": {
        "id": "JVbZ291M-7mv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMKeh0lHx8tS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74f73eb-dd13-48a1-9072-723572efd806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.32.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2025.4.26)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (4.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.6.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (1.17.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.9.1->oauth2client) (3.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (4.1.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gspread\n",
        "!pip install gspread google-auth-oauthlib google-auth-httplib2\n",
        "!pip install gspread google-auth oauth2client\n",
        "!pip install gspread oauth2client pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIVCOLMf4oFc"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "from google.oauth2.service_account import Credentials\n",
        "gc = gspread.authorize(creds)\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX9vEbLhRZAG"
      },
      "outputs": [],
      "source": [
        "# Details our Database spreadsheet which has details of all files, ID in Transport Department\n",
        "\n",
        "Database_File_spreadsheet_ID = gc.open_by_key('1nJKyvV1WQmZzvbjOP7Hsp1bQJmiNsYoJOH_jIL7H9PI') #ID of Database Spreadsheet\n",
        "MASsheetID = Database_File_spreadsheet_ID.worksheet('MAS')                                    #MAS Worksheet\n",
        "OdometersheetID = Database_File_spreadsheet_ID.worksheet('Odometer')                          #Odometer Worksheet\n",
        "\n",
        "#STS RR SVP\n",
        "RR_Oil_Lub_Coolant_DEF_spreadsheet_id = MASsheetID.acell('C2').value                  # Get the spreadsheet ID from cell C2\n",
        "RR_Oil_Lub = gc.open_by_key(RR_Oil_Lub_Coolant_DEF_spreadsheet_id)                    # Open RR_Oil_Lub spreadsheet\n",
        "\n",
        "RR_Engine_oil_CH_BSIV_worksheet_name = MASsheetID.acell('B2').value                        # Get the worksheet name from cell B2\n",
        "engine_oil_CH_BSIV_CH_MAS_rr = RR_Oil_Lub.worksheet(RR_Engine_oil_CH_BSIV_worksheet_name)  # Open RR CH engineoil worksheet\n",
        "\n",
        "RR_Engine_oil_CK_BSVI_worksheet_name = MASsheetID.acell('B3').value                        # Get the worksheet name from cell B3\n",
        "engine_oil_CK_BSVI_CK_MAS_rr = RR_Oil_Lub.worksheet(RR_Engine_oil_CK_BSVI_worksheet_name)  # Open RR CK engineoil worksheet\n",
        "\n",
        "RR_Report1_worksheet_name = MASsheetID.acell('B8').value                                # Get the worksheet name from report1, RR Km between and after last servicing\n",
        "RR_Report1_Worksheet = RR_Oil_Lub.worksheet(RR_Report1_worksheet_name)                  # Open RR Km between and after last servicing worksheet\n",
        "\n",
        "#STS ATR SVP\n",
        "ATR_Oil_Lub_Coolant_DEF_spreadsheet_id = MASsheetID.acell('C52').value                  # Get the spreadsheet ID from cell C51 ATR\n",
        "ATR_Oil_Lub = gc.open_by_key(ATR_Oil_Lub_Coolant_DEF_spreadsheet_id)                    # Open ATR_Oil_Lub spreadsheet\n",
        "\n",
        "ATR_Engine_oil_CH_BSIV_worksheet_name = MASsheetID.acell('B52').value                         # Get the worksheet name from cell B52\n",
        "engine_oil_CH_BSIV_CH_MAS_ATR = ATR_Oil_Lub.worksheet(ATR_Engine_oil_CH_BSIV_worksheet_name)  # Open ATR CH engineoil worksheet\n",
        "\n",
        "ATR_Engine_oil_CK_BSVI_worksheet_name = MASsheetID.acell('B53').value                         # Get the worksheet name from cell B52\n",
        "engine_oil_CK_BSVI_CK_MAS_ATR = ATR_Oil_Lub.worksheet(ATR_Engine_oil_CK_BSVI_worksheet_name)  # Open ATR CK engineoil worksheet\n",
        "\n",
        "#ATR_Report1_worksheet_name = MASsheetID.acell('B58').value                           #******This may not be required       # Get the worksheet name from report1, RR Km between and after last servicing\n",
        "#ATR_Report1_Worksheet = ATR_Oil_Lub.worksheet(ATR_Report1_worksheet_name)              #This may not be required     # Open RR Km between and after last servicing worksheet\n",
        "\n",
        "#STS FG\n",
        "FG_Oil_Lub_Coolant_DEF_spreadsheet_id = MASsheetID.acell('C102').value                  # Get the spreadsheet ID from cell C51 ATR\n",
        "FG_Oil_Lub = gc.open_by_key(FG_Oil_Lub_Coolant_DEF_spreadsheet_id)                    # Open ATR_Oil_Lub spreadsheet\n",
        "\n",
        "FG_Engine_oil_CH_BSIV_worksheet_name = MASsheetID.acell('B102').value                         # Get the worksheet name from cell B2\n",
        "engine_oil_CH_BSIV_CH_MAS_FG = FG_Oil_Lub.worksheet(FG_Engine_oil_CH_BSIV_worksheet_name)  # Open RR engineoil worksheet\n",
        "\n",
        "#FG_Report1_worksheet_name = MASsheetID.acell('B108').value                    #*****This may not be required            # Get the worksheet name from report1, RR Km between and after last servicing\n",
        "#FG_Report1_Worksheet = FG_Oil_Lub.worksheet(FG_Report1_worksheet_name)          #This may not be required         # Open RR Km between and after last servicing worksheet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear data in range A5:A200\n",
        "clear_range_all_OdometersheetID = 'A5:R200'\n",
        "clear_range_all_RR_Report1_Worksheet = ['B2:B200', 'AC2:AC200']\n",
        "\n",
        "OdometersheetID.batch_clear([clear_range_all_OdometersheetID])\n",
        "RR_Report1_Worksheet.batch_clear(clear_range_all_RR_Report1_Worksheet)\n",
        "\n",
        "# === PROCESS BUS DATA ===\n",
        "\n",
        "# Process SVP data\n",
        "SVP_Odometer_id = OdometersheetID.acell('A2').value\n",
        "Odometer_spreadsheet_SVP = gc.open_by_key(SVP_Odometer_id)\n",
        "bus_number_SVP = sorted([worksheet.title for worksheet in Odometer_spreadsheet_SVP])\n",
        "spreadsheet_name_SVP = Odometer_spreadsheet_SVP.title\n",
        "start_row_svp = 2\n",
        "\n",
        "# Process FG data\n",
        "FG_Odometer_id = OdometersheetID.acell('B2').value\n",
        "Odometer_spreadsheet_FG = gc.open_by_key(FG_Odometer_id)\n",
        "bus_number_FG = sorted([worksheet.title for worksheet in Odometer_spreadsheet_FG])\n",
        "spreadsheet_name_FG = Odometer_spreadsheet_FG.title\n",
        "start_row_fg = start_row_svp + len(bus_number_SVP)\n",
        "\n",
        "# Process Baratang data\n",
        "BT_Odometer_id = OdometersheetID.acell('C2').value\n",
        "Odometer_spreadsheet_BT = gc.open_by_key(BT_Odometer_id)\n",
        "bus_number_BT = sorted([worksheet.title for worksheet in Odometer_spreadsheet_BT])\n",
        "spreadsheet_name_BT = Odometer_spreadsheet_BT.title\n",
        "start_row_bt = start_row_fg + len(bus_number_FG)\n",
        "\n",
        "# Process Rangat data\n",
        "RT_Odometer_id = OdometersheetID.acell('D2').value\n",
        "Odometer_spreadsheet_RT = gc.open_by_key(RT_Odometer_id)\n",
        "bus_number_RT = sorted([worksheet.title for worksheet in Odometer_spreadsheet_RT])\n",
        "spreadsheet_name_RT = Odometer_spreadsheet_RT.title\n",
        "start_row_rt = start_row_bt + len(bus_number_BT)\n",
        "\n",
        "# Process Mayabunder data\n",
        "MB_Odometer_id = OdometersheetID.acell('E2').value\n",
        "Odometer_spreadsheet_MB = gc.open_by_key(MB_Odometer_id)\n",
        "bus_number_MB = sorted([worksheet.title for worksheet in Odometer_spreadsheet_MB])\n",
        "spreadsheet_name_MB = Odometer_spreadsheet_MB.title\n",
        "start_row_mb = start_row_rt + len(bus_number_RT)\n",
        "\n",
        "# Process Diglipur data\n",
        "DP_Odometer_id = OdometersheetID.acell('F2').value\n",
        "Odometer_spreadsheet_DP = gc.open_by_key(DP_Odometer_id)\n",
        "bus_number_DP = sorted([worksheet.title for worksheet in Odometer_spreadsheet_DP])\n",
        "spreadsheet_name_DP = Odometer_spreadsheet_DP.title\n",
        "start_row_dp = start_row_mb + len(bus_number_MB)\n",
        "\n",
        "# === UPDATE ODOMETERSHEERTID WITH BUS NUMBERS ===\n",
        "\n",
        "# Function to update OdometersheetID column with bus numbers - one by one to avoid quote issues\n",
        "def update_column_values(worksheet, column_letter, start_row, values_list):\n",
        "    for i, value in enumerate(values_list):\n",
        "        row = start_row + i\n",
        "        cell = f\"{column_letter}{row}\"\n",
        "        worksheet.update_acell(cell, value)\n",
        "\n",
        "    print(f\"Updated {len(values_list)} values in column {column_letter}\")\n",
        "\n",
        "# Function for batch update with string pre-processing to avoid quotes\n",
        "def batch_update_with_preprocessing(worksheet, column_letter, start_row, values_list):\n",
        "    # Create a list of dictionaries for batch update\n",
        "    requests = []\n",
        "    for i, value in enumerate(values_list):\n",
        "        row = start_row + i\n",
        "        # If value is numeric string, try to convert to number\n",
        "        try:\n",
        "            if value.isdigit():\n",
        "                value = int(value)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        requests.append({\n",
        "            'range': f'{column_letter}{row}',\n",
        "            'values': [[value]]\n",
        "        })\n",
        "\n",
        "    if requests:\n",
        "        worksheet.batch_update(requests)\n",
        "        print(f\"Batch updated {len(values_list)} values in column {column_letter}\")\n",
        "\n",
        "# Update spreadsheet names in row 4\n",
        "OdometersheetID.update_acell('A4', spreadsheet_name_SVP)\n",
        "OdometersheetID.update_acell('B4', spreadsheet_name_FG)\n",
        "OdometersheetID.update_acell('C4', spreadsheet_name_BT)\n",
        "OdometersheetID.update_acell('D4', spreadsheet_name_RT)\n",
        "OdometersheetID.update_acell('E4', spreadsheet_name_MB)\n",
        "OdometersheetID.update_acell('F4', spreadsheet_name_DP)\n",
        "print(\"Updated all spreadsheet names in row 4\")\n",
        "\n",
        "# Use either individual updates or batch updates with preprocessing\n",
        "USE_BATCH = True  # Set to False if you want individual cell updates\n",
        "\n",
        "if USE_BATCH:\n",
        "    # Update OdometersheetID columns in batches\n",
        "    batch_update_with_preprocessing(OdometersheetID, 'A', 5, bus_number_SVP)\n",
        "    batch_update_with_preprocessing(OdometersheetID, 'B', 5, bus_number_FG)\n",
        "    batch_update_with_preprocessing(OdometersheetID, 'C', 5, bus_number_BT)\n",
        "    batch_update_with_preprocessing(OdometersheetID, 'D', 5, bus_number_RT)\n",
        "    batch_update_with_preprocessing(OdometersheetID, 'E', 5, bus_number_MB)\n",
        "    batch_update_with_preprocessing(OdometersheetID, 'F', 5, bus_number_DP)\n",
        "else:\n",
        "    # Update OdometersheetID columns one by one\n",
        "    update_column_values(OdometersheetID, 'A', 5, bus_number_SVP)\n",
        "    update_column_values(OdometersheetID, 'B', 5, bus_number_FG)\n",
        "    update_column_values(OdometersheetID, 'C', 5, bus_number_BT)\n",
        "    update_column_values(OdometersheetID, 'D', 5, bus_number_RT)\n",
        "    update_column_values(OdometersheetID, 'E', 5, bus_number_MB)\n",
        "    update_column_values(OdometersheetID, 'F', 5, bus_number_DP)\n",
        "\n",
        "# === UPDATE REPORT1 WORKSHEET WITH ALL BUS NUMBERS ===\n",
        "\n",
        "# Combine all bus lists for Report1\n",
        "all_buses_with_sources = []\n",
        "for bus, source in zip(bus_number_SVP, [spreadsheet_name_SVP] * len(bus_number_SVP)):\n",
        "    all_buses_with_sources.append((bus, source))\n",
        "for bus, source in zip(bus_number_FG, [spreadsheet_name_FG] * len(bus_number_FG)):\n",
        "    all_buses_with_sources.append((bus, source))\n",
        "for bus, source in zip(bus_number_BT, [spreadsheet_name_BT] * len(bus_number_BT)):\n",
        "    all_buses_with_sources.append((bus, source))\n",
        "for bus, source in zip(bus_number_RT, [spreadsheet_name_RT] * len(bus_number_RT)):\n",
        "    all_buses_with_sources.append((bus, source))\n",
        "for bus, source in zip(bus_number_MB, [spreadsheet_name_MB] * len(bus_number_MB)):\n",
        "    all_buses_with_sources.append((bus, source))\n",
        "for bus, source in zip(bus_number_DP, [spreadsheet_name_DP] * len(bus_number_DP)):\n",
        "    all_buses_with_sources.append((bus, source))\n",
        "\n",
        "# Update Report1 with all bus data\n",
        "if USE_BATCH:\n",
        "    # Create batch update requests\n",
        "    requests = []\n",
        "    for i, (bus, source) in enumerate(all_buses_with_sources):\n",
        "        row = i + 2  # Start from row 2\n",
        "        # Try to convert numeric strings to integers\n",
        "        try:\n",
        "            if isinstance(bus, str) and bus.isdigit():\n",
        "                bus = int(bus)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        requests.append({\n",
        "            'range': f'B{row}',\n",
        "            'values': [[bus]]\n",
        "        })\n",
        "        requests.append({\n",
        "            'range': f'AC{row}',\n",
        "            'values': [[source]]\n",
        "        })\n",
        "\n",
        "    if requests:\n",
        "        RR_Report1_Worksheet.batch_update(requests)\n",
        "        print(f\"Batch updated {len(all_buses_with_sources)} bus entries in Report1 worksheet\")\n",
        "else:\n",
        "    # Update one by one\n",
        "    for i, (bus, source) in enumerate(all_buses_with_sources):\n",
        "        row = i + 2  # Start from row 2\n",
        "        RR_Report1_Worksheet.update_cell(row, 2, bus)  # Column B\n",
        "        RR_Report1_Worksheet.update_cell(row, 29, source)  # Column AC\n",
        "\n",
        "    print(f\"Updated {len(all_buses_with_sources)} bus entries in Report1 worksheet\")\n",
        "\n",
        "print(\"All operations completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPYzQZdOPQOE",
        "outputId": "0191846b-d4db-4034-ad39-23a4269eac5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated all spreadsheet names in row 4\n",
            "Batch updated 58 values in column A\n",
            "Batch updated 35 values in column B\n",
            "Batch updated 1 values in column C\n",
            "Batch updated 1 values in column D\n",
            "Batch updated 1 values in column E\n",
            "Batch updated 1 values in column F\n",
            "Batch updated 97 bus entries in Report1 worksheet\n",
            "All operations completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "donb8KLRgWKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9057da24-275d-42f2-aaef-ffb64f9a1cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Progress: Updated 710/727 values\n",
            "📊 Progress: Updated 720/727 values\n",
            "📊 Progress: Updated 730/727 values\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE: Updated 735 rows in column L and column M\n",
            "📊 Summary: 504 exact matches (normal format), 223 fallback matches (italic and right-aligned)\n",
            "❌ 168 rows could not be updated\n"
          ]
        }
      ],
      "source": [
        "# With fallback date display in M Column, For RR_MAS_Engine OIl_ Best Code\n",
        "\n",
        "# Make sure to include these imports at the top of your code\n",
        "import re\n",
        "from datetime import datetime\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import gspread\n",
        "\n",
        "\n",
        "# Clear data in range L2:M, Odometer value in Engine Oil and Fallback date removal\n",
        "clear_range_all_engine_oil_CH_BSIV_CH_MAS_rr = 'L2:M'\n",
        "engine_oil_CH_BSIV_CH_MAS_rr.batch_clear([clear_range_all_engine_oil_CH_BSIV_CH_MAS_rr])\n",
        "\n",
        "\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "print(\"🔍 Starting data processing with date fallback search...\")\n",
        "\n",
        "# 📥 Load main sheet\n",
        "print(\"📥 Loading main sheet data...\")\n",
        "main_data = engine_oil_CH_BSIV_CH_MAS_rr.get_all_values()\n",
        "print(f\"✅ Loaded {len(main_data)-1} rows from main sheet\")\n",
        "\n",
        "# Step 1: Collect unique (bus, date) and row mapping\n",
        "print(\"🔢 Mapping bus numbers and dates...\")\n",
        "bus_date_map = defaultdict(set)\n",
        "row_map = {}  # maps row number → (bus, date)\n",
        "\n",
        "for i, row in enumerate(main_data[1:], start=2):\n",
        "    try:\n",
        "        date_str = row[1].strip()\n",
        "        bus_num = row[4].strip()\n",
        "        if date_str and bus_num:\n",
        "            bus_date_map[bus_num].add(date_str)\n",
        "            row_map[i] = (bus_num, date_str)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"✅ Found {len(bus_date_map)} unique bus numbers\")\n",
        "print(f\"✅ Found {len(row_map)} rows to process\")\n",
        "\n",
        "# Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "print(\"\\n🔍 Searching for exact dates or closest earlier dates...\")\n",
        "bus_date_value_map = {}\n",
        "match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "fallback_date_map = {}  # Store the actual fallback date used\n",
        "success_count = 0\n",
        "fallback_count = 0\n",
        "\n",
        "for bus, dates in bus_date_map.items():\n",
        "    print(f\"📊 Processing bus {bus} ({len(dates)} dates)...\")\n",
        "    try:\n",
        "        sheet = Odometer_spreadsheet_SVP.worksheet(bus)\n",
        "        sheet_data = sheet.get_all_values()\n",
        "        sheet_success = 0\n",
        "\n",
        "        for date_str in dates:\n",
        "            # Find exact match first\n",
        "            exact_value = None\n",
        "            for row in sheet_data[1:]:\n",
        "                try:\n",
        "                    if len(row) > 12 and row[1].strip() == date_str:\n",
        "                        exact_value = row[12]  # Column M\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if exact_value:\n",
        "                bus_date_value_map[(bus, date_str)] = exact_value\n",
        "                match_type_map[(bus, date_str)] = \"exact\"\n",
        "                fallback_date_map[(bus, date_str)] = \"\"  # No fallback date for exact matches\n",
        "                sheet_success += 1\n",
        "                success_count += 1\n",
        "            else:\n",
        "                # Try to find closest earlier date\n",
        "                value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                if value:\n",
        "                    bus_date_value_map[(bus, date_str)] = value\n",
        "                    match_type_map[(bus, date_str)] = \"fallback\"\n",
        "                    fallback_date_map[(bus, date_str)] = fallback_date  # Store the fallback date used\n",
        "                    sheet_success += 1\n",
        "                    fallback_count += 1\n",
        "\n",
        "        print(f\"  ✅ Found {sheet_success}/{len(dates)} values for bus {bus}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Could not process sheet '{bus}': {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n✅ Found values for {success_count} exact date matches\")\n",
        "print(f\"✅ Found values for {fallback_count} fallback date matches\")\n",
        "print(f\"❌ Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "# Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "print(\"\\n📝 Updating values and formatting in main sheet...\")\n",
        "updated_count = 0\n",
        "\n",
        "# Get the worksheet object for batch updates\n",
        "worksheet = engine_oil_CH_BSIV_CH_MAS_rr\n",
        "\n",
        "# Prepare batch formatting requests for different match types\n",
        "exact_match_cells = []\n",
        "fallback_match_cells = []\n",
        "\n",
        "for row_num, (bus, date_str) in row_map.items():\n",
        "    value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "    fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "\n",
        "    if value:\n",
        "        max_retries = 5\n",
        "        retry_count = 0\n",
        "        update_successful = False\n",
        "\n",
        "        while not update_successful and retry_count < max_retries:\n",
        "            try:\n",
        "                # Update cell value in column L (value)\n",
        "                worksheet.update_cell(row_num, 12, value)  # Column L = col 12\n",
        "\n",
        "                # Update column M with fallback date if applicable\n",
        "                worksheet.update_cell(row_num, 13, fallback_date)  # Column M = col 13\n",
        "\n",
        "                # Track which cells need which formatting\n",
        "                match_type = match_type_map.get((bus, date_str))\n",
        "                if match_type == \"exact\":\n",
        "                    # For exact matches - normal formatting\n",
        "                    exact_match_cells.append(f\"L{row_num}\")\n",
        "                elif match_type == \"fallback\":\n",
        "                    # For fallback matches - italic and right-aligned\n",
        "                    fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "                update_successful = True\n",
        "                updated_count += 1\n",
        "                if updated_count % 10 == 0:  # Progress update every 10 rows\n",
        "                    print(f\"📊 Progress: Updated {updated_count}/{len(bus_date_value_map)} values\")\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                if \"429\" in str(e):\n",
        "                    # Calculate wait time with exponential backoff\n",
        "                    wait_time = (2 ** retry_count) + random.random()\n",
        "                    print(f\"⏳ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"❌ Failed to update row {row_num}: {e}\")\n",
        "                    break\n",
        "\n",
        "        if not update_successful:\n",
        "            print(f\"❌ Failed to update row {row_num} after {max_retries} retries\")\n",
        "\n",
        "# Apply formatting in batches to avoid rate limiting\n",
        "print(\"\\n🎨 Applying formatting to distinguish match types...\")\n",
        "\n",
        "print(f\"\\n✅ COMPLETE: Updated {updated_count} rows in column L and column M\")\n",
        "print(f\"📊 Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "print(f\"❌ {len(row_map) - updated_count} rows could not be updated\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# With fallback date display in M Column, For ATR_MAS_Engine OIl_ Best Code\n",
        "\n",
        "# With fallback date display in M Column, Best Code\n",
        "\n",
        "# Make sure to include these imports at the top of your code\n",
        "import re\n",
        "from datetime import datetime\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import gspread\n",
        "\n",
        "\n",
        "# Clear data in range L2:M, Odometer value in Engine Oil and Fallback date removal\n",
        "clear_range_all_engine_oil_CH_BSIV_CH_MAS_atr = 'L2:M'\n",
        "engine_oil_CH_BSIV_CH_MAS_ATR.batch_clear([clear_range_all_engine_oil_CH_BSIV_CH_MAS_atr])\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "print(\"🔍 Starting data processing with date fallback search...\")\n",
        "\n",
        "# 📥 Load main sheet\n",
        "print(\"📥 Loading main sheet data...\")\n",
        "main_data = engine_oil_CH_BSIV_CH_MAS_ATR.get_all_values()\n",
        "print(f\"✅ Loaded {len(main_data)-1} rows from main sheet\")\n",
        "\n",
        "# Step 1: Collect unique (bus, date) and row mapping\n",
        "print(\"🔢 Mapping bus numbers and dates...\")\n",
        "bus_date_map = defaultdict(set)\n",
        "row_map = {}  # maps row number → (bus, date)\n",
        "\n",
        "for i, row in enumerate(main_data[1:], start=2):\n",
        "    try:\n",
        "        date_str = row[1].strip()\n",
        "        bus_num = row[4].strip()\n",
        "        if date_str and bus_num:\n",
        "            bus_date_map[bus_num].add(date_str)\n",
        "            row_map[i] = (bus_num, date_str)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"✅ Found {len(bus_date_map)} unique bus numbers\")\n",
        "print(f\"✅ Found {len(row_map)} rows to process\")\n",
        "\n",
        "# Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "print(\"\\n🔍 Searching for exact dates or closest earlier dates...\")\n",
        "bus_date_value_map = {}\n",
        "match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "fallback_date_map = {}  # Store the actual fallback date used\n",
        "success_count = 0\n",
        "fallback_count = 0\n",
        "\n",
        "for bus, dates in bus_date_map.items():\n",
        "    print(f\"📊 Processing bus {bus} ({len(dates)} dates)...\")\n",
        "    try:\n",
        "        sheet = Odometer_spreadsheet_SVP.worksheet(bus)\n",
        "        sheet_data = sheet.get_all_values()\n",
        "        sheet_success = 0\n",
        "\n",
        "        for date_str in dates:\n",
        "            # Find exact match first\n",
        "            exact_value = None\n",
        "            for row in sheet_data[1:]:\n",
        "                try:\n",
        "                    if len(row) > 12 and row[1].strip() == date_str:\n",
        "                        exact_value = row[12]  # Column M\n",
        "                        break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if exact_value:\n",
        "                bus_date_value_map[(bus, date_str)] = exact_value\n",
        "                match_type_map[(bus, date_str)] = \"exact\"\n",
        "                fallback_date_map[(bus, date_str)] = \"\"  # No fallback date for exact matches\n",
        "                sheet_success += 1\n",
        "                success_count += 1\n",
        "            else:\n",
        "                # Try to find closest earlier date\n",
        "                value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                if value:\n",
        "                    bus_date_value_map[(bus, date_str)] = value\n",
        "                    match_type_map[(bus, date_str)] = \"fallback\"\n",
        "                    fallback_date_map[(bus, date_str)] = fallback_date  # Store the fallback date used\n",
        "                    sheet_success += 1\n",
        "                    fallback_count += 1\n",
        "\n",
        "        print(f\"  ✅ Found {sheet_success}/{len(dates)} values for bus {bus}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Could not process sheet '{bus}': {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\n✅ Found values for {success_count} exact date matches\")\n",
        "print(f\"✅ Found values for {fallback_count} fallback date matches\")\n",
        "print(f\"❌ Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "# Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "print(\"\\n📝 Updating values and formatting in main sheet...\")\n",
        "updated_count = 0\n",
        "\n",
        "# Get the worksheet object for batch updates\n",
        "worksheet = engine_oil_CH_BSIV_CH_MAS_ATR\n",
        "\n",
        "# Prepare batch formatting requests for different match types\n",
        "exact_match_cells = []\n",
        "fallback_match_cells = []\n",
        "\n",
        "for row_num, (bus, date_str) in row_map.items():\n",
        "    value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "    fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "\n",
        "    if value:\n",
        "        max_retries = 5\n",
        "        retry_count = 0\n",
        "        update_successful = False\n",
        "\n",
        "        while not update_successful and retry_count < max_retries:\n",
        "            try:\n",
        "                # Update cell value in column L (value)\n",
        "                worksheet.update_cell(row_num, 12, value)  # Column L = col 12\n",
        "\n",
        "                # Update column M with fallback date if applicable\n",
        "                worksheet.update_cell(row_num, 13, fallback_date)  # Column M = col 13\n",
        "\n",
        "                # Track which cells need which formatting\n",
        "                match_type = match_type_map.get((bus, date_str))\n",
        "                if match_type == \"exact\":\n",
        "                    exact_match_cells.append(f\"L{row_num}\")\n",
        "                elif match_type == \"fallback\":\n",
        "                    fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "                update_successful = True\n",
        "                updated_count += 1\n",
        "                if updated_count % 10 == 0:\n",
        "                    print(f\"📊 Progress: Updated {updated_count}/{len(bus_date_value_map)} values\")\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                if \"429\" in str(e):\n",
        "                    wait_time = (2 ** retry_count) + random.random()\n",
        "                    print(f\"⏳ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"❌ Failed to update row {row_num}: {e}\")\n",
        "                    break\n",
        "\n",
        "        if not update_successful:\n",
        "            print(f\"❌ Failed to update row {row_num} after {max_retries} retries\")\n",
        "\n",
        "# Apply formatting in batches (currently commented out)\n",
        "print(\"\\n🎨 Applying formatting to distinguish match types...\")\n",
        "# You can uncomment and implement batch formatting logic if needed.\n",
        "\n",
        "print(f\"\\n✅ COMPLETE: Updated {updated_count} rows in column L and column M\")\n",
        "print(f\"📊 Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "print(f\"❌ {len(row_map) - updated_count} rows could not be updated\")\n"
      ],
      "metadata": {
        "id": "WgcwRz-J2agi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deepseek Revision ongoing in CODE #112 KM in Column D in Report1 Sheet, here it is searching all Odometer, i.e. from Odometer_spreadsheet_SVP or Odometer_spreadsheet_FG or Odometer_spreadsheet_BT or Odometer_spreadsheet_RT or Odometer_spreadsheet_MB or Odometer_spreadsheet_DP\n",
        "# Working fine\n",
        "\n",
        "from datetime import datetime\n",
        "import re\n",
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "# CONFIGURATION\n",
        "odometer_spreadsheets = [Odometer_spreadsheet_SVP, Odometer_spreadsheet_FG, Odometer_spreadsheet_BT,\n",
        "                         Odometer_spreadsheet_RT, Odometer_spreadsheet_MB, Odometer_spreadsheet_DP]\n",
        "spreadsheet_names = [\"SVP\", \"FG\", \"BT\", \"RT\", \"MB\", \"DP\"]\n",
        "\n",
        "# Clear columns C and D\n",
        "RR_Report1_Worksheet.batch_clear([\"C2:D\"])\n",
        "\n",
        "# Get current date in expected format (e.g., \"05,May25\")\n",
        "current_date_str = datetime.now().strftime('%d,%b%y')\n",
        "\n",
        "# Get main data from Report1\n",
        "main_data = RR_Report1_Worksheet.get_all_values()\n",
        "header, rows = main_data[0], main_data[1:]\n",
        "\n",
        "# Map each row to bus + date (using today's date)\n",
        "row_map = {}\n",
        "bus_set = set()\n",
        "for i, row in enumerate(rows, start=2):\n",
        "    try:\n",
        "        bus = re.sub(r'[^a-zA-Z0-9]', '', row[1].strip()).upper()  # Clean bus name\n",
        "        if bus:\n",
        "            row_map[i] = (bus, current_date_str)\n",
        "            bus_set.add(bus)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error processing row {i}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"🔎 Total buses to process: {len(bus_set)}\")\n",
        "print(\"Sample buses:\", list(bus_set)[:5])  # Log first 5 buses\n",
        "\n",
        "# Initialize lookup maps\n",
        "bus_date_value_map = {}\n",
        "match_type_map = {}\n",
        "fallback_date_map = {}\n",
        "source_spreadsheet_map = {}\n",
        "\n",
        "# Function to find closest earlier date value\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    try:\n",
        "        target_date = datetime.strptime(target_date_str, '%d,%b%y')\n",
        "        valid_rows = []\n",
        "        for row_idx, row in enumerate(sheet_data[1:], start=2):\n",
        "            if len(row) <= value_column_index:\n",
        "                continue\n",
        "            date_cell = row[1].strip()\n",
        "            if not date_cell:\n",
        "                continue\n",
        "            # Try multiple date formats\n",
        "            try:\n",
        "                row_date = datetime.strptime(date_cell, '%d,%b%y')\n",
        "            except:\n",
        "                try:\n",
        "                    row_date = datetime.strptime(date_cell, '%d-%b-%y')\n",
        "                except:\n",
        "                    continue\n",
        "            if row_date <= target_date and row[value_column_index].strip():\n",
        "                valid_rows.append((row_date, date_cell, row[value_column_index].strip()))\n",
        "        if valid_rows:\n",
        "            valid_rows.sort(reverse=True)  # Newest date first\n",
        "            best = valid_rows[0]\n",
        "            return best[2], best[1]  # value, fallback_date\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error in fallback for {target_date_str}: {e}\")\n",
        "    return None, \"\"\n",
        "\n",
        "# Search logic with enhanced logging\n",
        "for bus in bus_set:\n",
        "    found = False\n",
        "    for idx, spreadsheet in enumerate(odometer_spreadsheets):\n",
        "        try:\n",
        "            time.sleep(1)  # Avoid API throttling\n",
        "            sheet = spreadsheet.worksheet(bus)\n",
        "            data = sheet.get_all_values()\n",
        "            print(f\"\\n✅ Found bus {bus} in {spreadsheet_names[idx]}\")\n",
        "            found = True\n",
        "            # Check for exact date match\n",
        "            exact_match = False\n",
        "            for row in data[1:]:\n",
        "                if len(row) > 12 and row[1].strip() == current_date_str and row[12].strip():\n",
        "                    odometer_val = row[12].strip()\n",
        "                    if odometer_val.isdigit():  # Validate numeric\n",
        "                        bus_date_value_map[(bus, current_date_str)] = odometer_val\n",
        "                        match_type_map[(bus, current_date_str)] = \"exact\"\n",
        "                        fallback_date_map[(bus, current_date_str)] = \"\"\n",
        "                        source_spreadsheet_map[(bus, current_date_str)] = spreadsheet_names[idx]\n",
        "                        exact_match = True\n",
        "                        print(f\"📌 Exact match: {odometer_val} km on {current_date_str}\")\n",
        "                        break\n",
        "            if not exact_match:\n",
        "                # Fallback to closest date\n",
        "                val, fallback_date = find_closest_date_value(data, current_date_str, 12)\n",
        "                if val:\n",
        "                    bus_date_value_map[(bus, current_date_str)] = val\n",
        "                    match_type_map[(bus, current_date_str)] = \"fallback\"\n",
        "                    fallback_date_map[(bus, current_date_str)] = fallback_date\n",
        "                    source_spreadsheet_map[(bus, current_date_str)] = spreadsheet_names[idx]\n",
        "                    print(f\"🔄 Fallback match: {val} km on {fallback_date}\")\n",
        "            break  # Stop searching if found\n",
        "        except Exception as e:\n",
        "            if \"not found\" in str(e):\n",
        "                print(f\"❌ Bus {bus} not in {spreadsheet_names[idx]}\")\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"⚠️ Error accessing {bus} in {spreadsheet_names[idx]}: {e}\")\n",
        "    if not found:\n",
        "        print(f\"🚨 Bus {bus} not found in ANY spreadsheet!\")\n",
        "\n",
        "# Update Report1 with logging\n",
        "print(\"\\n📝 Writing data to Report1...\")\n",
        "updated_rows = []\n",
        "for row_idx, (bus, date_str) in row_map.items():\n",
        "    key = (bus, date_str)\n",
        "    val = bus_date_value_map.get(key, \"\")\n",
        "    fallback = fallback_date_map.get(key, \"\")\n",
        "    match_type = match_type_map.get(key, \"\")\n",
        "    source = source_spreadsheet_map.get(key, \"\")\n",
        "\n",
        "    # Build updated values for Column C and D\n",
        "    col_c = fallback if match_type == \"fallback\" else (source if match_type == \"exact\" else \"\")\n",
        "    col_d = val if val else \"\"\n",
        "\n",
        "    # Log updates for verification\n",
        "    if not val:\n",
        "        print(f\"⚠️ No data for Bus {bus} | Date {date_str}\")\n",
        "\n",
        "    updated_rows.append([col_c, col_d])\n",
        "\n",
        "# Batch update\n",
        "if updated_rows:\n",
        "    range_to_update = f\"C2:D{len(updated_rows) + 1}\"\n",
        "    RR_Report1_Worksheet.update(range_to_update, updated_rows)\n",
        "    print(\"✅ Report1 updated successfully!\")\n",
        "else:\n",
        "    print(\"❌ No updates made to Report1.\")"
      ],
      "metadata": {
        "id": "HVEl5unftQaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b612cdae-4571-48b1-e397-7e1b6d99bee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔎 Total buses to process: 97\n",
            "Sample buses: ['573', '475', '550', '980', '473']\n",
            "⚠️ Error accessing 573 in SVP: 573\n",
            "\n",
            "✅ Found bus 573 in FG\n",
            "🔄 Fallback match: 537211 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 475 in SVP\n",
            "🔄 Fallback match: 327218 km on 12,Apr25\n",
            "\n",
            "✅ Found bus 550 in SVP\n",
            "🔄 Fallback match: 680912 km on 14,Oct24\n",
            "⚠️ Error accessing 980 in SVP: 980\n",
            "⚠️ Error accessing 980 in FG: 980\n",
            "⚠️ Error accessing 980 in BT: 980\n",
            "⚠️ Error accessing 980 in RT: 980\n",
            "\n",
            "✅ Found bus 980 in MB\n",
            "🔄 Fallback match: 361040 km on 05,Apr25\n",
            "\n",
            "✅ Found bus 473 in SVP\n",
            "🔄 Fallback match: 335615 km on 31,Jan25\n",
            "⚠️ Error accessing 505 in SVP: 505\n",
            "\n",
            "✅ Found bus 505 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "⚠️ Error accessing 516 in SVP: 516\n",
            "\n",
            "✅ Found bus 516 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "\n",
            "✅ Found bus 535 in SVP\n",
            "🔄 Fallback match: 347321 km on 30,Apr25\n",
            "⚠️ Error accessing 616 in SVP: 616\n",
            "\n",
            "✅ Found bus 616 in FG\n",
            "🔄 Fallback match: 69878 km on 30,Apr25\n",
            "⚠️ Error accessing 517 in SVP: 517\n",
            "\n",
            "✅ Found bus 517 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "\n",
            "✅ Found bus 514 in SVP\n",
            "🔄 Fallback match: 181581 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 523 in SVP\n",
            "🔄 Fallback match: 281016 km on 23,Apr25\n",
            "\n",
            "✅ Found bus 546 in SVP\n",
            "🔄 Fallback match: 530821 km on 29,Apr25\n",
            "⚠️ Error accessing 344 in SVP: 344\n",
            "\n",
            "✅ Found bus 344 in FG\n",
            "🔄 Fallback match: 848312 km on 28,Nov24\n",
            "\n",
            "✅ Found bus 604 in SVP\n",
            "🔄 Fallback match: 112715 km on 28,Apr25\n",
            "\n",
            "✅ Found bus 598 in SVP\n",
            "🔄 Fallback match: 112276 km on 30,Apr25\n",
            "⚠️ Error accessing 419 in SVP: 419\n",
            "\n",
            "✅ Found bus 419 in FG\n",
            "📌 Exact match: 822549 km on 07,May25\n",
            "⚠️ Error accessing 507 in SVP: 507\n",
            "\n",
            "✅ Found bus 507 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "⚠️ Error accessing 561 in SVP: 561\n",
            "\n",
            "✅ Found bus 561 in FG\n",
            "🔄 Fallback match: 568080 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 611 in SVP\n",
            "⚠️ Error accessing 572 in SVP: 572\n",
            "\n",
            "✅ Found bus 572 in FG\n",
            "🔄 Fallback match: 462944 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 577 in SVP\n",
            "🔄 Fallback match: 612439 km on 29,Apr25\n",
            "⚠️ Error accessing 970 in SVP: 970\n",
            "⚠️ Error accessing 970 in FG: 970\n",
            "⚠️ Error accessing 970 in BT: 970\n",
            "⚠️ Error accessing 970 in RT: 970\n",
            "⚠️ Error accessing 970 in MB: 970\n",
            "\n",
            "✅ Found bus 970 in DP\n",
            "🔄 Fallback match: 383845 km on 29,Mar25\n",
            "⚠️ Error accessing 529 in SVP: 529\n",
            "\n",
            "✅ Found bus 529 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "\n",
            "✅ Found bus 563 in SVP\n",
            "🔄 Fallback match: 731725 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 613 in SVP\n",
            "🔄 Fallback match: 53915 km on 17,Mar25\n",
            "⚠️ Error accessing 386 in SVP: 386\n",
            "\n",
            "✅ Found bus 386 in FG\n",
            "📌 Exact match: 952819 km on 07,May25\n",
            "⚠️ Error accessing 328 in SVP: 328\n",
            "\n",
            "✅ Found bus 328 in FG\n",
            "📌 Exact match: 890649 km on 07,May25\n",
            "⚠️ Error accessing 437 in SVP: 437\n",
            "\n",
            "✅ Found bus 437 in FG\n",
            "📌 Exact match: 226239 km on 07,May25\n",
            "\n",
            "✅ Found bus 588 in SVP\n",
            "🔄 Fallback match: 283724 km on 29,Apr25\n",
            "⚠️ Error accessing 436 in SVP: 436\n",
            "\n",
            "✅ Found bus 436 in FG\n",
            "📌 Exact match: 844333 km on 07,May25\n",
            "\n",
            "✅ Found bus 444 in SVP\n",
            "🔄 Fallback match: 302009 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 612 in SVP\n",
            "🔄 Fallback match: 59542 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 578 in SVP\n",
            "🔄 Fallback match: 470659 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 441 in SVP\n",
            "🔄 Fallback match: 278164 km on 12,Apr25\n",
            "\n",
            "✅ Found bus 442 in SVP\n",
            "🔄 Fallback match: 276631 km on 29,Apr25\n",
            "\n",
            "✅ Found bus 472 in SVP\n",
            "🔄 Fallback match: 394977 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 548 in SVP\n",
            "🔄 Fallback match: 584445 km on 30,Apr25\n",
            "⚠️ Error accessing 593 in SVP: 593\n",
            "\n",
            "✅ Found bus 593 in FG\n",
            "🔄 Fallback match: 392975 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 515 in SVP\n",
            "🔄 Fallback match: 474742 km on 14,Feb25\n",
            "\n",
            "✅ Found bus 590 in SVP\n",
            "🔄 Fallback match: 434115 km on 30,Apr25\n",
            "⚠️ Error accessing 435 in SVP: 435\n",
            "\n",
            "✅ Found bus 435 in FG\n",
            "📌 Exact match: 759130 km on 07,May25\n",
            "⚠️ Error accessing 478 in SVP: 478\n",
            "\n",
            "✅ Found bus 478 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "\n",
            "✅ Found bus 614 in SVP\n",
            "🔄 Fallback match: 58677 km on 30,Apr25\n",
            "⚠️ Error accessing 617 in SVP: 617\n",
            "\n",
            "✅ Found bus 617 in FG\n",
            "🔄 Fallback match: 64884 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 534 in SVP\n",
            "🔄 Fallback match: 308237 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 495 in SVP\n",
            "🔄 Fallback match: 582773 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 605 in SVP\n",
            "🔄 Fallback match: 97548 km on 30,Apr25\n",
            "⚠️ Error accessing 388 in SVP: 388\n",
            "\n",
            "✅ Found bus 388 in FG\n",
            "📌 Exact match: 970626 km on 07,May25\n",
            "\n",
            "✅ Found bus 589 in SVP\n",
            "🔄 Fallback match: 197762 km on 04,Mar25\n",
            "⚠️ Error accessing 479 in SVP: 479\n",
            "\n",
            "✅ Found bus 479 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "\n",
            "✅ Found bus 511 in SVP\n",
            "🔄 Fallback match: 249770 km on 21,Apr25\n",
            "\n",
            "✅ Found bus 585 in SVP\n",
            "🔄 Fallback match: 357505 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 530 in SVP\n",
            "🔄 Fallback match: 397808 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 462 in SVP\n",
            "🔄 Fallback match: 394278 km on 11,Apr25\n",
            "\n",
            "✅ Found bus 460 in SVP\n",
            "🔄 Fallback match: 367402 km on 06,Feb25\n",
            "\n",
            "✅ Found bus 536 in SVP\n",
            "🔄 Fallback match: 327453 km on 30,Apr25\n",
            "⚠️ Error accessing 415 in SVP: 415\n",
            "\n",
            "✅ Found bus 415 in FG\n",
            "📌 Exact match: 782927 km on 07,May25\n",
            "\n",
            "✅ Found bus 599 in SVP\n",
            "🔄 Fallback match: 98555 km on 29,Apr25\n",
            "\n",
            "✅ Found bus 547 in SVP\n",
            "🔄 Fallback match: 700980 km on 30,Apr25\n",
            "⚠️ Error accessing 999 in SVP: 999\n",
            "⚠️ Error accessing 999 in FG: 999\n",
            "\n",
            "✅ Found bus 999 in BT\n",
            "🔄 Fallback match: 345158 km on 29,Mar25\n",
            "\n",
            "✅ Found bus 595 in SVP\n",
            "🔄 Fallback match: 277672 km on 29,Apr25\n",
            "⚠️ Error accessing 370 in SVP: 370\n",
            "\n",
            "✅ Found bus 370 in FG\n",
            "📌 Exact match: 869516 km on 07,May25\n",
            "\n",
            "✅ Found bus 317 in SVP\n",
            "🔄 Fallback match: 22268 km on 11,Aug24\n",
            "\n",
            "✅ Found bus 528 in SVP\n",
            "🔄 Fallback match: 302453 km on 25,Apr25\n",
            "\n",
            "✅ Found bus 504 in SVP\n",
            "🔄 Fallback match: 378130 km on 30,Apr25\n",
            "⚠️ Error accessing 463 in SVP: 463\n",
            "\n",
            "✅ Found bus 463 in FG\n",
            "📌 Exact match: 254649 km on 07,May25\n",
            "⚠️ Error accessing 461 in SVP: 461\n",
            "\n",
            "✅ Found bus 461 in FG\n",
            "📌 Exact match: 273427 km on 07,May25\n",
            "\n",
            "✅ Found bus 575 in SVP\n",
            "🔄 Fallback match: 391243 km on 13,Nov24\n",
            "\n",
            "✅ Found bus 440 in SVP\n",
            "🔄 Fallback match: 259274 km on 23,Apr25\n",
            "\n",
            "✅ Found bus 469 in SVP\n",
            "🔄 Fallback match: 236807 km on 29,Apr25\n",
            "\n",
            "✅ Found bus 521 in SVP\n",
            "🔄 Fallback match: 307029 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 508 in SVP\n",
            "🔄 Fallback match: 379571 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 596 in SVP\n",
            "🔄 Fallback match: 94648 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 474 in SVP\n",
            "🔄 Fallback match: 373312 km on 28,Apr25\n",
            "⚠️ Error accessing 202 in SVP: 202\n",
            "\n",
            "✅ Found bus 202 in FG\n",
            "🔄 Fallback match: 420507 km on 09,Oct24\n",
            "⚠️ Error accessing 592 in SVP: 592\n",
            "\n",
            "✅ Found bus 592 in FG\n",
            "🔄 Fallback match: 367136 km on 30,Apr25\n",
            "⚠️ Error accessing 615 in SVP: 615\n",
            "\n",
            "✅ Found bus 615 in FG\n",
            "🔄 Fallback match: 58303 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 597 in SVP\n",
            "🔄 Fallback match: 121118 km on 30,Apr25\n",
            "⚠️ Error accessing 990 in SVP: 990\n",
            "⚠️ Error accessing 990 in FG: 990\n",
            "⚠️ Error accessing 990 in BT: 990\n",
            "\n",
            "✅ Found bus 990 in RT\n",
            "🔄 Fallback match: 278164 km on 03,Mar25\n",
            "\n",
            "✅ Found bus 486 in SVP\n",
            "🔄 Fallback match: 379760 km on 28,Mar25\n",
            "⚠️ Error accessing 340 in SVP: 340\n",
            "\n",
            "✅ Found bus 340 in FG\n",
            "📌 Exact match: 826062 km on 07,May25\n",
            "⚠️ Error accessing 438 in SVP: 438\n",
            "\n",
            "✅ Found bus 438 in FG\n",
            "🔄 Fallback match: 316573 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 603 in SVP\n",
            "🔄 Fallback match: 96410 km on 29,Apr25\n",
            "⚠️ Error accessing 560 in SVP: 560\n",
            "\n",
            "✅ Found bus 560 in FG\n",
            "🔄 Fallback match: 576255 km on 24,Apr25\n",
            "\n",
            "✅ Found bus 587 in SVP\n",
            "🔄 Fallback match: 294523 km on 29,Apr25\n",
            "\n",
            "✅ Found bus 476 in SVP\n",
            "🔄 Fallback match: 387273 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 471 in SVP\n",
            "🔄 Fallback match: 401396 km on 30,Apr25\n",
            "⚠️ Error accessing 562 in SVP: 562\n",
            "\n",
            "✅ Found bus 562 in FG\n",
            "🔄 Fallback match: 588872 km on 30,Apr25\n",
            "⚠️ Error accessing 389 in SVP: 389\n",
            "\n",
            "✅ Found bus 389 in FG\n",
            "📌 Exact match: 1274309 km on 07,May25\n",
            "⚠️ Error accessing 350 in SVP: 350\n",
            "\n",
            "✅ Found bus 350 in FG\n",
            "📌 Exact match: 808382 km on 07,May25\n",
            "\n",
            "✅ Found bus 538 in SVP\n",
            "🔄 Fallback match: 340969 km on 30,Apr25\n",
            "⚠️ Error accessing 493 in SVP: 493\n",
            "\n",
            "✅ Found bus 493 in FG\n",
            "📌 Exact match: 488369 km on 07,May25\n",
            "\n",
            "✅ Found bus 574 in SVP\n",
            "🔄 Fallback match: 548919 km on 02,Dec24\n",
            "\n",
            "✅ Found bus 459 in SVP\n",
            "🔄 Fallback match: 158773 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 457 in SVP\n",
            "🔄 Fallback match: 410222 km on 30,Apr25\n",
            "\n",
            "✅ Found bus 610 in SVP\n",
            "\n",
            "📝 Writing data to Report1...\n",
            "⚠️ No data for Bus 610 | Date 07,May25\n",
            "⚠️ No data for Bus 611 | Date 07,May25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-64-b1d2be683ee7>:140: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  RR_Report1_Worksheet.update(range_to_update, updated_rows)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Report1 updated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Modifications Needed\n",
        "Multiple Target Worksheets:\n",
        "\n",
        "engine_oil_CH_BSIV_CH_MAS_rr (existing)\n",
        "engine_oil_CK_BSVI_CK_MAS_rr (new)\n",
        "engine_oil_CK_BSVI_CK_MAS_ATR (new)\n",
        "engine_oil_CH_BSIV_CH_MAS_ATR (new)\n",
        "\n",
        "Multiple Source Spreadsheets:\n",
        "\n",
        "Odometer_spreadsheet_SVP (existing)\n",
        "Odometer_spreadsheet_FG (new)\n",
        "Odometer_spreadsheet_BT (new)\n",
        "Odometer_spreadsheet_RT (new)\n",
        "Odometer_spreadsheet_MB (new)\n",
        "Odometer_spreadsheet_DP (new)"
      ],
      "metadata": {
        "id": "wvMmprUNKW7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified to process multiple engine oil worksheets SVP CH CK, ATR CH CK, No batch processing done\n",
        "\n",
        "# Make sure to include these imports at the top of your code\n",
        "import re\n",
        "from datetime import datetime\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import gspread\n",
        "\n",
        "# List of all worksheets to process\n",
        "engine_oil_worksheets = [\n",
        "    'engine_oil_CH_BSIV_CH_MAS_ATR',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_ATR',\n",
        "    'engine_oil_CH_BSIV_CH_MAS_rr',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_rr'\n",
        "]\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "# Function to process each worksheet\n",
        "def process_worksheet(worksheet_name):\n",
        "    print(f\"\\n🔄 Processing worksheet: {worksheet_name}\")\n",
        "\n",
        "    # Get the worksheet object\n",
        "    worksheet = None\n",
        "    try:\n",
        "        # Assuming these are defined in your notebook environment\n",
        "        worksheet = eval(worksheet_name)  # This will use the already defined variable in your notebook\n",
        "    except:\n",
        "        print(f\"❌ Error: Worksheet '{worksheet_name}' not found or not accessible\")\n",
        "        return\n",
        "\n",
        "    # Clear data in range L2:M, Odometer value in Engine Oil and Fallback date removal\n",
        "    clear_range = 'L2:M'\n",
        "    print(f\"🧹 Clearing range {clear_range} in {worksheet_name}...\")\n",
        "    worksheet.batch_clear([clear_range])\n",
        "\n",
        "    print(\"🔍 Starting data processing with date fallback search...\")\n",
        "\n",
        "    # 📥 Load main sheet\n",
        "    print(\"📥 Loading worksheet data...\")\n",
        "    main_data = worksheet.get_all_values()\n",
        "    print(f\"✅ Loaded {len(main_data)-1} rows from worksheet\")\n",
        "\n",
        "    # Step 1: Collect unique (bus, date) and row mapping\n",
        "    print(\"🔢 Mapping bus numbers and dates...\")\n",
        "    bus_date_map = defaultdict(set)\n",
        "    row_map = {}  # maps row number → (bus, date)\n",
        "\n",
        "    for i, row in enumerate(main_data[1:], start=2):\n",
        "        try:\n",
        "            date_str = row[1].strip()\n",
        "            bus_num = row[4].strip()\n",
        "            if date_str and bus_num:\n",
        "                bus_date_map[bus_num].add(date_str)\n",
        "                row_map[i] = (bus_num, date_str)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"✅ Found {len(bus_date_map)} unique bus numbers\")\n",
        "    print(f\"✅ Found {len(row_map)} rows to process\")\n",
        "\n",
        "    # Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "    print(\"\\n🔍 Searching for exact dates or closest earlier dates...\")\n",
        "    bus_date_value_map = {}\n",
        "    match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "    fallback_date_map = {}  # Store the actual fallback date used\n",
        "    success_count = 0\n",
        "    fallback_count = 0\n",
        "\n",
        "    for bus, dates in bus_date_map.items():\n",
        "        print(f\"📊 Processing bus {bus} ({len(dates)} dates)...\")\n",
        "        try:\n",
        "            # Assuming Odometer_spreadsheet_SVP is defined in your notebook\n",
        "            sheet = Odometer_spreadsheet_SVP.worksheet(bus)\n",
        "            sheet_data = sheet.get_all_values()\n",
        "            sheet_success = 0\n",
        "\n",
        "            for date_str in dates:\n",
        "                # Find exact match first\n",
        "                exact_value = None\n",
        "                for row in sheet_data[1:]:\n",
        "                    try:\n",
        "                        if len(row) > 12 and row[1].strip() == date_str:\n",
        "                            exact_value = row[12]  # Column M\n",
        "                            break\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                if exact_value:\n",
        "                    bus_date_value_map[(bus, date_str)] = exact_value\n",
        "                    match_type_map[(bus, date_str)] = \"exact\"\n",
        "                    fallback_date_map[(bus, date_str)] = \"\"  # No fallback date for exact matches\n",
        "                    sheet_success += 1\n",
        "                    success_count += 1\n",
        "                else:\n",
        "                    # Try to find closest earlier date\n",
        "                    value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                    if value:\n",
        "                        bus_date_value_map[(bus, date_str)] = value\n",
        "                        match_type_map[(bus, date_str)] = \"fallback\"\n",
        "                        fallback_date_map[(bus, date_str)] = fallback_date  # Store the fallback date used\n",
        "                        sheet_success += 1\n",
        "                        fallback_count += 1\n",
        "\n",
        "            print(f\"  ✅ Found {sheet_success}/{len(dates)} values for bus {bus}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Could not process sheet '{bus}': {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n✅ Found values for {success_count} exact date matches\")\n",
        "    print(f\"✅ Found values for {fallback_count} fallback date matches\")\n",
        "    print(f\"❌ Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "    # Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "    print(f\"\\n📝 Updating values and formatting in {worksheet_name}...\")\n",
        "    updated_count = 0\n",
        "\n",
        "    # Prepare batch formatting requests for different match types\n",
        "    exact_match_cells = []\n",
        "    fallback_match_cells = []\n",
        "\n",
        "    for row_num, (bus, date_str) in row_map.items():\n",
        "        value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "        fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "\n",
        "        if value:\n",
        "            max_retries = 5\n",
        "            retry_count = 0\n",
        "            update_successful = False\n",
        "\n",
        "            while not update_successful and retry_count < max_retries:\n",
        "                try:\n",
        "                    # Update cell value in column L (value)\n",
        "                    worksheet.update_cell(row_num, 12, value)  # Column L = col 12\n",
        "\n",
        "                    # Update column M with fallback date if applicable\n",
        "                    worksheet.update_cell(row_num, 13, fallback_date)  # Column M = col 13\n",
        "\n",
        "                    # Track which cells need which formatting\n",
        "                    match_type = match_type_map.get((bus, date_str))\n",
        "                    if match_type == \"exact\":\n",
        "                        exact_match_cells.append(f\"L{row_num}\")\n",
        "                    elif match_type == \"fallback\":\n",
        "                        fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "                    update_successful = True\n",
        "                    updated_count += 1\n",
        "                    if updated_count % 10 == 0:\n",
        "                        print(f\"📊 Progress: Updated {updated_count}/{len(bus_date_value_map)} values\")\n",
        "                except Exception as e:\n",
        "                    retry_count += 1\n",
        "                    if \"429\" in str(e):\n",
        "                        wait_time = (2 ** retry_count) + random.random()\n",
        "                        print(f\"⏳ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                        time.sleep(wait_time)\n",
        "                    else:\n",
        "                        print(f\"❌ Failed to update row {row_num}: {e}\")\n",
        "                        break\n",
        "\n",
        "            if not update_successful:\n",
        "                print(f\"❌ Failed to update row {row_num} after {max_retries} retries\")\n",
        "\n",
        "    # Apply formatting in batches (currently commented out)\n",
        "    print(\"\\n🎨 Applying formatting to distinguish match types...\")\n",
        "    # You can uncomment and implement batch formatting logic if needed.\n",
        "\n",
        "    print(f\"\\n✅ COMPLETE for {worksheet_name}: Updated {updated_count} rows in column L and column M\")\n",
        "    print(f\"📊 Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "    print(f\"❌ {len(row_map) - updated_count} rows could not be updated\")\n",
        "\n",
        "# Main execution\n",
        "print(\"🚀 Starting to process all engine oil worksheets...\")\n",
        "\n",
        "# Process each worksheet in sequence\n",
        "for worksheet_name in engine_oil_worksheets:\n",
        "    process_worksheet(worksheet_name)\n",
        "\n",
        "print(\"\\n✅ All worksheets have been processed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGaEDmbzQGBc",
        "outputId": "d69b41d7-e60d-4e35-e15e-1e0796421939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting to process all engine oil worksheets...\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CH_BSIV_CH_MAS_ATR\n",
            "🧹 Clearing range L2:M in engine_oil_CH_BSIV_CH_MAS_ATR...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 900 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 39 unique bus numbers\n",
            "✅ Found 320 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "📊 Processing bus 381 (3 dates)...\n",
            "❌ Could not process sheet '381': 381\n",
            "📊 Processing bus 574 (16 dates)...\n",
            "  ✅ Found 16/16 values for bus 574\n",
            "📊 Processing bus 575 (5 dates)...\n",
            "  ✅ Found 5/5 values for bus 575\n",
            "📊 Processing bus 576 (5 dates)...\n",
            "❌ Could not process sheet '576': 576\n",
            "📊 Processing bus 579 (5 dates)...\n",
            "❌ Could not process sheet '579': 579\n",
            "📊 Processing bus 590 (14 dates)...\n",
            "  ✅ Found 14/14 values for bus 590\n",
            "📊 Processing bus 546 (28 dates)...\n",
            "  ✅ Found 28/28 values for bus 546\n",
            "📊 Processing bus 368 (4 dates)...\n",
            "❌ Could not process sheet '368': 368\n",
            "📊 Processing bus 550 (16 dates)...\n",
            "  ✅ Found 16/16 values for bus 550\n",
            "📊 Processing bus 565 (1 dates)...\n",
            "❌ Could not process sheet '565': 565\n",
            "📊 Processing bus 319 (3 dates)...\n",
            "❌ Could not process sheet '319': 319\n",
            "📊 Processing bus 548 (25 dates)...\n",
            "  ✅ Found 25/25 values for bus 548\n",
            "📊 Processing bus 564 (3 dates)...\n",
            "❌ Could not process sheet '564': 564\n",
            "📊 Processing bus 584 (3 dates)...\n",
            "❌ Could not process sheet '584': 584\n",
            "📊 Processing bus 547 (19 dates)...\n",
            "  ✅ Found 19/19 values for bus 547\n",
            "📊 Processing bus 495 (9 dates)...\n",
            "  ✅ Found 9/9 values for bus 495\n",
            "📊 Processing bus 566 (2 dates)...\n",
            "❌ Could not process sheet '566': 566\n",
            "📊 Processing bus 595 (16 dates)...\n",
            "  ✅ Found 16/16 values for bus 595\n",
            "📊 Processing bus 560 (1 dates)...\n",
            "❌ Could not process sheet '560': 560\n",
            "📊 Processing bus 578 (27 dates)...\n",
            "  ✅ Found 27/27 values for bus 578\n",
            "📊 Processing bus 591 (1 dates)...\n",
            "❌ Could not process sheet '591': 591\n",
            "📊 Processing bus 545 (3 dates)...\n",
            "❌ Could not process sheet '545': 545\n",
            "📊 Processing bus 593 (1 dates)...\n",
            "❌ Could not process sheet '593': 593\n",
            "📊 Processing bus 549 (2 dates)...\n",
            "❌ Could not process sheet '549': 549\n",
            "📊 Processing bus 589 (6 dates)...\n",
            "  ✅ Found 6/6 values for bus 589\n",
            "📊 Processing bus 563 (26 dates)...\n",
            "  ✅ Found 26/26 values for bus 563\n",
            "📊 Processing bus 553 (3 dates)...\n",
            "❌ Could not process sheet '553': 553\n",
            "📊 Processing bus 544 (1 dates)...\n",
            "❌ Could not process sheet '544': 544\n",
            "📊 Processing bus 430 (1 dates)...\n",
            "❌ Could not process sheet '430': 430\n",
            "📊 Processing bus 577 (32 dates)...\n",
            "  ✅ Found 32/32 values for bus 577\n",
            "📊 Processing bus 588 (21 dates)...\n",
            "  ✅ Found 21/21 values for bus 588\n",
            "📊 Processing bus 317 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 317\n",
            "📊 Processing bus 474 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 474\n",
            "📊 Processing bus 562 (1 dates)...\n",
            "❌ Could not process sheet '562': 562\n",
            "📊 Processing bus 433 (1 dates)...\n",
            "❌ Could not process sheet '433': 433\n",
            "📊 Processing bus 409 (1 dates)...\n",
            "❌ Could not process sheet '409': 409\n",
            "📊 Processing bus 587 (10 dates)...\n",
            "  ✅ Found 10/10 values for bus 587\n",
            "📊 Processing bus Grease Gun (2 dates)...\n",
            "❌ Could not process sheet 'Grease Gun': Grease Gun\n",
            "📊 Processing bus 557 (1 dates)...\n",
            "❌ Could not process sheet '557': 557\n",
            "\n",
            "✅ Found values for 65 exact date matches\n",
            "✅ Found values for 207 fallback date matches\n",
            "❌ Could not find values for 48 dates\n",
            "\n",
            "📝 Updating values and formatting in engine_oil_CH_BSIV_CH_MAS_ATR...\n",
            "📊 Progress: Updated 10/272 values\n",
            "📊 Progress: Updated 20/272 values\n",
            "📊 Progress: Updated 30/272 values\n",
            "📊 Progress: Updated 40/272 values\n",
            "📊 Progress: Updated 50/272 values\n",
            "📊 Progress: Updated 60/272 values\n",
            "📊 Progress: Updated 70/272 values\n",
            "📊 Progress: Updated 80/272 values\n",
            "📊 Progress: Updated 90/272 values\n",
            "📊 Progress: Updated 100/272 values\n",
            "📊 Progress: Updated 110/272 values\n",
            "📊 Progress: Updated 120/272 values\n",
            "📊 Progress: Updated 130/272 values\n",
            "📊 Progress: Updated 140/272 values\n",
            "⏳ Rate limit hit, waiting for 2.63 seconds (retry 1/5)\n",
            "⏳ Rate limit hit, waiting for 4.05 seconds (retry 2/5)\n",
            "⏳ Rate limit hit, waiting for 8.29 seconds (retry 3/5)\n",
            "⏳ Rate limit hit, waiting for 16.36 seconds (retry 4/5)\n",
            "📊 Progress: Updated 150/272 values\n",
            "📊 Progress: Updated 160/272 values\n",
            "📊 Progress: Updated 170/272 values\n",
            "📊 Progress: Updated 180/272 values\n",
            "📊 Progress: Updated 190/272 values\n",
            "📊 Progress: Updated 200/272 values\n",
            "📊 Progress: Updated 210/272 values\n",
            "📊 Progress: Updated 220/272 values\n",
            "📊 Progress: Updated 230/272 values\n",
            "📊 Progress: Updated 240/272 values\n",
            "📊 Progress: Updated 250/272 values\n",
            "📊 Progress: Updated 260/272 values\n",
            "📊 Progress: Updated 270/272 values\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CH_BSIV_CH_MAS_ATR: Updated 272 rows in column L and column M\n",
            "📊 Summary: 65 exact matches (normal format), 207 fallback matches (italic and right-aligned)\n",
            "❌ 48 rows could not be updated\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CK_BSVI_CK_MAS_ATR\n",
            "🧹 Clearing range L2:M in engine_oil_CK_BSVI_CK_MAS_ATR...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 32 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 8 unique bus numbers\n",
            "✅ Found 22 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "📊 Processing bus 596 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 596\n",
            "📊 Processing bus 600 (1 dates)...\n",
            "❌ Could not process sheet '600': 600\n",
            "📊 Processing bus 597 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 597\n",
            "📊 Processing bus 603 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 603\n",
            "📊 Processing bus 598 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 598\n",
            "📊 Processing bus 604 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 604\n",
            "📊 Processing bus 599 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 599\n",
            "📊 Processing bus 605 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 605\n",
            "\n",
            "✅ Found values for 1 exact date matches\n",
            "✅ Found values for 20 fallback date matches\n",
            "❌ Could not find values for 1 dates\n",
            "\n",
            "📝 Updating values and formatting in engine_oil_CK_BSVI_CK_MAS_ATR...\n",
            "📊 Progress: Updated 10/21 values\n",
            "📊 Progress: Updated 20/21 values\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CK_BSVI_CK_MAS_ATR: Updated 21 rows in column L and column M\n",
            "📊 Summary: 1 exact matches (normal format), 20 fallback matches (italic and right-aligned)\n",
            "❌ 1 rows could not be updated\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CH_BSIV_CH_MAS_rr\n",
            "🧹 Clearing range L2:M in engine_oil_CH_BSIV_CH_MAS_rr...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 929 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 76 unique bus numbers\n",
            "✅ Found 914 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "📊 Processing bus 504 (17 dates)...\n",
            "  ✅ Found 17/17 values for bus 504\n",
            "📊 Processing bus 326 (5 dates)...\n",
            "❌ Could not process sheet '326': 326\n",
            "📊 Processing bus 477 (3 dates)...\n",
            "❌ Could not process sheet '477': 477\n",
            "📊 Processing bus 322 (8 dates)...\n",
            "❌ Could not process sheet '322': 322\n",
            "📊 Processing bus 317 (55 dates)...\n",
            "  ✅ Found 55/55 values for bus 317\n",
            "📊 Processing bus 486 (15 dates)...\n",
            "  ✅ Found 15/15 values for bus 486\n",
            "📊 Processing bus 342 (15 dates)...\n",
            "❌ Could not process sheet '342': 342\n",
            "📊 Processing bus 585 (39 dates)...\n",
            "  ✅ Found 39/39 values for bus 585\n",
            "📊 Processing bus 493 (21 dates)...\n",
            "❌ Could not process sheet '493': 493\n",
            "📊 Processing bus 460 (28 dates)...\n",
            "  ✅ Found 28/28 values for bus 460\n",
            "📊 Processing bus 381 (25 dates)...\n",
            "❌ Could not process sheet '381': 381\n",
            "📊 Processing bus 474 (41 dates)...\n",
            "  ✅ Found 41/41 values for bus 474\n",
            "📊 Processing bus 546 (2 dates)...\n",
            "  ✅ Found 2/2 values for bus 546\n",
            "📊 Processing bus 462 (46 dates)...\n",
            "  ✅ Found 46/46 values for bus 462\n",
            "📊 Processing bus 319 (26 dates)...\n",
            "❌ Could not process sheet '319': 319\n",
            "📊 Processing bus 443 (5 dates)...\n",
            "❌ Could not process sheet '443': 443\n",
            "📊 Processing bus 534 (22 dates)...\n",
            "  ✅ Found 22/22 values for bus 534\n",
            "📊 Processing bus 595 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 595\n",
            "📊 Processing bus 473 (14 dates)...\n",
            "  ✅ Found 14/14 values for bus 473\n",
            "📊 Processing bus 535 (14 dates)...\n",
            "  ✅ Found 14/14 values for bus 535\n",
            "📊 Processing bus 576 (1 dates)...\n",
            "❌ Could not process sheet '576': 576\n",
            "📊 Processing bus 523 (14 dates)...\n",
            "  ✅ Found 14/14 values for bus 523\n",
            "📊 Processing bus RCS (7 dates)...\n",
            "❌ Could not process sheet 'RCS': RCS\n",
            "📊 Processing bus 469 (33 dates)...\n",
            "  ✅ Found 33/33 values for bus 469\n",
            "📊 Processing bus 560 (2 dates)...\n",
            "❌ Could not process sheet '560': 560\n",
            "📊 Processing bus 440 (18 dates)...\n",
            "  ✅ Found 18/18 values for bus 440\n",
            "📊 Processing bus 444 (25 dates)...\n",
            "  ✅ Found 25/25 values for bus 444\n",
            "📊 Processing bus 457 (48 dates)...\n",
            "  ✅ Found 48/48 values for bus 457\n",
            "📊 Processing bus 574 (2 dates)...\n",
            "  ✅ Found 2/2 values for bus 574\n",
            "📊 Processing bus 442 (12 dates)...\n",
            "  ✅ Found 12/12 values for bus 442\n",
            "📊 Processing bus 590 (6 dates)...\n",
            "  ✅ Found 6/6 values for bus 590\n",
            "📊 Processing bus 548 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 548\n",
            "📊 Processing bus 515 (31 dates)...\n",
            "  ✅ Found 31/31 values for bus 515\n",
            "📊 Processing bus 419 (2 dates)...\n",
            "❌ Could not process sheet '419': 419\n",
            "📊 Processing bus 475 (12 dates)...\n",
            "  ✅ Found 12/12 values for bus 475\n",
            "📊 Processing bus 476 (19 dates)...\n",
            "  ✅ Found 19/19 values for bus 476\n",
            "📊 Processing bus 536 (26 dates)...\n",
            "  ✅ Found 26/26 values for bus 536\n",
            "📊 Processing bus 514 (19 dates)...\n",
            "  ✅ Found 19/19 values for bus 514\n",
            "📊 Processing bus 341 (11 dates)...\n",
            "❌ Could not process sheet '341': 341\n",
            "📊 Processing bus 578 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 578\n",
            "📊 Processing bus 528 (13 dates)...\n",
            "  ✅ Found 13/13 values for bus 528\n",
            "📊 Processing bus 472 (30 dates)...\n",
            "  ✅ Found 30/30 values for bus 472\n",
            "📊 Processing bus 553 (1 dates)...\n",
            "❌ Could not process sheet '553': 553\n",
            "📊 Processing bus 538 (13 dates)...\n",
            "  ✅ Found 13/13 values for bus 538\n",
            "📊 Processing bus 441 (8 dates)...\n",
            "  ✅ Found 8/8 values for bus 441\n",
            "📊 Processing bus 589 (2 dates)...\n",
            "  ✅ Found 2/2 values for bus 589\n",
            "📊 Processing bus 314 (2 dates)...\n",
            "❌ Could not process sheet '314': 314\n",
            "📊 Processing bus 471 (24 dates)...\n",
            "  ✅ Found 24/24 values for bus 471\n",
            "📊 Processing bus 513 (1 dates)...\n",
            "❌ Could not process sheet '513': 513\n",
            "📊 Processing bus 459 (10 dates)...\n",
            "  ✅ Found 10/10 values for bus 459\n",
            "📊 Processing bus 511 (14 dates)...\n",
            "  ✅ Found 14/14 values for bus 511\n",
            "📊 Processing bus 544 (1 dates)...\n",
            "❌ Could not process sheet '544': 544\n",
            "📊 Processing bus 352 (1 dates)...\n",
            "❌ Could not process sheet '352': 352\n",
            "📊 Processing bus 487 (5 dates)...\n",
            "❌ Could not process sheet '487': 487\n",
            "📊 Processing bus ES (1 dates)...\n",
            "❌ Could not process sheet 'ES': ES\n",
            "📊 Processing bus 368 (12 dates)...\n",
            "❌ Could not process sheet '368': 368\n",
            "📊 Processing bus 438 (1 dates)...\n",
            "❌ Could not process sheet '438': 438\n",
            "📊 Processing bus D.G.SET (2 dates)...\n",
            "❌ Could not process sheet 'D.G.SET': D.G.SET\n",
            "📊 Processing bus 508 (16 dates)...\n",
            "  ✅ Found 16/16 values for bus 508\n",
            "📊 Processing bus 587 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 587\n",
            "📊 Processing bus 435 (1 dates)...\n",
            "❌ Could not process sheet '435': 435\n",
            "📊 Processing bus 563 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 563\n",
            "📊 Processing bus 593 (1 dates)...\n",
            "❌ Could not process sheet '593': 593\n",
            "📊 Processing bus 530 (9 dates)...\n",
            "  ✅ Found 9/9 values for bus 530\n",
            "📊 Processing bus 409 (1 dates)...\n",
            "❌ Could not process sheet '409': 409\n",
            "📊 Processing bus 550 (2 dates)...\n",
            "  ✅ Found 2/2 values for bus 550\n",
            "📊 Processing bus 495 (22 dates)...\n",
            "  ✅ Found 22/22 values for bus 495\n",
            "📊 Processing bus 575 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 575\n",
            "📊 Processing bus 521 (5 dates)...\n",
            "  ✅ Found 5/5 values for bus 521\n",
            "📊 Processing bus 547 (2 dates)...\n",
            "  ✅ Found 2/2 values for bus 547\n",
            "📊 Processing bus 613 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 613\n",
            "📊 Processing bus AirComp. (1 dates)...\n",
            "❌ Could not process sheet 'AirComp.': AirComp.\n",
            "📊 Processing bus 482 (1 dates)...\n",
            "❌ Could not process sheet '482': 482\n",
            "📊 Processing bus 552 (1 dates)...\n",
            "❌ Could not process sheet '552': 552\n",
            "📊 Processing bus 518 (1 dates)...\n",
            "❌ Could not process sheet '518': 518\n",
            "📊 Processing bus B/T (1 dates)...\n",
            "❌ Could not process sheet 'B/T': B/T\n",
            "\n",
            "✅ Found values for 509 exact date matches\n",
            "✅ Found values for 228 fallback date matches\n",
            "❌ Could not find values for 177 dates\n",
            "\n",
            "📝 Updating values and formatting in engine_oil_CH_BSIV_CH_MAS_rr...\n",
            "📊 Progress: Updated 10/737 values\n",
            "📊 Progress: Updated 20/737 values\n",
            "📊 Progress: Updated 30/737 values\n",
            "📊 Progress: Updated 40/737 values\n",
            "📊 Progress: Updated 50/737 values\n",
            "📊 Progress: Updated 60/737 values\n",
            "📊 Progress: Updated 70/737 values\n",
            "📊 Progress: Updated 80/737 values\n",
            "📊 Progress: Updated 90/737 values\n",
            "📊 Progress: Updated 100/737 values\n",
            "📊 Progress: Updated 110/737 values\n",
            "📊 Progress: Updated 120/737 values\n",
            "📊 Progress: Updated 130/737 values\n",
            "📊 Progress: Updated 140/737 values\n",
            "📊 Progress: Updated 150/737 values\n",
            "📊 Progress: Updated 160/737 values\n",
            "📊 Progress: Updated 170/737 values\n",
            "📊 Progress: Updated 180/737 values\n",
            "📊 Progress: Updated 190/737 values\n",
            "📊 Progress: Updated 200/737 values\n",
            "📊 Progress: Updated 210/737 values\n",
            "📊 Progress: Updated 220/737 values\n",
            "📊 Progress: Updated 230/737 values\n",
            "📊 Progress: Updated 240/737 values\n",
            "📊 Progress: Updated 250/737 values\n",
            "📊 Progress: Updated 260/737 values\n",
            "📊 Progress: Updated 270/737 values\n",
            "📊 Progress: Updated 280/737 values\n",
            "📊 Progress: Updated 290/737 values\n",
            "📊 Progress: Updated 300/737 values\n",
            "📊 Progress: Updated 310/737 values\n",
            "📊 Progress: Updated 320/737 values\n",
            "📊 Progress: Updated 330/737 values\n",
            "📊 Progress: Updated 340/737 values\n",
            "📊 Progress: Updated 350/737 values\n",
            "📊 Progress: Updated 360/737 values\n",
            "📊 Progress: Updated 370/737 values\n",
            "📊 Progress: Updated 380/737 values\n",
            "📊 Progress: Updated 390/737 values\n",
            "📊 Progress: Updated 400/737 values\n",
            "📊 Progress: Updated 410/737 values\n",
            "📊 Progress: Updated 420/737 values\n",
            "📊 Progress: Updated 430/737 values\n",
            "📊 Progress: Updated 440/737 values\n",
            "📊 Progress: Updated 450/737 values\n",
            "📊 Progress: Updated 460/737 values\n",
            "📊 Progress: Updated 470/737 values\n",
            "📊 Progress: Updated 480/737 values\n",
            "📊 Progress: Updated 490/737 values\n",
            "📊 Progress: Updated 500/737 values\n",
            "📊 Progress: Updated 510/737 values\n",
            "📊 Progress: Updated 520/737 values\n",
            "📊 Progress: Updated 530/737 values\n",
            "📊 Progress: Updated 540/737 values\n",
            "📊 Progress: Updated 550/737 values\n",
            "📊 Progress: Updated 560/737 values\n",
            "📊 Progress: Updated 570/737 values\n",
            "📊 Progress: Updated 580/737 values\n",
            "📊 Progress: Updated 590/737 values\n",
            "📊 Progress: Updated 600/737 values\n",
            "📊 Progress: Updated 610/737 values\n",
            "📊 Progress: Updated 620/737 values\n",
            "📊 Progress: Updated 630/737 values\n",
            "📊 Progress: Updated 640/737 values\n",
            "⏳ Rate limit hit, waiting for 2.05 seconds (retry 1/5)\n",
            "⏳ Rate limit hit, waiting for 4.59 seconds (retry 2/5)\n",
            "📊 Progress: Updated 650/737 values\n",
            "📊 Progress: Updated 660/737 values\n",
            "📊 Progress: Updated 670/737 values\n",
            "📊 Progress: Updated 680/737 values\n",
            "📊 Progress: Updated 690/737 values\n",
            "📊 Progress: Updated 700/737 values\n",
            "📊 Progress: Updated 710/737 values\n",
            "📊 Progress: Updated 720/737 values\n",
            "📊 Progress: Updated 730/737 values\n",
            "📊 Progress: Updated 740/737 values\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CH_BSIV_CH_MAS_rr: Updated 745 rows in column L and column M\n",
            "📊 Summary: 509 exact matches (normal format), 228 fallback matches (italic and right-aligned)\n",
            "❌ 169 rows could not be updated\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CK_BSVI_CK_MAS_rr\n",
            "🧹 Clearing range L2:M in engine_oil_CK_BSVI_CK_MAS_rr...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 12 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 4 unique bus numbers\n",
            "✅ Found 7 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "📊 Processing bus 613 (3 dates)...\n",
            "  ✅ Found 3/3 values for bus 613\n",
            "📊 Processing bus 612 (2 dates)...\n",
            "  ✅ Found 2/2 values for bus 612\n",
            "📊 Processing bus 610 (1 dates)...\n",
            "  ✅ Found 0/1 values for bus 610\n",
            "📊 Processing bus 614 (1 dates)...\n",
            "  ✅ Found 1/1 values for bus 614\n",
            "\n",
            "✅ Found values for 4 exact date matches\n",
            "✅ Found values for 2 fallback date matches\n",
            "❌ Could not find values for 1 dates\n",
            "\n",
            "📝 Updating values and formatting in engine_oil_CK_BSVI_CK_MAS_rr...\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CK_BSVI_CK_MAS_rr: Updated 6 rows in column L and column M\n",
            "📊 Summary: 4 exact matches (normal format), 2 fallback matches (italic and right-aligned)\n",
            "❌ 1 rows could not be updated\n",
            "\n",
            "✅ All worksheets have been processed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified to process multiple engine oil worksheets SVP CH CK, ATR CH CK, Added batch processing done\n",
        "\n",
        "# Modified to process multiple engine oil worksheets with batch processing\n",
        "# With fallback date display in M Column, For ATR_MAS_Engine Oil\n",
        "\n",
        "# Make sure to include these imports at the top of your code\n",
        "import re\n",
        "from datetime import datetime\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import gspread\n",
        "import math\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# List of all worksheets to process\n",
        "engine_oil_worksheets = [\n",
        "    'engine_oil_CH_BSIV_CH_MAS_ATR',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_ATR',\n",
        "    'engine_oil_CH_BSIV_CH_MAS_rr',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_rr'\n",
        "]\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "# Function to process each worksheet\n",
        "def process_worksheet(worksheet_name):\n",
        "    print(f\"\\n🔄 Processing worksheet: {worksheet_name}\")\n",
        "\n",
        "    # Get the worksheet object\n",
        "    worksheet = None\n",
        "    try:\n",
        "        # Assuming these are defined in your notebook environment\n",
        "        worksheet = eval(worksheet_name)  # This will use the already defined variable in your notebook\n",
        "    except:\n",
        "        print(f\"❌ Error: Worksheet '{worksheet_name}' not found or not accessible\")\n",
        "        return\n",
        "\n",
        "    # Clear data in range L2:M, Odometer value in Engine Oil and Fallback date removal\n",
        "    clear_range = 'L2:M'\n",
        "    print(f\"🧹 Clearing range {clear_range} in {worksheet_name}...\")\n",
        "    worksheet.batch_clear([clear_range])\n",
        "\n",
        "    print(\"🔍 Starting data processing with date fallback search...\")\n",
        "\n",
        "    # 📥 Load main sheet\n",
        "    print(\"📥 Loading worksheet data...\")\n",
        "    main_data = worksheet.get_all_values()\n",
        "    print(f\"✅ Loaded {len(main_data)-1} rows from worksheet\")\n",
        "\n",
        "    # Step 1: Collect unique (bus, date) and row mapping\n",
        "    print(\"🔢 Mapping bus numbers and dates...\")\n",
        "    bus_date_map = defaultdict(set)\n",
        "    row_map = {}  # maps row number → (bus, date)\n",
        "\n",
        "    for i, row in enumerate(main_data[1:], start=2):\n",
        "        try:\n",
        "            date_str = row[1].strip()\n",
        "            bus_num = row[4].strip()\n",
        "            if date_str and bus_num:\n",
        "                bus_date_map[bus_num].add(date_str)\n",
        "                row_map[i] = (bus_num, date_str)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"✅ Found {len(bus_date_map)} unique bus numbers\")\n",
        "    print(f\"✅ Found {len(row_map)} rows to process\")\n",
        "\n",
        "    # Create a cache for worksheet data to avoid redundant fetches\n",
        "    bus_worksheet_cache = {}\n",
        "\n",
        "    # Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "    print(\"\\n🔍 Searching for exact dates or closest earlier dates...\")\n",
        "    bus_date_value_map = {}\n",
        "    match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "    fallback_date_map = {}  # Store the actual fallback date used\n",
        "    success_count = 0\n",
        "    fallback_count = 0\n",
        "\n",
        "    # Function to process a single bus\n",
        "    def process_bus(bus_dates_tuple):\n",
        "        bus, dates = bus_dates_tuple\n",
        "        sheet_success = 0\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            # Check if we already have this bus's data in cache\n",
        "            if bus in bus_worksheet_cache:\n",
        "                sheet_data = bus_worksheet_cache[bus]\n",
        "            else:\n",
        "                # Fetch the bus worksheet data and store in cache\n",
        "                sheet = Odometer_spreadsheet_SVP.worksheet(bus)\n",
        "                sheet_data = sheet.get_all_values()\n",
        "                bus_worksheet_cache[bus] = sheet_data\n",
        "\n",
        "            # Create a dictionary for faster exact date lookups\n",
        "            date_value_lookup = {}\n",
        "            for row in sheet_data[1:]:\n",
        "                try:\n",
        "                    if len(row) > 12:\n",
        "                        date_str_key = row[1].strip()\n",
        "                        date_value_lookup[date_str_key] = row[12]  # Column M\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            for date_str in dates:\n",
        "                # Check for exact match using the lookup dictionary\n",
        "                exact_value = date_value_lookup.get(date_str)\n",
        "\n",
        "                if exact_value:\n",
        "                    results.append((bus, date_str, exact_value, \"exact\", \"\"))\n",
        "                    sheet_success += 1\n",
        "                else:\n",
        "                    # Try to find closest earlier date\n",
        "                    value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                    if value:\n",
        "                        results.append((bus, date_str, value, \"fallback\", fallback_date))\n",
        "                        sheet_success += 1\n",
        "\n",
        "            print(f\"  ✅ Found {sheet_success}/{len(dates)} values for bus {bus}\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Could not process sheet '{bus}': {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    # Process buses in parallel using ThreadPoolExecutor\n",
        "    print(f\"🚀 Processing {len(bus_date_map)} buses in parallel...\")\n",
        "\n",
        "    # Convert to list for ThreadPoolExecutor\n",
        "    bus_dates_list = list(bus_date_map.items())\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    # Adjust max_workers based on your system's capabilities\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        all_results = list(executor.map(process_bus, bus_dates_list))\n",
        "\n",
        "    # Process all results\n",
        "    for bus_results in all_results:\n",
        "        for bus, date_str, value, match_type, fallback_date in bus_results:\n",
        "            bus_date_value_map[(bus, date_str)] = value\n",
        "            match_type_map[(bus, date_str)] = match_type\n",
        "            fallback_date_map[(bus, date_str)] = fallback_date\n",
        "\n",
        "            if match_type == \"exact\":\n",
        "                success_count += 1\n",
        "            else:\n",
        "                fallback_count += 1\n",
        "\n",
        "    print(f\"\\n✅ Found values for {success_count} exact date matches\")\n",
        "    print(f\"✅ Found values for {fallback_count} fallback date matches\")\n",
        "    print(f\"❌ Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "    # Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "    print(f\"\\n📝 Preparing batch updates for {worksheet_name}...\")\n",
        "\n",
        "    # Prepare batch update for all cells at once\n",
        "    batch_updates = []\n",
        "    exact_match_cells = []\n",
        "    fallback_match_cells = []\n",
        "\n",
        "    for row_num, (bus, date_str) in row_map.items():\n",
        "        value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "        fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "\n",
        "        if value:\n",
        "            # Add to batch updates list (row, col, value)\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 12,  # Column L\n",
        "                'value': value\n",
        "            })\n",
        "\n",
        "            # Add fallback date update\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 13,  # Column M\n",
        "                'value': fallback_date\n",
        "            })\n",
        "\n",
        "            # Track which cells need which formatting\n",
        "            match_type = match_type_map.get((bus, date_str))\n",
        "            if match_type == \"exact\":\n",
        "                exact_match_cells.append(f\"L{row_num}\")\n",
        "            elif match_type == \"fallback\":\n",
        "                fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "    print(f\"✅ Prepared {len(batch_updates)} cell updates\")\n",
        "\n",
        "    # Execute batch updates in chunks to avoid rate limits\n",
        "    updated_count = 0\n",
        "    chunk_size = 50  # Adjust based on API limits\n",
        "    chunks = math.ceil(len(batch_updates) / chunk_size)\n",
        "\n",
        "    print(f\"🔄 Executing batch updates in {chunks} chunks...\")\n",
        "\n",
        "    for chunk_index in range(chunks):\n",
        "        start_idx = chunk_index * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, len(batch_updates))\n",
        "        current_chunk = batch_updates[start_idx:end_idx]\n",
        "\n",
        "        max_retries = 5\n",
        "        retry_count = 0\n",
        "        update_successful = False\n",
        "\n",
        "        while not update_successful and retry_count < max_retries:\n",
        "            try:\n",
        "                # Prepare the batch update request\n",
        "                cell_list = []\n",
        "\n",
        "                for update in current_chunk:\n",
        "                    cell = worksheet.cell(update['row'], update['col'])\n",
        "                    cell.value = update['value']\n",
        "                    cell_list.append(cell)\n",
        "\n",
        "                # Execute the batch update\n",
        "                worksheet.update_cells(cell_list, value_input_option='USER_ENTERED')\n",
        "\n",
        "                update_successful = True\n",
        "                updated_count += len(current_chunk) // 2  # Divide by 2 because we have 2 cells per row\n",
        "                print(f\"📊 Progress: Chunk {chunk_index+1}/{chunks} complete - {updated_count}/{len(batch_updates)//2} rows updated\")\n",
        "\n",
        "                # Add a small delay between chunks to avoid rate limits\n",
        "                time.sleep(1)\n",
        "\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                if \"429\" in str(e):\n",
        "                    wait_time = (2 ** retry_count) + random.random()\n",
        "                    print(f\"⏳ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"❌ Failed to update chunk {chunk_index+1}: {e}\")\n",
        "                    break\n",
        "\n",
        "        if not update_successful:\n",
        "            print(f\"❌ Failed to update chunk {chunk_index+1} after {max_retries} retries\")\n",
        "\n",
        "    # Apply formatting in batches (currently commented out)\n",
        "    print(\"\\n🎨 Applying formatting to distinguish match types...\")\n",
        "    # You can uncomment and implement batch formatting logic if needed.\n",
        "\n",
        "    print(f\"\\n✅ COMPLETE for {worksheet_name}: Updated {updated_count} rows in column L and column M\")\n",
        "    print(f\"📊 Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "    print(f\"❌ {len(row_map) - updated_count} rows could not be updated\")\n",
        "\n",
        "# Main execution\n",
        "print(\"🚀 Starting to process all engine oil worksheets...\")\n",
        "\n",
        "# Create a global cache for bus worksheets to reuse across all worksheets\n",
        "global_bus_worksheet_cache = {}\n",
        "\n",
        "# Process each worksheet in sequence\n",
        "for worksheet_name in engine_oil_worksheets:\n",
        "    print(f\"\\n{'='*80}\\n📊 Processing worksheet: {worksheet_name}\\n{'='*80}\")\n",
        "    process_worksheet(worksheet_name)\n",
        "    # Add a delay between worksheets to avoid rate limiting\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\n✅ All worksheets have been processed successfully!\")\n",
        "print(\"💡 Performance Summary:\")\n",
        "print(f\"✓ Processed {len(engine_oil_worksheets)} worksheets with batch processing\")\n",
        "print(f\"✓ Used parallel processing for bus data with ThreadPoolExecutor\")\n",
        "print(f\"✓ Implemented caching to reduce API calls\")\n",
        "print(f\"✓ Used batch updates to minimize API requests\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7POcdIrOaQjU",
        "outputId": "5b8dfdcb-d19d-4ab8-de97-a9713fc59487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting to process all engine oil worksheets...\n",
            "\n",
            "================================================================================\n",
            "📊 Processing worksheet: engine_oil_CH_BSIV_CH_MAS_ATR\n",
            "================================================================================\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CH_BSIV_CH_MAS_ATR\n",
            "🧹 Clearing range L2:M in engine_oil_CH_BSIV_CH_MAS_ATR...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 900 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 39 unique bus numbers\n",
            "✅ Found 320 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "🚀 Processing 39 buses in parallel...\n",
            "❌ Could not process sheet '381': 381\n",
            "❌ Could not process sheet '576': 576\n",
            "❌ Could not process sheet '579': 579\n",
            "  ✅ Found 5/5 values for bus 575\n",
            "❌ Could not process sheet '368': 368\n",
            "  ✅ Found 16/16 values for bus 574\n",
            "  ✅ Found 14/14 values for bus 590\n",
            "  ✅ Found 28/28 values for bus 546\n",
            "❌ Could not process sheet '565': 565\n",
            "❌ Could not process sheet '319': 319\n",
            "❌ Could not process sheet '564': 564\n",
            "❌ Could not process sheet '584': 584\n",
            "  ✅ Found 25/25 values for bus 548\n",
            "  ✅ Found 16/16 values for bus 550\n",
            "❌ Could not process sheet '566': 566\n",
            "❌ Could not process sheet '560': 560\n",
            "  ✅ Found 19/19 values for bus 547\n",
            "  ✅ Found 9/9 values for bus 495\n",
            "  ✅ Found 16/16 values for bus 595\n",
            "❌ Could not process sheet '591': 591\n",
            "❌ Could not process sheet '545': 545\n",
            "❌ Could not process sheet '593': 593\n",
            "❌ Could not process sheet '549': 549\n",
            "  ✅ Found 27/27 values for bus 578\n",
            "❌ Could not process sheet '553': 553\n",
            "❌ Could not process sheet '544': 544\n",
            "❌ Could not process sheet '430': 430\n",
            "  ✅ Found 6/6 values for bus 589\n",
            "  ✅ Found 26/26 values for bus 563\n",
            "  ✅ Found 21/21 values for bus 588\n",
            "  ✅ Found 1/1 values for bus 317\n",
            "  ✅ Found 32/32 values for bus 577\n",
            "❌ Could not process sheet '562': 562\n",
            "❌ Could not process sheet '433': 433\n",
            "❌ Could not process sheet '409': 409\n",
            "❌ Could not process sheet 'Grease Gun': Grease Gun\n",
            "  ✅ Found 1/1 values for bus 474\n",
            "❌ Could not process sheet '557': 557\n",
            "  ✅ Found 10/10 values for bus 587\n",
            "\n",
            "✅ Found values for 65 exact date matches\n",
            "✅ Found values for 207 fallback date matches\n",
            "❌ Could not find values for 48 dates\n",
            "\n",
            "📝 Preparing batch updates for engine_oil_CH_BSIV_CH_MAS_ATR...\n",
            "✅ Prepared 544 cell updates\n",
            "🔄 Executing batch updates in 11 chunks...\n",
            "📊 Progress: Chunk 1/11 complete - 25/272 rows updated\n",
            "📊 Progress: Chunk 2/11 complete - 50/272 rows updated\n",
            "📊 Progress: Chunk 3/11 complete - 75/272 rows updated\n",
            "📊 Progress: Chunk 4/11 complete - 100/272 rows updated\n",
            "📊 Progress: Chunk 5/11 complete - 125/272 rows updated\n",
            "⏳ Rate limit hit, waiting for 2.81 seconds (retry 1/5)\n",
            "⏳ Rate limit hit, waiting for 4.74 seconds (retry 2/5)\n",
            "⏳ Rate limit hit, waiting for 8.40 seconds (retry 3/5)\n",
            "⏳ Rate limit hit, waiting for 16.67 seconds (retry 4/5)\n",
            "📊 Progress: Chunk 6/11 complete - 150/272 rows updated\n",
            "📊 Progress: Chunk 7/11 complete - 175/272 rows updated\n",
            "📊 Progress: Chunk 8/11 complete - 200/272 rows updated\n",
            "📊 Progress: Chunk 9/11 complete - 225/272 rows updated\n",
            "📊 Progress: Chunk 10/11 complete - 250/272 rows updated\n",
            "📊 Progress: Chunk 11/11 complete - 272/272 rows updated\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CH_BSIV_CH_MAS_ATR: Updated 272 rows in column L and column M\n",
            "📊 Summary: 65 exact matches (normal format), 207 fallback matches (italic and right-aligned)\n",
            "❌ 48 rows could not be updated\n",
            "\n",
            "================================================================================\n",
            "📊 Processing worksheet: engine_oil_CK_BSVI_CK_MAS_ATR\n",
            "================================================================================\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CK_BSVI_CK_MAS_ATR\n",
            "🧹 Clearing range L2:M in engine_oil_CK_BSVI_CK_MAS_ATR...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 32 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 8 unique bus numbers\n",
            "✅ Found 22 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "🚀 Processing 8 buses in parallel...\n",
            "❌ Could not process sheet '600': 600\n",
            "  ✅ Found 3/3 values for bus 597\n",
            "  ✅ Found 3/3 values for bus 598\n",
            "  ✅ Found 3/3 values for bus 596\n",
            "  ✅ Found 3/3 values for bus 603\n",
            "  ✅ Found 3/3 values for bus 604\n",
            "  ✅ Found 3/3 values for bus 605\n",
            "  ✅ Found 3/3 values for bus 599\n",
            "\n",
            "✅ Found values for 1 exact date matches\n",
            "✅ Found values for 20 fallback date matches\n",
            "❌ Could not find values for 1 dates\n",
            "\n",
            "📝 Preparing batch updates for engine_oil_CK_BSVI_CK_MAS_ATR...\n",
            "✅ Prepared 42 cell updates\n",
            "🔄 Executing batch updates in 1 chunks...\n",
            "📊 Progress: Chunk 1/1 complete - 21/21 rows updated\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CK_BSVI_CK_MAS_ATR: Updated 21 rows in column L and column M\n",
            "📊 Summary: 1 exact matches (normal format), 20 fallback matches (italic and right-aligned)\n",
            "❌ 1 rows could not be updated\n",
            "\n",
            "================================================================================\n",
            "📊 Processing worksheet: engine_oil_CH_BSIV_CH_MAS_rr\n",
            "================================================================================\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CH_BSIV_CH_MAS_rr\n",
            "🧹 Clearing range L2:M in engine_oil_CH_BSIV_CH_MAS_rr...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 929 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 76 unique bus numbers\n",
            "✅ Found 914 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "🚀 Processing 76 buses in parallel...\n",
            "❌ Could not process sheet '477': 477\n",
            "❌ Could not process sheet '326': 326\n",
            "❌ Could not process sheet '322': 322\n",
            "❌ Could not process sheet '342': 342\n",
            "  ✅ Found 17/17 values for bus 504\n",
            "  ✅ Found 55/55 values for bus 317\n",
            "❌ Could not process sheet '493': 493\n",
            "  ✅ Found 15/15 values for bus 486\n",
            "  ✅ Found 39/39 values for bus 585\n",
            "❌ Could not process sheet '381': 381\n",
            "  ✅ Found 41/41 values for bus 474\n",
            "  ✅ Found 28/28 values for bus 460\n",
            "❌ Could not process sheet '319': 319\n",
            "❌ Could not process sheet '443': 443\n",
            "  ✅ Found 2/2 values for bus 546\n",
            "  ✅ Found 46/46 values for bus 462\n",
            "❌ Could not process sheet '576': 576\n",
            "  ✅ Found 22/22 values for bus 534\n",
            "  ✅ Found 1/1 values for bus 595\n",
            "  ✅ Found 14/14 values for bus 473\n",
            "  ✅ Found 14/14 values for bus 535\n",
            "❌ Could not process sheet '560': 560\n",
            "❌ Could not process sheet 'RCS': RCS\n",
            "  ✅ Found 14/14 values for bus 523\n",
            "  ✅ Found 33/33 values for bus 469\n",
            "  ✅ Found 25/25 values for bus 444\n",
            "  ✅ Found 18/18 values for bus 440\n",
            "  ✅ Found 48/48 values for bus 457\n",
            "  ✅ Found 2/2 values for bus 574\n",
            "  ✅ Found 1/1 values for bus 548\n",
            "  ✅ Found 12/12 values for bus 442\n",
            "  ✅ Found 6/6 values for bus 590\n",
            "❌ Could not process sheet '419': 419\n",
            "  ✅ Found 31/31 values for bus 515\n",
            "❌ Could not process sheet '341': 341\n",
            "  ✅ Found 12/12 values for bus 475\n",
            "  ✅ Found 26/26 values for bus 536\n",
            "  ✅ Found 19/19 values for bus 476\n",
            "  ✅ Found 19/19 values for bus 514\n",
            "❌ Could not process sheet '553': 553\n",
            "  ✅ Found 30/30 values for bus 472\n",
            "  ✅ Found 1/1 values for bus 578\n",
            "  ✅ Found 13/13 values for bus 528\n",
            "  ✅ Found 13/13 values for bus 538\n",
            "❌ Could not process sheet '314': 314\n",
            "  ✅ Found 8/8 values for bus 441\n",
            "❌ Could not process sheet '513': 513\n",
            "  ✅ Found 2/2 values for bus 589\n",
            "  ✅ Found 24/24 values for bus 471\n",
            "❌ Could not process sheet '544': 544\n",
            "❌ Could not process sheet '352': 352\n",
            "❌ Could not process sheet '487': 487\n",
            "  ✅ Found 10/10 values for bus 459\n",
            "  ✅ Found 14/14 values for bus 511\n",
            "❌ Could not process sheet 'ES': ES\n",
            "❌ Could not process sheet '368': 368\n",
            "❌ Could not process sheet '438': 438\n",
            "❌ Could not process sheet 'D.G.SET': D.G.SET\n",
            "❌ Could not process sheet '435': 435\n",
            "❌ Could not process sheet '593': 593\n",
            "  ✅ Found 16/16 values for bus 508\n",
            "  ✅ Found 3/3 values for bus 587\n",
            "❌ Could not process sheet '409': 409\n",
            "  ✅ Found 1/1 values for bus 563\n",
            "  ✅ Found 2/2 values for bus 550\n",
            "  ✅ Found 9/9 values for bus 530\n",
            "  ✅ Found 22/22 values for bus 495\n",
            "❌ Could not process sheet 'AirComp.': AirComp.\n",
            "  ✅ Found 5/5 values for bus 521\n",
            "  ✅ Found 1/1 values for bus 575\n",
            "  ✅ Found 2/2 values for bus 547\n",
            "  ✅ Found 1/1 values for bus 613\n",
            "❌ Could not process sheet '482': 482\n",
            "❌ Could not process sheet '552': 552\n",
            "❌ Could not process sheet '518': 518\n",
            "❌ Could not process sheet 'B/T': B/T\n",
            "\n",
            "✅ Found values for 509 exact date matches\n",
            "✅ Found values for 228 fallback date matches\n",
            "❌ Could not find values for 177 dates\n",
            "\n",
            "📝 Preparing batch updates for engine_oil_CH_BSIV_CH_MAS_rr...\n",
            "✅ Prepared 1490 cell updates\n",
            "🔄 Executing batch updates in 30 chunks...\n",
            "📊 Progress: Chunk 1/30 complete - 25/745 rows updated\n",
            "📊 Progress: Chunk 2/30 complete - 50/745 rows updated\n",
            "📊 Progress: Chunk 3/30 complete - 75/745 rows updated\n",
            "📊 Progress: Chunk 4/30 complete - 100/745 rows updated\n",
            "📊 Progress: Chunk 5/30 complete - 125/745 rows updated\n",
            "📊 Progress: Chunk 6/30 complete - 150/745 rows updated\n",
            "📊 Progress: Chunk 7/30 complete - 175/745 rows updated\n",
            "📊 Progress: Chunk 8/30 complete - 200/745 rows updated\n",
            "📊 Progress: Chunk 9/30 complete - 225/745 rows updated\n",
            "📊 Progress: Chunk 10/30 complete - 250/745 rows updated\n",
            "📊 Progress: Chunk 11/30 complete - 275/745 rows updated\n",
            "📊 Progress: Chunk 12/30 complete - 300/745 rows updated\n",
            "📊 Progress: Chunk 13/30 complete - 325/745 rows updated\n",
            "📊 Progress: Chunk 14/30 complete - 350/745 rows updated\n",
            "📊 Progress: Chunk 15/30 complete - 375/745 rows updated\n",
            "📊 Progress: Chunk 16/30 complete - 400/745 rows updated\n",
            "📊 Progress: Chunk 17/30 complete - 425/745 rows updated\n",
            "📊 Progress: Chunk 18/30 complete - 450/745 rows updated\n",
            "📊 Progress: Chunk 19/30 complete - 475/745 rows updated\n",
            "📊 Progress: Chunk 20/30 complete - 500/745 rows updated\n",
            "📊 Progress: Chunk 21/30 complete - 525/745 rows updated\n",
            "📊 Progress: Chunk 22/30 complete - 550/745 rows updated\n",
            "📊 Progress: Chunk 23/30 complete - 575/745 rows updated\n",
            "📊 Progress: Chunk 24/30 complete - 600/745 rows updated\n",
            "📊 Progress: Chunk 25/30 complete - 625/745 rows updated\n",
            "📊 Progress: Chunk 26/30 complete - 650/745 rows updated\n",
            "⏳ Rate limit hit, waiting for 2.83 seconds (retry 1/5)\n",
            "⏳ Rate limit hit, waiting for 4.45 seconds (retry 2/5)\n",
            "📊 Progress: Chunk 27/30 complete - 675/745 rows updated\n",
            "📊 Progress: Chunk 28/30 complete - 700/745 rows updated\n",
            "📊 Progress: Chunk 29/30 complete - 725/745 rows updated\n",
            "📊 Progress: Chunk 30/30 complete - 745/745 rows updated\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CH_BSIV_CH_MAS_rr: Updated 745 rows in column L and column M\n",
            "📊 Summary: 509 exact matches (normal format), 228 fallback matches (italic and right-aligned)\n",
            "❌ 169 rows could not be updated\n",
            "\n",
            "================================================================================\n",
            "📊 Processing worksheet: engine_oil_CK_BSVI_CK_MAS_rr\n",
            "================================================================================\n",
            "\n",
            "🔄 Processing worksheet: engine_oil_CK_BSVI_CK_MAS_rr\n",
            "🧹 Clearing range L2:M in engine_oil_CK_BSVI_CK_MAS_rr...\n",
            "🔍 Starting data processing with date fallback search...\n",
            "📥 Loading worksheet data...\n",
            "✅ Loaded 12 rows from worksheet\n",
            "🔢 Mapping bus numbers and dates...\n",
            "✅ Found 4 unique bus numbers\n",
            "✅ Found 7 rows to process\n",
            "\n",
            "🔍 Searching for exact dates or closest earlier dates...\n",
            "🚀 Processing 4 buses in parallel...\n",
            "  ✅ Found 3/3 values for bus 613\n",
            "  ✅ Found 2/2 values for bus 612\n",
            "  ✅ Found 1/1 values for bus 614\n",
            "  ✅ Found 0/1 values for bus 610\n",
            "\n",
            "✅ Found values for 4 exact date matches\n",
            "✅ Found values for 2 fallback date matches\n",
            "❌ Could not find values for 1 dates\n",
            "\n",
            "📝 Preparing batch updates for engine_oil_CK_BSVI_CK_MAS_rr...\n",
            "✅ Prepared 12 cell updates\n",
            "🔄 Executing batch updates in 1 chunks...\n",
            "📊 Progress: Chunk 1/1 complete - 6/6 rows updated\n",
            "\n",
            "🎨 Applying formatting to distinguish match types...\n",
            "\n",
            "✅ COMPLETE for engine_oil_CK_BSVI_CK_MAS_rr: Updated 6 rows in column L and column M\n",
            "📊 Summary: 4 exact matches (normal format), 2 fallback matches (italic and right-aligned)\n",
            "❌ 1 rows could not be updated\n",
            "\n",
            "✅ All worksheets have been processed successfully!\n",
            "💡 Performance Summary:\n",
            "✓ Processed 4 worksheets with batch processing\n",
            "✓ Used parallel processing for bus data with ThreadPoolExecutor\n",
            "✓ Implemented caching to reduce API calls\n",
            "✓ Used batch updates to minimize API requests\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAINSyLE1iBlw9UehQinoF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}