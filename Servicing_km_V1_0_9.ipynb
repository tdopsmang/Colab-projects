{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tdopsmang/Colab-projects/blob/main/Servicing_km_V1_0_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Did not work on RR path, rather added bus details upto DP, in consolidated report, also batch processing done in few cases"
      ],
      "metadata": {
        "id": "JVbZ291M-7mv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMKeh0lHx8tS",
        "outputId": "9553b1b2-5f9b-4d3f-d57d-95369469f540",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.32.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2025.4.26)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (4.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.6.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (1.17.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.9.1->oauth2client) (3.2.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (4.1.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gspread\n",
        "!pip install gspread google-auth-oauthlib google-auth-httplib2\n",
        "!pip install gspread google-auth oauth2client\n",
        "!pip install gspread oauth2client pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIVCOLMf4oFc"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "from google.oauth2.service_account import Credentials\n",
        "gc = gspread.authorize(creds)\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import concurrent.futures\n",
        "from functools import lru_cache\n",
        "import math\n",
        "from concurrent.futures import ThreadPoolExecutor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX9vEbLhRZAG"
      },
      "outputs": [],
      "source": [
        "# Details our Database spreadsheet which has details of all files, ID in Transport Department\n",
        "\n",
        "Database_File_spreadsheet_ID = gc.open_by_key('1nJKyvV1WQmZzvbjOP7Hsp1bQJmiNsYoJOH_jIL7H9PI') #ID of Database Spreadsheet\n",
        "MASsheetID = Database_File_spreadsheet_ID.worksheet('MAS')                                    #MAS Worksheet\n",
        "OdometersheetID = Database_File_spreadsheet_ID.worksheet('Odometer')                          #Odometer Worksheet\n",
        "ReportID = Database_File_spreadsheet_ID.worksheet('Report')                          #Odometer Worksheet\n",
        "\n",
        "#Reports spreadsheet and worksheet details\n",
        "Report_EO_SpreadsheetID = ReportID.acell('C2').value                  # Get the spreadsheet ID from cell C2\n",
        "Report_EO = gc.open_by_key(Report_EO_SpreadsheetID)                    # Open RR_Oil_Lub spreadsheet\n",
        "Report_EO1_worksheet_name = ReportID.acell('B2').value                        # Km after last servicing consolidated\n",
        "Report_EO1_Worksheet = Report_EO.worksheet(Report_EO1_worksheet_name)  # Open RR CH engineoil worksheet\n",
        "\n",
        "#STS RR SVP\n",
        "RR_Oil_Lub_Coolant_DEF_spreadsheet_id = MASsheetID.acell('C2').value                  # Get the spreadsheet ID from cell C2\n",
        "RR_Oil_Lub = gc.open_by_key(RR_Oil_Lub_Coolant_DEF_spreadsheet_id)                    # Open RR_Oil_Lub spreadsheet\n",
        "\n",
        "RR_Engine_oil_CH_BSIV_worksheet_name = MASsheetID.acell('B2').value                        # Get the worksheet name from cell B2\n",
        "engine_oil_CH_BSIV_CH_MAS_rr = RR_Oil_Lub.worksheet(RR_Engine_oil_CH_BSIV_worksheet_name)  # Open RR CH engineoil worksheet\n",
        "\n",
        "RR_Engine_oil_CK_BSVI_worksheet_name = MASsheetID.acell('B3').value                        # Get the worksheet name from cell B3\n",
        "engine_oil_CK_BSVI_CK_MAS_rr = RR_Oil_Lub.worksheet(RR_Engine_oil_CK_BSVI_worksheet_name)  # Open RR CK engineoil worksheet\n",
        "\n",
        "RR_Report1_worksheet_name = MASsheetID.acell('B8').value                                # Get the worksheet name from report1, RR Km between and after last servicing\n",
        "RR_Report1_Worksheet = RR_Oil_Lub.worksheet(RR_Report1_worksheet_name)                  # Open RR Km between and after last servicing worksheet\n",
        "\n",
        "RR_Report1_worksheet_name = MASsheetID.acell('B8').value                                # Get the worksheet name from report1, RR Km between and after last servicing\n",
        "RR_Report1_Worksheet = RR_Oil_Lub.worksheet(RR_Report1_worksheet_name)                  # Open RR Km between and after last servicing worksheet\n",
        "\n",
        "#STS ATR SVP\n",
        "ATR_Oil_Lub_Coolant_DEF_spreadsheet_id = MASsheetID.acell('C52').value                  # Get the spreadsheet ID from cell C51 ATR\n",
        "ATR_Oil_Lub = gc.open_by_key(ATR_Oil_Lub_Coolant_DEF_spreadsheet_id)                    # Open ATR_Oil_Lub spreadsheet\n",
        "\n",
        "ATR_Engine_oil_CH_BSIV_worksheet_name = MASsheetID.acell('B52').value                         # Get the worksheet name from cell B52\n",
        "engine_oil_CH_BSIV_CH_MAS_ATR = ATR_Oil_Lub.worksheet(ATR_Engine_oil_CH_BSIV_worksheet_name)  # Open ATR CH engineoil worksheet\n",
        "\n",
        "ATR_Engine_oil_CK_BSVI_worksheet_name = MASsheetID.acell('B53').value                         # Get the worksheet name from cell B52\n",
        "engine_oil_CK_BSVI_CK_MAS_ATR = ATR_Oil_Lub.worksheet(ATR_Engine_oil_CK_BSVI_worksheet_name)  # Open ATR CK engineoil worksheet\n",
        "\n",
        "#ATR_Report1_worksheet_name = MASsheetID.acell('B58').value                           #******This may not be required       # Get the worksheet name from report1, RR Km between and after last servicing\n",
        "#ATR_Report1_Worksheet = ATR_Oil_Lub.worksheet(ATR_Report1_worksheet_name)              #This may not be required     # Open RR Km between and after last servicing worksheet\n",
        "\n",
        "#STS FG\n",
        "FG_Oil_Lub_Coolant_DEF_spreadsheet_id = MASsheetID.acell('C102').value                  # Get the spreadsheet ID from cell C51 ATR\n",
        "FG_Oil_Lub = gc.open_by_key(FG_Oil_Lub_Coolant_DEF_spreadsheet_id)                    # Open ATR_Oil_Lub spreadsheet\n",
        "\n",
        "FG_Engine_oil_CH_BSIV_worksheet_name = MASsheetID.acell('B102').value                         # Get the worksheet name from cell B2\n",
        "engine_oil_CH_BSIV_CH_MAS_FG = FG_Oil_Lub.worksheet(FG_Engine_oil_CH_BSIV_worksheet_name)  # Open RR engineoil worksheet\n",
        "\n",
        "FG_Engine_oil_CK_BSVI_worksheet_name = MASsheetID.acell('B103').value                         # Get the worksheet name from cell B52\n",
        "engine_oil_CK_BSVI_CK_MAS_FG = FG_Oil_Lub.worksheet(FG_Engine_oil_CK_BSVI_worksheet_name)  # Open ATR CK engineoil worksheet\n",
        "\n",
        "#FG_Report1_worksheet_name = MASsheetID.acell('B108').value                    #*****This may not be required            # Get the worksheet name from report1, RR Km between and after last servicing\n",
        "#FG_Report1_Worksheet = FG_Oil_Lub.worksheet(FG_Report1_worksheet_name)          #This may not be required         # Open RR Km between and after last servicing worksheet\n",
        "\n",
        "\n",
        "# Process SVP data\n",
        "SVP_Odometer_id = OdometersheetID.acell('A2').value\n",
        "Odometer_spreadsheet_SVP = gc.open_by_key(SVP_Odometer_id)\n",
        "bus_number_SVP = sorted([worksheet.title for worksheet in Odometer_spreadsheet_SVP])\n",
        "spreadsheet_name_SVP = Odometer_spreadsheet_SVP.title\n",
        "start_row_svp = 2\n",
        "\n",
        "# Process FG data\n",
        "FG_Odometer_id = OdometersheetID.acell('B2').value\n",
        "Odometer_spreadsheet_FG = gc.open_by_key(FG_Odometer_id)\n",
        "bus_number_FG = sorted([worksheet.title for worksheet in Odometer_spreadsheet_FG])\n",
        "spreadsheet_name_FG = Odometer_spreadsheet_FG.title\n",
        "start_row_fg = start_row_svp + len(bus_number_SVP)\n",
        "\n",
        "# Process Baratang data\n",
        "BT_Odometer_id = OdometersheetID.acell('C2').value\n",
        "Odometer_spreadsheet_BT = gc.open_by_key(BT_Odometer_id)\n",
        "bus_number_BT = sorted([worksheet.title for worksheet in Odometer_spreadsheet_BT])\n",
        "spreadsheet_name_BT = Odometer_spreadsheet_BT.title\n",
        "start_row_bt = start_row_fg + len(bus_number_FG)\n",
        "\n",
        "# Process Rangat data\n",
        "RT_Odometer_id = OdometersheetID.acell('D2').value\n",
        "Odometer_spreadsheet_RT = gc.open_by_key(RT_Odometer_id)\n",
        "bus_number_RT = sorted([worksheet.title for worksheet in Odometer_spreadsheet_RT])\n",
        "spreadsheet_name_RT = Odometer_spreadsheet_RT.title\n",
        "start_row_rt = start_row_bt + len(bus_number_BT)\n",
        "\n",
        "# Process Mayabunder data\n",
        "MB_Odometer_id = OdometersheetID.acell('E2').value\n",
        "Odometer_spreadsheet_MB = gc.open_by_key(MB_Odometer_id)\n",
        "bus_number_MB = sorted([worksheet.title for worksheet in Odometer_spreadsheet_MB])\n",
        "spreadsheet_name_MB = Odometer_spreadsheet_MB.title\n",
        "start_row_mb = start_row_rt + len(bus_number_RT)\n",
        "\n",
        "# Process Diglipur data\n",
        "DP_Odometer_id = OdometersheetID.acell('F2').value\n",
        "Odometer_spreadsheet_DP = gc.open_by_key(DP_Odometer_id)\n",
        "bus_number_DP = sorted([worksheet.title for worksheet in Odometer_spreadsheet_DP])\n",
        "spreadsheet_name_DP = Odometer_spreadsheet_DP.title\n",
        "start_row_dp = start_row_mb + len(bus_number_MB)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code for balance km in all Engine oil sheet from Odometer sheets"
      ],
      "metadata": {
        "id": "nVrb1uA9BJ7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lean for all units, improved API limiter, #Lean combined all Units Engine Oil and Search all Odometer, but it search only missing values, if it works, then in future just add engine oil sheet and odometer sheet\n",
        "\n",
        "\n",
        "# Lean version - Only processes rows with empty L column\n",
        "# With fallback date display in M Column, For SVP, FG, BT, RT, MB, and DP\n",
        "\n",
        "import re\n",
        "from datetime import datetime\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import gspread\n",
        "import math\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# List of all worksheets to process\n",
        "engine_oil_worksheets = [\n",
        "    'engine_oil_CH_BSIV_CH_MAS_FG',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_FG',\n",
        "    'engine_oil_CH_BSIV_CH_MAS_ATR',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_ATR',\n",
        "    'engine_oil_CH_BSIV_CH_MAS_rr',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_rr'\n",
        "]\n",
        "\n",
        "# List of all odometer spreadsheets to search\n",
        "odometer_spreadsheets = [\n",
        "    'Odometer_spreadsheet_SVP',\n",
        "    'Odometer_spreadsheet_FG',\n",
        "    'Odometer_spreadsheet_BT',\n",
        "    'Odometer_spreadsheet_RT',\n",
        "    'Odometer_spreadsheet_MB',\n",
        "    'Odometer_spreadsheet_DP'\n",
        "]\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "# Global cache for bus worksheets to reuse across all worksheets and spreadsheets\n",
        "global_bus_worksheet_cache = {}\n",
        "\n",
        "# Function to process each worksheet - LEAN VERSION (only empty L cells)\n",
        "def process_worksheet_lean(worksheet_name):\n",
        "    print(f\"\\nüîÑ Processing worksheet: {worksheet_name}\")\n",
        "\n",
        "    # Get the worksheet object\n",
        "    worksheet = None\n",
        "    try:\n",
        "        # Assuming these are defined in your notebook environment\n",
        "        worksheet = eval(worksheet_name)  # This will use the already defined variable in your notebook\n",
        "    except:\n",
        "        print(f\"‚ùå Error: Worksheet '{worksheet_name}' not found or not accessible\")\n",
        "        return\n",
        "\n",
        "    # NO CLEARING OF RANGES - we're only updating empty cells\n",
        "    print(\"üîç Starting data processing for EMPTY L cells only...\")\n",
        "\n",
        "    # üì• Load main sheet\n",
        "    print(\"üì• Loading worksheet data...\")\n",
        "    main_data = worksheet.get_all_values()\n",
        "    print(f\"‚úÖ Loaded {len(main_data)-1} rows from worksheet\")\n",
        "\n",
        "    # Step 1: Collect unique (bus, date) and row mapping ONLY FOR EMPTY L CELLS\n",
        "    print(\"üî¢ Mapping bus numbers and dates for empty L cells...\")\n",
        "    bus_date_map = defaultdict(set)\n",
        "    row_map = {}  # maps row number ‚Üí (bus, date)\n",
        "    empty_cell_count = 0\n",
        "\n",
        "    for i, row in enumerate(main_data[1:], start=2):\n",
        "        try:\n",
        "            # Check if L column (index 11) is empty\n",
        "            l_value = row[11].strip() if len(row) > 11 else \"\"\n",
        "\n",
        "            if not l_value:  # Only process if L column is empty\n",
        "                date_str = row[1].strip()\n",
        "                bus_num = row[4].strip()\n",
        "                if date_str and bus_num:\n",
        "                    bus_date_map[bus_num].add(date_str)\n",
        "                    row_map[i] = (bus_num, date_str)\n",
        "                    empty_cell_count += 1\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"‚úÖ Found {len(bus_date_map)} unique bus numbers with empty L cells\")\n",
        "    print(f\"‚úÖ Found {empty_cell_count} empty L cells to process\")\n",
        "\n",
        "    # Exit early if no empty cells to process\n",
        "    if empty_cell_count == 0:\n",
        "        print(f\"‚úì No empty L cells to process in {worksheet_name}. Moving to next worksheet.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "    print(\"\\nüîç Searching for exact dates or closest earlier dates...\")\n",
        "    bus_date_value_map = {}\n",
        "    match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "    fallback_date_map = {}  # Store the actual fallback date used\n",
        "    success_count = 0\n",
        "    fallback_count = 0\n",
        "\n",
        "    # Track which spreadsheet contained the match for metadata\n",
        "    spreadsheet_source_map = {}  # Maps (bus, date) to spreadsheet name\n",
        "\n",
        "    # Function to process a single bus across all spreadsheets\n",
        "    def process_bus(bus_dates_tuple):\n",
        "        bus, dates = bus_dates_tuple\n",
        "        sheet_success = 0\n",
        "        results = []\n",
        "        dates_to_process = set(dates)  # Create a copy to safely modify\n",
        "\n",
        "        # Try each spreadsheet in sequence\n",
        "        for spreadsheet_name in odometer_spreadsheets:\n",
        "            if not dates_to_process:  # If all dates have been found, skip further processing\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                # Generate cache key that includes the spreadsheet name\n",
        "                cache_key = f\"{spreadsheet_name}:{bus}\"\n",
        "\n",
        "                # Check if we already have this bus's data in cache\n",
        "                if cache_key in global_bus_worksheet_cache:\n",
        "                    sheet_data = global_bus_worksheet_cache[cache_key]\n",
        "                else:\n",
        "                    # Get the spreadsheet object dynamically\n",
        "                    try:\n",
        "                        spreadsheet = eval(spreadsheet_name)\n",
        "                        # Try to get the worksheet for this bus with retry mechanism\n",
        "                        max_retries = 5\n",
        "                        retry_count = 0\n",
        "                        while retry_count < max_retries:\n",
        "                            try:\n",
        "                                sheet = spreadsheet.worksheet(bus)\n",
        "                                sheet_data = sheet.get_all_values()\n",
        "                                global_bus_worksheet_cache[cache_key] = sheet_data\n",
        "                                break  # Success, exit retry loop\n",
        "                            except gspread.exceptions.APIError as api_error:\n",
        "                                if hasattr(api_error, 'response') and api_error.response.status_code == 429:\n",
        "                                    retry_count += 1\n",
        "                                    wait_time = (2 ** retry_count) + (random.random() * 2)\n",
        "                                    print(f\"‚è≥ Rate limit hit for bus {bus}, waiting {wait_time:.2f}s (retry {retry_count}/{max_retries})\")\n",
        "                                    time.sleep(wait_time)\n",
        "                                    if retry_count == max_retries:\n",
        "                                        print(f\"‚ö†Ô∏è Max retries reached for bus {bus} in {spreadsheet_name}\")\n",
        "                                        raise\n",
        "                                else:\n",
        "                                    # Not a rate limit issue, the worksheet likely doesn't exist\n",
        "                                    raise\n",
        "                            except Exception as e:\n",
        "                                # The worksheet doesn't exist in this spreadsheet\n",
        "                                if \"Worksheet not found\" in str(e) or \"404\" in str(e):\n",
        "                                    print(f\"  ‚ÑπÔ∏è Bus {bus} not found in {spreadsheet_name}\")\n",
        "                                else:\n",
        "                                    print(f\"  ‚ö†Ô∏è Error accessing {bus} in {spreadsheet_name}: {str(e)}\")\n",
        "                                raise\n",
        "                    except Exception:\n",
        "                        # This bus doesn't exist in this spreadsheet or we couldn't access it\n",
        "                        continue\n",
        "\n",
        "                # Process each date for this bus in this spreadsheet\n",
        "                # Create a dictionary for faster exact date lookups\n",
        "                date_value_lookup = {}\n",
        "                for row in sheet_data[1:]:\n",
        "                    try:\n",
        "                        if len(row) > 12:\n",
        "                            date_str_key = row[1].strip()\n",
        "                            date_value_lookup[date_str_key] = row[12]  # Column M\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                dates_found_in_this_sheet = set()\n",
        "\n",
        "                # First try exact matches which are faster to check\n",
        "                for date_str in dates_to_process:\n",
        "                    # Check for exact match using the lookup dictionary\n",
        "                    exact_value = date_value_lookup.get(date_str)\n",
        "                    if exact_value:\n",
        "                        results.append((bus, date_str, exact_value, \"exact\", \"\", spreadsheet_name))\n",
        "                        sheet_success += 1\n",
        "                        dates_found_in_this_sheet.add(date_str)\n",
        "\n",
        "                # Then try fallback matches for remaining dates\n",
        "                remaining_dates = dates_to_process - dates_found_in_this_sheet\n",
        "                for date_str in remaining_dates:\n",
        "                    # Try to find closest earlier date\n",
        "                    value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                    if value:\n",
        "                        results.append((bus, date_str, value, \"fallback\", fallback_date, spreadsheet_name))\n",
        "                        sheet_success += 1\n",
        "                        dates_found_in_this_sheet.add(date_str)\n",
        "\n",
        "                # Remove all processed dates\n",
        "                dates_to_process -= dates_found_in_this_sheet\n",
        "\n",
        "            except Exception as e:\n",
        "                if \"Worksheet not found\" not in str(e) and \"404\" not in str(e):\n",
        "                    print(f\"‚ùå Could not process sheet '{bus}' in spreadsheet '{spreadsheet_name}': {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        if sheet_success > 0:\n",
        "            print(f\"  ‚úÖ Found {sheet_success} values for bus {bus}\")\n",
        "        else:\n",
        "            print(f\"  ‚ö†Ô∏è No values found for bus {bus} in any spreadsheet\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    # Only process if we have buses to check\n",
        "    if len(bus_date_map) > 0:\n",
        "        # Convert to list for ThreadPoolExecutor\n",
        "        bus_dates_list = list(bus_date_map.items())\n",
        "\n",
        "        # Use ThreadPoolExecutor for parallel processing\n",
        "        max_workers = min(5, len(bus_dates_list))  # Adjust based on data size\n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            all_results = list(executor.map(process_bus, bus_dates_list))\n",
        "\n",
        "        # Process all results\n",
        "        for bus_results in all_results:\n",
        "            for bus, date_str, value, match_type, fallback_date, source_spreadsheet in bus_results:\n",
        "                bus_date_value_map[(bus, date_str)] = value\n",
        "                match_type_map[(bus, date_str)] = match_type\n",
        "                fallback_date_map[(bus, date_str)] = fallback_date\n",
        "                spreadsheet_source_map[(bus, date_str)] = source_spreadsheet\n",
        "\n",
        "                if match_type == \"exact\":\n",
        "                    success_count += 1\n",
        "                else:\n",
        "                    fallback_count += 1\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No buses to process - all L cells have values already\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Found values for {success_count} exact date matches\")\n",
        "    print(f\"‚úÖ Found values for {fallback_count} fallback date matches\")\n",
        "    print(f\"‚ùå Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "    # Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "    print(f\"\\nüìù Preparing batch updates for {worksheet_name}...\")\n",
        "\n",
        "    # Prepare batch update for all cells at once\n",
        "    batch_updates = []\n",
        "    exact_match_cells = []\n",
        "    fallback_match_cells = []\n",
        "\n",
        "    for row_num, (bus, date_str) in row_map.items():\n",
        "        value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "        fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "        spreadsheet_source = spreadsheet_source_map.get((bus, date_str), \"\")\n",
        "\n",
        "        if value:\n",
        "            # Add to batch updates list (row, col, value)\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 12,  # Column L\n",
        "                'value': value\n",
        "            })\n",
        "\n",
        "            # Add fallback date update\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 13,  # Column M\n",
        "                'value': fallback_date if fallback_date else \"\"\n",
        "            })\n",
        "\n",
        "            # Add source spreadsheet info in Column N for tracking\n",
        "     #       batch_updates.append({\n",
        "      #          'row': row_num,\n",
        "      #          'col': 14,  # Column N\n",
        "      #          'value': spreadsheet_source\n",
        "      #      })\n",
        "\n",
        "            # Track which cells need which formatting\n",
        "            match_type = match_type_map.get((bus, date_str))\n",
        "            if match_type == \"exact\":\n",
        "                exact_match_cells.append(f\"L{row_num}\")\n",
        "            elif match_type == \"fallback\":\n",
        "                fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "    print(f\"‚úÖ Prepared {len(batch_updates)} cell updates\")\n",
        "\n",
        "    # Skip if no updates needed\n",
        "    if len(batch_updates) == 0:\n",
        "        print(\"‚úì No updates needed for this worksheet\")\n",
        "        return\n",
        "\n",
        "    # Execute batch updates in chunks to avoid rate limits\n",
        "    updated_count = 0\n",
        "    chunk_size = 25  # Reduced chunk size to avoid API limits\n",
        "    chunks = math.ceil(len(batch_updates) / chunk_size)\n",
        "\n",
        "    print(f\"üîÑ Executing batch updates in {chunks} chunks...\")\n",
        "\n",
        "    for chunk_index in range(chunks):\n",
        "        start_idx = chunk_index * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, len(batch_updates))\n",
        "        current_chunk = batch_updates[start_idx:end_idx]\n",
        "\n",
        "        max_retries = 8  # Increased retries\n",
        "        retry_count = 0\n",
        "        update_successful = False\n",
        "\n",
        "        while not update_successful and retry_count < max_retries:\n",
        "            try:\n",
        "                # Prepare the batch update request\n",
        "                cell_list = []\n",
        "\n",
        "                for update in current_chunk:\n",
        "                    cell = worksheet.cell(update['row'], update['col'])\n",
        "                    cell.value = update['value']\n",
        "                    cell_list.append(cell)\n",
        "\n",
        "                # Execute the batch update using our rate-limited function\n",
        "                def do_update():\n",
        "                    return worksheet.update_cells(cell_list, value_input_option='USER_ENTERED')\n",
        "\n",
        "                rate_limited_request(do_update)\n",
        "\n",
        "                update_successful = True\n",
        "                updated_count += len(current_chunk) // 3  # Divide by 3 because we have 3 cells per row (L, M, N)\n",
        "                print(f\"üìä Progress: Chunk {chunk_index+1}/{chunks} complete - {updated_count}/{len(batch_updates)//3} rows updated\")\n",
        "\n",
        "                # Add a variable delay between chunks to avoid rate limits\n",
        "                # More aggressive backoff with increasing chunk index\n",
        "                wait_time = 2 + (chunk_index % 3) + (random.random() * 3)\n",
        "                print(f\"‚è≥ Waiting {wait_time:.2f}s before next chunk...\")\n",
        "                time.sleep(wait_time)\n",
        "\n",
        "            except gspread.exceptions.APIError as api_error:\n",
        "                retry_count += 1\n",
        "                if hasattr(api_error, 'response') and api_error.response.status_code == 429:\n",
        "                    # Exponential backoff with jitter for rate limits\n",
        "                    wait_time = (2 ** retry_count) + (random.random() * 5)\n",
        "                    # Cap maximum wait time at 2 minutes\n",
        "                    wait_time = min(wait_time, 120)\n",
        "                    print(f\"‚è≥ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"‚ùå API Error on chunk {chunk_index+1}: {api_error}\")\n",
        "                    if retry_count < 3:  # Only retry a few times for non-rate-limit errors\n",
        "                        time.sleep(5)\n",
        "                    else:\n",
        "                        break\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                print(f\"‚ùå Failed to update chunk {chunk_index+1}: {e}\")\n",
        "                if retry_count < 3:  # Only retry a few times for general errors\n",
        "                    time.sleep(5)\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "        if not update_successful:\n",
        "            print(f\"‚ùå Failed to update chunk {chunk_index+1} after {max_retries} retries\")\n",
        "            # Add extra delay when a chunk completely fails before moving to next chunk\n",
        "            wait_time = 15 + (random.random() * 10)\n",
        "            print(f\"‚è≥ Taking a longer break: {wait_time:.2f}s before continuing...\")\n",
        "            time.sleep(wait_time)\n",
        "\n",
        "    # Apply formatting in batches (currently commented out)\n",
        "    print(\"\\nüé® Applying formatting to distinguish match types...\")\n",
        "    # You can uncomment and implement batch formatting logic if needed.\n",
        "\n",
        "    print(f\"\\n‚úÖ COMPLETE for {worksheet_name}: Updated {updated_count} rows in columns L, M, and N\")\n",
        "    print(f\"üìä Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "    print(f\"‚ùå {len(row_map) - updated_count} rows could not be updated\")\n",
        "\n",
        "# Global rate limiting function\n",
        "def rate_limited_request(func, *args, **kwargs):\n",
        "    \"\"\"Execute a function with rate limiting and retries for API errors\"\"\"\n",
        "    max_retries = 8  # More retries for critical operations\n",
        "    retry_count = 0\n",
        "    base_wait_time = 2  # seconds\n",
        "\n",
        "    while retry_count < max_retries:\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except gspread.exceptions.APIError as api_error:\n",
        "            if hasattr(api_error, 'response') and api_error.response.status_code == 429:\n",
        "                retry_count += 1\n",
        "                # Exponential backoff with jitter\n",
        "                wait_time = (base_wait_time ** retry_count) + (random.random() * 5)\n",
        "                # Cap the wait time at 3 minutes\n",
        "                wait_time = min(wait_time, 180)\n",
        "                print(f\"‚è≥ Rate limit hit! Waiting {wait_time:.2f}s (retry {retry_count}/{max_retries})\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                # Re-raise non-rate-limit errors\n",
        "                raise\n",
        "        except Exception as e:\n",
        "            # For other exceptions, retry a few times but with less patience\n",
        "            if retry_count < 3:\n",
        "                retry_count += 1\n",
        "                wait_time = base_wait_time + (random.random() * 2)\n",
        "                print(f\"‚ö†Ô∏è Error occurred: {str(e)}\")\n",
        "                print(f\"Retrying in {wait_time:.2f}s (retry {retry_count}/3)\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    # If we've exhausted all retries\n",
        "    raise Exception(f\"Failed after {max_retries} retries due to persistent rate limiting\")\n",
        "\n",
        "# Main execution - LEAN VERSION with improved rate limiting\n",
        "print(\"üöÄ Starting LEAN processing - only empty L cells...\")\n",
        "print(f\"üîç Will search across {len(odometer_spreadsheets)} odometer spreadsheets: {', '.join(odometer_spreadsheets)}\")\n",
        "\n",
        "# Process each worksheet with rate limiting and proper delays\n",
        "for i, worksheet_name in enumerate(engine_oil_worksheets):\n",
        "    print(f\"\\n{'='*80}\\nüìä Processing worksheet: {worksheet_name} ({i+1}/{len(engine_oil_worksheets)})\\n{'='*80}\")\n",
        "\n",
        "    # Add a longer delay between worksheets to avoid rate limiting\n",
        "    if i > 0:\n",
        "        wait_time = 5 + (random.random() * 5)  # 5-10 second delay between worksheets\n",
        "        print(f\"‚è≥ Waiting {wait_time:.2f}s before processing next worksheet...\")\n",
        "        time.sleep(wait_time)\n",
        "\n",
        "    # Process the worksheet with proper rate limiting\n",
        "    try:\n",
        "        process_worksheet_lean(worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing worksheet {worksheet_name}: {str(e)}\")\n",
        "        print(\"Continuing with next worksheet after a delay...\")\n",
        "        time.sleep(15)  # Longer delay after an error\n",
        "\n",
        "print(\"\\n‚úÖ All worksheets have been processed successfully!\")\n",
        "print(\"üí° Performance Summary:\")\n",
        "print(f\"‚úì Processed {len(engine_oil_worksheets)} worksheets with LEAN mode (empty L cells only)\")\n",
        "print(f\"‚úì Searched across {len(odometer_spreadsheets)} odometer spreadsheets\")\n",
        "print(f\"‚úì Used parallel processing for bus data with ThreadPoolExecutor\")\n",
        "print(f\"‚úì Implemented caching to reduce API calls\")\n",
        "print(f\"‚úì Used batch updates to minimize API requests\")\n",
        "\n"
      ],
      "metadata": {
        "id": "azCz95R7KQK9",
        "outputId": "40224c2b-8f8c-4a51-e550-ab4590a6a52d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting LEAN processing - only empty L cells...\n",
            "üîç Will search across 6 odometer spreadsheets: Odometer_spreadsheet_SVP, Odometer_spreadsheet_FG, Odometer_spreadsheet_BT, Odometer_spreadsheet_RT, Odometer_spreadsheet_MB, Odometer_spreadsheet_DP\n",
            "\n",
            "================================================================================\n",
            "üìä Processing worksheet: engine_oil_CH_BSIV_CH_MAS_FG (1/6)\n",
            "================================================================================\n",
            "\n",
            "üîÑ Processing worksheet: engine_oil_CH_BSIV_CH_MAS_FG\n",
            "üîç Starting data processing for EMPTY L cells only...\n",
            "üì• Loading worksheet data...\n",
            "‚úÖ Loaded 1005 rows from worksheet\n",
            "üî¢ Mapping bus numbers and dates for empty L cells...\n",
            "‚úÖ Found 21 unique bus numbers with empty L cells\n",
            "‚úÖ Found 486 empty L cells to process\n",
            "\n",
            "üîç Searching for exact dates or closest earlier dates...\n",
            "  ‚ö†Ô∏è Error accessing 388 in Odometer_spreadsheet_SVP: 388\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_SVP: 419\n",
            "  ‚ö†Ô∏è Error accessing 415 in Odometer_spreadsheet_SVP: 415\n",
            "  ‚ö†Ô∏è Error accessing tyreplant in Odometer_spreadsheet_SVP: tyreplant\n",
            "  ‚ö†Ô∏è Error accessing 389 in Odometer_spreadsheet_SVP: 389\n",
            "  ‚ö†Ô∏è Error accessing tyreplant in Odometer_spreadsheet_FG: tyreplant\n",
            "  ‚ö†Ô∏è Error accessing tyreplant in Odometer_spreadsheet_BT: tyreplant\n",
            "  ‚ö†Ô∏è Error accessing 388 in Odometer_spreadsheet_FG: 388\n",
            "  ‚ö†Ô∏è Error accessing tyreplant in Odometer_spreadsheet_RT: tyreplant\n",
            "  ‚ö†Ô∏è Error accessing 389 in Odometer_spreadsheet_FG: 389\n",
            "  ‚ö†Ô∏è Error accessing 388 in Odometer_spreadsheet_BT: 388\n",
            "  ‚ö†Ô∏è Error accessing 388 in Odometer_spreadsheet_RT: 388\n",
            "  ‚ö†Ô∏è Error accessing tyreplant in Odometer_spreadsheet_MB: tyreplant\n",
            "  ‚ö†Ô∏è Error accessing 389 in Odometer_spreadsheet_BT: 389\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_FG: 419\n",
            "  ‚ö†Ô∏è Error accessing 415 in Odometer_spreadsheet_FG: 415\n",
            "  ‚ö†Ô∏è Error accessing 389 in Odometer_spreadsheet_RT: 389\n",
            "  ‚ö†Ô∏è Error accessing 388 in Odometer_spreadsheet_MB: 388\n",
            "  ‚ö†Ô∏è Error accessing tyreplant in Odometer_spreadsheet_DP: tyreplant\n",
            "  ‚ö†Ô∏è No values found for bus tyreplant in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_BT: 419\n",
            "  ‚ö†Ô∏è Error accessing 415 in Odometer_spreadsheet_BT: 415\n",
            "  ‚ö†Ô∏è Error accessing 389 in Odometer_spreadsheet_MB: 389\n",
            "  ‚ö†Ô∏è Error accessing 388 in Odometer_spreadsheet_DP: 388\n",
            "  ‚ö†Ô∏è No values found for bus 388 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_RT: 419\n",
            "  ‚ö†Ô∏è Error accessing 389 in Odometer_spreadsheet_DP: 389\n",
            "  ‚ö†Ô∏è No values found for bus 389 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 415 in Odometer_spreadsheet_RT: 415\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_MB: 419\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_SVP: 435\n",
            "  ‚ö†Ô∏è Error accessing 415 in Odometer_spreadsheet_MB: 415\n",
            "  ‚ö†Ô∏è Error accessing workshop in Odometer_spreadsheet_SVP: workshop\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_DP: 419\n",
            "  ‚ö†Ô∏è No values found for bus 419 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 370 in Odometer_spreadsheet_SVP: 370\n",
            "  ‚ö†Ô∏è Error accessing 415 in Odometer_spreadsheet_DP: 415\n",
            "  ‚ö†Ô∏è No values found for bus 415 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 386 in Odometer_spreadsheet_SVP: 386\n",
            "  ‚ö†Ô∏è Error accessing 328 in Odometer_spreadsheet_SVP: 328\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_FG: 435\n",
            "  ‚ö†Ô∏è Error accessing 370 in Odometer_spreadsheet_FG: 370\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_BT: 435\n",
            "  ‚ö†Ô∏è Error accessing 370 in Odometer_spreadsheet_BT: 370\n",
            "  ‚ö†Ô∏è Error accessing workshop in Odometer_spreadsheet_FG: workshop\n",
            "  ‚ö†Ô∏è Error accessing 370 in Odometer_spreadsheet_RT: 370\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_RT: 435\n",
            "  ‚ö†Ô∏è Error accessing workshop in Odometer_spreadsheet_BT: workshop\n",
            "  ‚ö†Ô∏è Error accessing 386 in Odometer_spreadsheet_FG: 386\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_MB: 435\n",
            "  ‚ö†Ô∏è Error accessing workshop in Odometer_spreadsheet_RT: workshop\n",
            "  ‚ö†Ô∏è Error accessing 370 in Odometer_spreadsheet_MB: 370\n",
            "  ‚ö†Ô∏è Error accessing 386 in Odometer_spreadsheet_BT: 386\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_DP: 435\n",
            "  ‚ö†Ô∏è No values found for bus 435 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing workshop in Odometer_spreadsheet_MB: workshop\n",
            "  ‚ö†Ô∏è Error accessing 328 in Odometer_spreadsheet_FG: 328\n",
            "  ‚ö†Ô∏è Error accessing 370 in Odometer_spreadsheet_DP: 370\n",
            "  ‚ö†Ô∏è No values found for bus 370 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 386 in Odometer_spreadsheet_RT: 386\n",
            "  ‚ö†Ô∏è Error accessing workshop in Odometer_spreadsheet_DP: workshop\n",
            "  ‚ö†Ô∏è No values found for bus workshop in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 328 in Odometer_spreadsheet_BT: 328\n",
            "  ‚ö†Ô∏è Error accessing 386 in Odometer_spreadsheet_MB: 386\n",
            "  ‚ö†Ô∏è Error accessing 328 in Odometer_spreadsheet_RT: 328\n",
            "  ‚ö†Ô∏è Error accessing 386 in Odometer_spreadsheet_DP: 386\n",
            "  ‚ö†Ô∏è No values found for bus 386 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 202 in Odometer_spreadsheet_SVP: 202\n",
            "  ‚ö†Ô∏è Error accessing 328 in Odometer_spreadsheet_MB: 328\n",
            "  ‚ö†Ô∏è Error accessing 436 in Odometer_spreadsheet_SVP: 436\n",
            "  ‚ö†Ô∏è Error accessing 328 in Odometer_spreadsheet_DP: 328\n",
            "  ‚ö†Ô∏è No values found for bus 328 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 344 in Odometer_spreadsheet_SVP: 344\n",
            "  ‚ö†Ô∏è Error accessing 350 in Odometer_spreadsheet_SVP: 350\n",
            "  ‚ö†Ô∏è Error accessing tyre plant in Odometer_spreadsheet_SVP: tyre plant\n",
            "  ‚ö†Ô∏è Error accessing 202 in Odometer_spreadsheet_FG: 202\n",
            "  ‚ö†Ô∏è Error accessing 350 in Odometer_spreadsheet_FG: 350\n",
            "  ‚ö†Ô∏è Error accessing 202 in Odometer_spreadsheet_BT: 202\n",
            "  ‚ö†Ô∏è Error accessing 350 in Odometer_spreadsheet_BT: 350\n",
            "  ‚ö†Ô∏è Error accessing 436 in Odometer_spreadsheet_FG: 436\n",
            "  ‚ö†Ô∏è Error accessing 202 in Odometer_spreadsheet_RT: 202\n",
            "  ‚ö†Ô∏è Error accessing 350 in Odometer_spreadsheet_RT: 350\n",
            "  ‚ö†Ô∏è Error accessing tyre plant in Odometer_spreadsheet_FG: tyre plant\n",
            "  ‚ö†Ô∏è Error accessing 436 in Odometer_spreadsheet_BT: 436\n",
            "  ‚ö†Ô∏è Error accessing 202 in Odometer_spreadsheet_MB: 202\n",
            "  ‚ö†Ô∏è Error accessing tyre plant in Odometer_spreadsheet_BT: tyre plant\n",
            "  ‚ö†Ô∏è Error accessing 344 in Odometer_spreadsheet_FG: 344\n",
            "  ‚ö†Ô∏è Error accessing 350 in Odometer_spreadsheet_MB: 350\n",
            "  ‚ö†Ô∏è Error accessing 436 in Odometer_spreadsheet_RT: 436\n",
            "  ‚ö†Ô∏è Error accessing 202 in Odometer_spreadsheet_DP: 202\n",
            "  ‚ö†Ô∏è No values found for bus 202 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing tyre plant in Odometer_spreadsheet_RT: tyre plant\n",
            "  ‚ö†Ô∏è Error accessing 350 in Odometer_spreadsheet_DP: 350\n",
            "  ‚ö†Ô∏è No values found for bus 350 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 436 in Odometer_spreadsheet_MB: 436\n",
            "  ‚ö†Ô∏è Error accessing tyre plant in Odometer_spreadsheet_MB: tyre plant\n",
            "  ‚ö†Ô∏è Error accessing 436 in Odometer_spreadsheet_DP: 436\n",
            "  ‚ö†Ô∏è No values found for bus 436 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 378 in Odometer_spreadsheet_SVP: 378\n",
            "  ‚ö†Ô∏è Error accessing tyre plant in Odometer_spreadsheet_DP: tyre plant\n",
            "  ‚ö†Ô∏è No values found for bus tyre plant in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing Tyre Plant in Odometer_spreadsheet_SVP: Tyre Plant\n",
            "  ‚ö†Ô∏è Error accessing 572 in Odometer_spreadsheet_SVP: 572\n",
            "  ‚ö†Ô∏è Error accessing 378 in Odometer_spreadsheet_FG: 378\n",
            "  ‚ö†Ô∏è Error accessing others in Odometer_spreadsheet_SVP: others\n",
            "  ‚ö†Ô∏è Error accessing Tyre Plant in Odometer_spreadsheet_FG: Tyre Plant\n",
            "  ‚ö†Ô∏è Error accessing others in Odometer_spreadsheet_FG: others\n",
            "  ‚ö†Ô∏è Error accessing Tyre Plant in Odometer_spreadsheet_BT: Tyre Plant\n",
            "  ‚ö†Ô∏è Error accessing 344 in Odometer_spreadsheet_BT: 344\n",
            "  ‚ö†Ô∏è Error accessing 378 in Odometer_spreadsheet_BT: 378\n",
            "  ‚ö†Ô∏è Error accessing others in Odometer_spreadsheet_BT: others\n",
            "  ‚ö†Ô∏è Error accessing 344 in Odometer_spreadsheet_RT: 344\n",
            "  ‚ö†Ô∏è Error accessing 378 in Odometer_spreadsheet_RT: 378\n",
            "  ‚ö†Ô∏è Error accessing others in Odometer_spreadsheet_RT: others\n",
            "  ‚ö†Ô∏è Error accessing Tyre Plant in Odometer_spreadsheet_RT: Tyre Plant\n",
            "  ‚ö†Ô∏è Error accessing 344 in Odometer_spreadsheet_MB: 344\n",
            "  ‚ö†Ô∏è Error accessing 378 in Odometer_spreadsheet_MB: 378\n",
            "  ‚ö†Ô∏è Error accessing Tyre Plant in Odometer_spreadsheet_MB: Tyre Plant\n",
            "  ‚ö†Ô∏è Error accessing others in Odometer_spreadsheet_MB: others\n",
            "  ‚ö†Ô∏è Error accessing 572 in Odometer_spreadsheet_BT: 572\n",
            "  ‚ö†Ô∏è Error accessing 378 in Odometer_spreadsheet_DP: 378\n",
            "  ‚ö†Ô∏è No values found for bus 378 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing Tyre Plant in Odometer_spreadsheet_DP: Tyre Plant\n",
            "  ‚ö†Ô∏è No values found for bus Tyre Plant in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 344 in Odometer_spreadsheet_DP: 344\n",
            "  ‚ö†Ô∏è No values found for bus 344 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing others in Odometer_spreadsheet_DP: others\n",
            "  ‚ö†Ô∏è No values found for bus others in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 572 in Odometer_spreadsheet_RT: 572\n",
            "  ‚ö†Ô∏è Error accessing TYRE PLANT in Odometer_spreadsheet_SVP: TYRE PLANT\n",
            "  ‚ö†Ô∏è Error accessing 572 in Odometer_spreadsheet_MB: 572\n",
            "  ‚ö†Ô∏è Error accessing OTHER in Odometer_spreadsheet_SVP: OTHER\n",
            "  ‚ö†Ô∏è Error accessing 572 in Odometer_spreadsheet_DP: 572\n",
            "  ‚ö†Ô∏è No values found for bus 572 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing OTHER in Odometer_spreadsheet_FG: OTHER\n",
            "  ‚ö†Ô∏è Error accessing OTHER in Odometer_spreadsheet_BT: OTHER\n",
            "  ‚ö†Ô∏è Error accessing OTHER in Odometer_spreadsheet_RT: OTHER\n",
            "  ‚ö†Ô∏è Error accessing TYRE PLANT in Odometer_spreadsheet_FG: TYRE PLANT\n",
            "  ‚ö†Ô∏è Error accessing OTHER in Odometer_spreadsheet_MB: OTHER\n",
            "  ‚ö†Ô∏è Error accessing TYRE PLANT in Odometer_spreadsheet_BT: TYRE PLANT\n",
            "  ‚ö†Ô∏è Error accessing OTHER in Odometer_spreadsheet_DP: OTHER\n",
            "  ‚ö†Ô∏è No values found for bus OTHER in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing TYRE PLANT in Odometer_spreadsheet_RT: TYRE PLANT\n",
            "  ‚ö†Ô∏è Error accessing TYRE PLANT in Odometer_spreadsheet_MB: TYRE PLANT\n",
            "  ‚ö†Ô∏è Error accessing TYRE PLANT in Odometer_spreadsheet_DP: TYRE PLANT\n",
            "  ‚ö†Ô∏è No values found for bus TYRE PLANT in any spreadsheet\n",
            "\n",
            "‚úÖ Found values for 0 exact date matches\n",
            "‚úÖ Found values for 0 fallback date matches\n",
            "‚ùå Could not find values for 486 dates\n",
            "\n",
            "üìù Preparing batch updates for engine_oil_CH_BSIV_CH_MAS_FG...\n",
            "‚úÖ Prepared 0 cell updates\n",
            "‚úì No updates needed for this worksheet\n",
            "\n",
            "================================================================================\n",
            "üìä Processing worksheet: engine_oil_CK_BSVI_CK_MAS_FG (2/6)\n",
            "================================================================================\n",
            "‚è≥ Waiting 8.48s before processing next worksheet...\n",
            "\n",
            "üîÑ Processing worksheet: engine_oil_CK_BSVI_CK_MAS_FG\n",
            "üîç Starting data processing for EMPTY L cells only...\n",
            "üì• Loading worksheet data...\n",
            "‚úÖ Loaded 7 rows from worksheet\n",
            "üî¢ Mapping bus numbers and dates for empty L cells...\n",
            "‚úÖ Found 0 unique bus numbers with empty L cells\n",
            "‚úÖ Found 0 empty L cells to process\n",
            "‚úì No empty L cells to process in engine_oil_CK_BSVI_CK_MAS_FG. Moving to next worksheet.\n",
            "\n",
            "================================================================================\n",
            "üìä Processing worksheet: engine_oil_CH_BSIV_CH_MAS_ATR (3/6)\n",
            "================================================================================\n",
            "‚è≥ Waiting 7.27s before processing next worksheet...\n",
            "\n",
            "üîÑ Processing worksheet: engine_oil_CH_BSIV_CH_MAS_ATR\n",
            "üîç Starting data processing for EMPTY L cells only...\n",
            "üì• Loading worksheet data...\n",
            "‚úÖ Loaded 900 rows from worksheet\n",
            "üî¢ Mapping bus numbers and dates for empty L cells...\n",
            "‚úÖ Found 19 unique bus numbers with empty L cells\n",
            "‚úÖ Found 42 empty L cells to process\n",
            "\n",
            "üîç Searching for exact dates or closest earlier dates...\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_SVP: 381\n",
            "  ‚ö†Ô∏è Error accessing 579 in Odometer_spreadsheet_SVP: 579\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_SVP: 368\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_FG: 381\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_SVP: 576\n",
            "  ‚ö†Ô∏è Error accessing 579 in Odometer_spreadsheet_FG: 579\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_BT: 381\n",
            "  ‚ö†Ô∏è Error accessing 565 in Odometer_spreadsheet_SVP: 565\n",
            "  ‚ö†Ô∏è Error accessing 579 in Odometer_spreadsheet_BT: 579\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_RT: 381\n",
            "  ‚ö†Ô∏è Error accessing 579 in Odometer_spreadsheet_RT: 579\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_MB: 381\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_FG: 368\n",
            "  ‚ö†Ô∏è Error accessing 579 in Odometer_spreadsheet_MB: 579\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_DP: 381\n",
            "  ‚ö†Ô∏è No values found for bus 381 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_FG: 576\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_BT: 368\n",
            "  ‚ö†Ô∏è Error accessing 579 in Odometer_spreadsheet_DP: 579\n",
            "  ‚ö†Ô∏è No values found for bus 579 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 565 in Odometer_spreadsheet_FG: 565\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_BT: 576\n",
            "  ‚ö†Ô∏è Error accessing 565 in Odometer_spreadsheet_BT: 565\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_RT: 368\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_SVP: 319\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_RT: 576\n",
            "  ‚ö†Ô∏è Error accessing 566 in Odometer_spreadsheet_SVP: 566\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_MB: 576\n",
            "  ‚ö†Ô∏è Error accessing 565 in Odometer_spreadsheet_RT: 565\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_MB: 368\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_FG: 319\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_DP: 576\n",
            "  ‚ö†Ô∏è No values found for bus 576 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 565 in Odometer_spreadsheet_MB: 565\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_BT: 319\n",
            "  ‚ö†Ô∏è Error accessing 566 in Odometer_spreadsheet_FG: 566\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_DP: 368\n",
            "  ‚ö†Ô∏è No values found for bus 368 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_RT: 319\n",
            "  ‚ö†Ô∏è Error accessing 566 in Odometer_spreadsheet_BT: 566\n",
            "  ‚ö†Ô∏è Error accessing 565 in Odometer_spreadsheet_DP: 565\n",
            "  ‚ö†Ô∏è No values found for bus 565 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_MB: 319\n",
            "  ‚ö†Ô∏è Error accessing 566 in Odometer_spreadsheet_RT: 566\n",
            "  ‚ö†Ô∏è Error accessing 591 in Odometer_spreadsheet_SVP: 591\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_DP: 319\n",
            "  ‚ö†Ô∏è No values found for bus 319 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 566 in Odometer_spreadsheet_MB: 566\n",
            "  ‚ö†Ô∏è Error accessing 545 in Odometer_spreadsheet_SVP: 545\n",
            "  ‚ö†Ô∏è Error accessing 566 in Odometer_spreadsheet_DP: 566\n",
            "  ‚ö†Ô∏è No values found for bus 566 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 591 in Odometer_spreadsheet_FG: 591\n",
            "  ‚ö†Ô∏è Error accessing 591 in Odometer_spreadsheet_BT: 591\n",
            "  ‚ö†Ô∏è Error accessing 545 in Odometer_spreadsheet_FG: 545\n",
            "  ‚ö†Ô∏è Error accessing 549 in Odometer_spreadsheet_SVP: 549\n",
            "  ‚ö†Ô∏è Error accessing 591 in Odometer_spreadsheet_RT: 591\n",
            "  ‚ö†Ô∏è Error accessing 545 in Odometer_spreadsheet_BT: 545\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_SVP: 553\n",
            "  ‚ö†Ô∏è Error accessing 549 in Odometer_spreadsheet_FG: 549\n",
            "  ‚ö†Ô∏è Error accessing 545 in Odometer_spreadsheet_RT: 545\n",
            "  ‚ö†Ô∏è Error accessing 591 in Odometer_spreadsheet_MB: 591\n",
            "  ‚ö†Ô∏è Error accessing 578 in Odometer_spreadsheet_FG: 578\n",
            "  ‚ö†Ô∏è Error accessing 549 in Odometer_spreadsheet_BT: 549\n",
            "  ‚ö†Ô∏è Error accessing 545 in Odometer_spreadsheet_MB: 545\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_FG: 553\n",
            "  ‚ö†Ô∏è Error accessing 591 in Odometer_spreadsheet_DP: 591\n",
            "  ‚ö†Ô∏è No values found for bus 591 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 578 in Odometer_spreadsheet_BT: 578\n",
            "  ‚ö†Ô∏è Error accessing 549 in Odometer_spreadsheet_RT: 549\n",
            "  ‚ö†Ô∏è Error accessing 545 in Odometer_spreadsheet_DP: 545\n",
            "  ‚ö†Ô∏è No values found for bus 545 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_BT: 553\n",
            "  ‚ö†Ô∏è Error accessing 578 in Odometer_spreadsheet_RT: 578\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_RT: 553\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_SVP: 544\n",
            "  ‚ö†Ô∏è Error accessing 549 in Odometer_spreadsheet_MB: 549\n",
            "  ‚ö†Ô∏è Error accessing 578 in Odometer_spreadsheet_MB: 578\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_MB: 553\n",
            "  ‚ö†Ô∏è Error accessing 430 in Odometer_spreadsheet_SVP: 430\n",
            "  ‚ö†Ô∏è Error accessing 549 in Odometer_spreadsheet_DP: 549\n",
            "  ‚ö†Ô∏è No values found for bus 549 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 578 in Odometer_spreadsheet_DP: 578\n",
            "  ‚ö†Ô∏è No values found for bus 578 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_DP: 553\n",
            "  ‚ö†Ô∏è No values found for bus 553 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 430 in Odometer_spreadsheet_FG: 430\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_SVP: 317\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_FG: 544\n",
            "  ‚ö†Ô∏è Error accessing 430 in Odometer_spreadsheet_BT: 430\n",
            "  ‚ö†Ô∏è Error accessing 433 in Odometer_spreadsheet_SVP: 433\n",
            "  ‚ö†Ô∏è Error accessing 430 in Odometer_spreadsheet_RT: 430\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_BT: 544\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_SVP: 409\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_RT: 544\n",
            "  ‚ö†Ô∏è Error accessing 430 in Odometer_spreadsheet_MB: 430\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_FG: 317\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_MB: 544\n",
            "  ‚ö†Ô∏è Error accessing 430 in Odometer_spreadsheet_DP: 430\n",
            "  ‚ö†Ô∏è No values found for bus 430 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_BT: 317\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_DP: 544\n",
            "  ‚ö†Ô∏è No values found for bus 544 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_FG: 409\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_RT: 317\n",
            "  ‚ö†Ô∏è Error accessing Grease Gun in Odometer_spreadsheet_SVP: Grease Gun\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_BT: 409\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_MB: 317\n",
            "  ‚ö†Ô∏è Error accessing 433 in Odometer_spreadsheet_FG: 433\n",
            "  ‚ö†Ô∏è Error accessing 557 in Odometer_spreadsheet_SVP: 557\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_RT: 409\n",
            "  ‚ö†Ô∏è Error accessing 433 in Odometer_spreadsheet_BT: 433\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_DP: 317\n",
            "  ‚ö†Ô∏è No values found for bus 317 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_MB: 409\n",
            "  ‚ö†Ô∏è Error accessing 433 in Odometer_spreadsheet_RT: 433\n",
            "  ‚ö†Ô∏è Error accessing Grease Gun in Odometer_spreadsheet_FG: Grease Gun\n",
            "  ‚ö†Ô∏è Error accessing 433 in Odometer_spreadsheet_MB: 433\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_DP: 409\n",
            "  ‚ö†Ô∏è No values found for bus 409 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing Grease Gun in Odometer_spreadsheet_BT: Grease Gun\n",
            "  ‚ö†Ô∏è Error accessing 433 in Odometer_spreadsheet_DP: 433\n",
            "  ‚ö†Ô∏è No values found for bus 433 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 557 in Odometer_spreadsheet_FG: 557\n",
            "  ‚ö†Ô∏è Error accessing Grease Gun in Odometer_spreadsheet_RT: Grease Gun\n",
            "  ‚ö†Ô∏è Error accessing 557 in Odometer_spreadsheet_BT: 557\n",
            "  ‚ö†Ô∏è Error accessing Grease Gun in Odometer_spreadsheet_MB: Grease Gun\n",
            "  ‚ö†Ô∏è Error accessing 557 in Odometer_spreadsheet_RT: 557\n",
            "  ‚ö†Ô∏è Error accessing Grease Gun in Odometer_spreadsheet_DP: Grease Gun\n",
            "  ‚ö†Ô∏è No values found for bus Grease Gun in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 557 in Odometer_spreadsheet_MB: 557\n",
            "  ‚ö†Ô∏è Error accessing 557 in Odometer_spreadsheet_DP: 557\n",
            "  ‚ö†Ô∏è No values found for bus 557 in any spreadsheet\n",
            "\n",
            "‚úÖ Found values for 0 exact date matches\n",
            "‚úÖ Found values for 0 fallback date matches\n",
            "‚ùå Could not find values for 42 dates\n",
            "\n",
            "üìù Preparing batch updates for engine_oil_CH_BSIV_CH_MAS_ATR...\n",
            "‚úÖ Prepared 0 cell updates\n",
            "‚úì No updates needed for this worksheet\n",
            "\n",
            "================================================================================\n",
            "üìä Processing worksheet: engine_oil_CK_BSVI_CK_MAS_ATR (4/6)\n",
            "================================================================================\n",
            "‚è≥ Waiting 7.69s before processing next worksheet...\n",
            "\n",
            "üîÑ Processing worksheet: engine_oil_CK_BSVI_CK_MAS_ATR\n",
            "üîç Starting data processing for EMPTY L cells only...\n",
            "üì• Loading worksheet data...\n",
            "‚úÖ Loaded 35 rows from worksheet\n",
            "üî¢ Mapping bus numbers and dates for empty L cells...\n",
            "‚úÖ Found 1 unique bus numbers with empty L cells\n",
            "‚úÖ Found 1 empty L cells to process\n",
            "\n",
            "üîç Searching for exact dates or closest earlier dates...\n",
            "  ‚ö†Ô∏è Error accessing 600 in Odometer_spreadsheet_SVP: 600\n",
            "  ‚ö†Ô∏è Error accessing 600 in Odometer_spreadsheet_FG: 600\n",
            "  ‚ö†Ô∏è Error accessing 600 in Odometer_spreadsheet_BT: 600\n",
            "  ‚ö†Ô∏è Error accessing 600 in Odometer_spreadsheet_RT: 600\n",
            "  ‚ö†Ô∏è Error accessing 600 in Odometer_spreadsheet_MB: 600\n",
            "  ‚ö†Ô∏è Error accessing 600 in Odometer_spreadsheet_DP: 600\n",
            "  ‚ö†Ô∏è No values found for bus 600 in any spreadsheet\n",
            "\n",
            "‚úÖ Found values for 0 exact date matches\n",
            "‚úÖ Found values for 0 fallback date matches\n",
            "‚ùå Could not find values for 1 dates\n",
            "\n",
            "üìù Preparing batch updates for engine_oil_CK_BSVI_CK_MAS_ATR...\n",
            "‚úÖ Prepared 0 cell updates\n",
            "‚úì No updates needed for this worksheet\n",
            "\n",
            "================================================================================\n",
            "üìä Processing worksheet: engine_oil_CH_BSIV_CH_MAS_rr (5/6)\n",
            "================================================================================\n",
            "‚è≥ Waiting 7.50s before processing next worksheet...\n",
            "\n",
            "üîÑ Processing worksheet: engine_oil_CH_BSIV_CH_MAS_rr\n",
            "üîç Starting data processing for EMPTY L cells only...\n",
            "üì• Loading worksheet data...\n",
            "‚úÖ Loaded 950 rows from worksheet\n",
            "üî¢ Mapping bus numbers and dates for empty L cells...\n",
            "‚úÖ Found 28 unique bus numbers with empty L cells\n",
            "‚úÖ Found 200 empty L cells to process\n",
            "\n",
            "üîç Searching for exact dates or closest earlier dates...\n",
            "  ‚ö†Ô∏è Error accessing 477 in Odometer_spreadsheet_SVP: 477\n",
            "  ‚ö†Ô∏è Error accessing 322 in Odometer_spreadsheet_SVP: 322\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_SVP: 317\n",
            "  ‚ö†Ô∏è Error accessing 477 in Odometer_spreadsheet_FG: 477\n",
            "  ‚ö†Ô∏è Error accessing 326 in Odometer_spreadsheet_SVP: 326\n",
            "  ‚ö†Ô∏è Error accessing 322 in Odometer_spreadsheet_FG: 322\n",
            "  ‚ö†Ô∏è Error accessing 477 in Odometer_spreadsheet_BT: 477\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_FG: 317\n",
            "  ‚ö†Ô∏è Error accessing 342 in Odometer_spreadsheet_SVP: 342\n",
            "  ‚ö†Ô∏è Error accessing 322 in Odometer_spreadsheet_BT: 322\n",
            "  ‚ö†Ô∏è Error accessing 477 in Odometer_spreadsheet_RT: 477\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_BT: 317\n",
            "  ‚ö†Ô∏è Error accessing 326 in Odometer_spreadsheet_FG: 326\n",
            "  ‚ö†Ô∏è Error accessing 322 in Odometer_spreadsheet_RT: 322\n",
            "  ‚ö†Ô∏è Error accessing 342 in Odometer_spreadsheet_FG: 342\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_RT: 317\n",
            "  ‚ö†Ô∏è Error accessing 326 in Odometer_spreadsheet_BT: 326\n",
            "  ‚ö†Ô∏è Error accessing 342 in Odometer_spreadsheet_BT: 342\n",
            "  ‚ö†Ô∏è Error accessing 326 in Odometer_spreadsheet_RT: 326\n",
            "  ‚ö†Ô∏è Error accessing 342 in Odometer_spreadsheet_RT: 342\n",
            "  ‚ö†Ô∏è Error accessing 477 in Odometer_spreadsheet_MB: 477\n",
            "  ‚ö†Ô∏è Error accessing 322 in Odometer_spreadsheet_MB: 322\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_MB: 317\n",
            "  ‚ö†Ô∏è Error accessing 326 in Odometer_spreadsheet_MB: 326\n",
            "  ‚ö†Ô∏è Error accessing 342 in Odometer_spreadsheet_MB: 342\n",
            "  ‚ö†Ô∏è Error accessing 322 in Odometer_spreadsheet_DP: 322\n",
            "  ‚ö†Ô∏è No values found for bus 322 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 477 in Odometer_spreadsheet_DP: 477\n",
            "  ‚ö†Ô∏è No values found for bus 477 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 317 in Odometer_spreadsheet_DP: 317\n",
            "  ‚ö†Ô∏è No values found for bus 317 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 326 in Odometer_spreadsheet_DP: 326\n",
            "  ‚ö†Ô∏è No values found for bus 326 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 342 in Odometer_spreadsheet_DP: 342\n",
            "  ‚ö†Ô∏è No values found for bus 342 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_SVP: 319\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_SVP: 381\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_FG: 319\n",
            "  ‚ö†Ô∏è Error accessing 443 in Odometer_spreadsheet_SVP: 443\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_FG: 381\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_BT: 319\n",
            "  ‚ö†Ô∏è Error accessing 443 in Odometer_spreadsheet_FG: 443\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_BT: 381\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_SVP: 576\n",
            "  ‚ö†Ô∏è Error accessing 443 in Odometer_spreadsheet_BT: 443\n",
            "  ‚ö†Ô∏è Error accessing RCS in Odometer_spreadsheet_SVP: RCS\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_RT: 381\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_RT: 319\n",
            "  ‚ö†Ô∏è Error accessing 443 in Odometer_spreadsheet_RT: 443\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_FG: 576\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_BT: 576\n",
            "  ‚ö†Ô∏è Error accessing RCS in Odometer_spreadsheet_FG: RCS\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_MB: 381\n",
            "  ‚ö†Ô∏è Error accessing 443 in Odometer_spreadsheet_MB: 443\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_MB: 319\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_RT: 576\n",
            "  ‚ö†Ô∏è Error accessing RCS in Odometer_spreadsheet_BT: RCS\n",
            "  ‚ö†Ô∏è Error accessing 319 in Odometer_spreadsheet_DP: 319\n",
            "  ‚ö†Ô∏è No values found for bus 319 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 443 in Odometer_spreadsheet_DP: 443\n",
            "  ‚ö†Ô∏è No values found for bus 443 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 381 in Odometer_spreadsheet_DP: 381\n",
            "  ‚ö†Ô∏è No values found for bus 381 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_MB: 576\n",
            "  ‚ö†Ô∏è Error accessing RCS in Odometer_spreadsheet_RT: RCS\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_SVP: 419\n",
            "  ‚ö†Ô∏è Error accessing RCS in Odometer_spreadsheet_MB: RCS\n",
            "  ‚ö†Ô∏è Error accessing 576 in Odometer_spreadsheet_DP: 576\n",
            "  ‚ö†Ô∏è No values found for bus 576 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_SVP: 553\n",
            "  ‚ö†Ô∏è Error accessing RCS in Odometer_spreadsheet_DP: RCS\n",
            "  ‚ö†Ô∏è No values found for bus RCS in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 341 in Odometer_spreadsheet_SVP: 341\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_FG: 419\n",
            "  ‚ö†Ô∏è Error accessing 314 in Odometer_spreadsheet_SVP: 314\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_FG: 553\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_BT: 419\n",
            "  ‚ö†Ô∏è Error accessing 341 in Odometer_spreadsheet_FG: 341\n",
            "  ‚ö†Ô∏è Error accessing 513 in Odometer_spreadsheet_SVP: 513\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_BT: 553\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_RT: 419\n",
            "  ‚ö†Ô∏è Error accessing 341 in Odometer_spreadsheet_BT: 341\n",
            "  ‚ö†Ô∏è Error accessing 314 in Odometer_spreadsheet_FG: 314\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_RT: 553\n",
            "  ‚ö†Ô∏è Error accessing 341 in Odometer_spreadsheet_RT: 341\n",
            "  ‚ö†Ô∏è Error accessing 314 in Odometer_spreadsheet_BT: 314\n",
            "  ‚ö†Ô∏è Error accessing 513 in Odometer_spreadsheet_FG: 513\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_MB: 419\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_MB: 553\n",
            "  ‚ö†Ô∏è Error accessing 341 in Odometer_spreadsheet_MB: 341\n",
            "  ‚ö†Ô∏è Error accessing 419 in Odometer_spreadsheet_DP: 419\n",
            "  ‚ö†Ô∏è No values found for bus 419 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 553 in Odometer_spreadsheet_DP: 553\n",
            "  ‚ö†Ô∏è No values found for bus 553 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 513 in Odometer_spreadsheet_BT: 513\n",
            "  ‚ö†Ô∏è Error accessing 314 in Odometer_spreadsheet_RT: 314\n",
            "  ‚ö†Ô∏è Error accessing 341 in Odometer_spreadsheet_DP: 341\n",
            "  ‚ö†Ô∏è No values found for bus 341 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 513 in Odometer_spreadsheet_RT: 513\n",
            "  ‚ö†Ô∏è Error accessing 314 in Odometer_spreadsheet_MB: 314\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_SVP: 544\n",
            "  ‚ö†Ô∏è Error accessing 314 in Odometer_spreadsheet_DP: 314\n",
            "  ‚ö†Ô∏è No values found for bus 314 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 513 in Odometer_spreadsheet_MB: 513\n",
            "  ‚ö†Ô∏è Error accessing 487 in Odometer_spreadsheet_SVP: 487\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_FG: 544\n",
            "  ‚ö†Ô∏è Error accessing 352 in Odometer_spreadsheet_SVP: 352\n",
            "  ‚ö†Ô∏è Error accessing 513 in Odometer_spreadsheet_DP: 513\n",
            "  ‚ö†Ô∏è No values found for bus 513 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_BT: 544\n",
            "  ‚ö†Ô∏è Error accessing ES in Odometer_spreadsheet_SVP: ES\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_RT: 544\n",
            "  ‚ö†Ô∏è Error accessing 487 in Odometer_spreadsheet_FG: 487\n",
            "  ‚ö†Ô∏è Error accessing 352 in Odometer_spreadsheet_FG: 352\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_MB: 544\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_SVP: 368\n",
            "  ‚ö†Ô∏è Error accessing 487 in Odometer_spreadsheet_BT: 487\n",
            "  ‚ö†Ô∏è Error accessing ES in Odometer_spreadsheet_FG: ES\n",
            "  ‚ö†Ô∏è Error accessing 352 in Odometer_spreadsheet_BT: 352\n",
            "  ‚ö†Ô∏è Error accessing 544 in Odometer_spreadsheet_DP: 544\n",
            "  ‚ö†Ô∏è No values found for bus 544 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 487 in Odometer_spreadsheet_RT: 487\n",
            "  ‚ö†Ô∏è Error accessing ES in Odometer_spreadsheet_BT: ES\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_FG: 368\n",
            "  ‚ö†Ô∏è Error accessing 352 in Odometer_spreadsheet_RT: 352\n",
            "  ‚ö†Ô∏è Error accessing 487 in Odometer_spreadsheet_MB: 487\n",
            "  ‚ö†Ô∏è Error accessing ES in Odometer_spreadsheet_RT: ES\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_BT: 368\n",
            "  ‚ö†Ô∏è Error accessing 487 in Odometer_spreadsheet_DP: 487\n",
            "  ‚ö†Ô∏è No values found for bus 487 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing D.G.SET in Odometer_spreadsheet_SVP: D.G.SET\n",
            "  ‚ö†Ô∏è Error accessing ES in Odometer_spreadsheet_MB: ES\n",
            "  ‚ö†Ô∏è Error accessing 352 in Odometer_spreadsheet_MB: 352\n",
            "  ‚ö†Ô∏è Error accessing ES in Odometer_spreadsheet_DP: ES\n",
            "  ‚ö†Ô∏è No values found for bus ES in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_RT: 368\n",
            "  ‚ö†Ô∏è Error accessing 352 in Odometer_spreadsheet_DP: 352\n",
            "  ‚ö†Ô∏è No values found for bus 352 in any spreadsheet\n",
            "‚è≥ Rate limit hit for bus 368, waiting 3.63s (retry 1/5)\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_SVP: 435\n",
            "‚è≥ Rate limit hit for bus 444, waiting 2.05s (retry 1/5)\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_SVP: 409\n",
            "  ‚ö†Ô∏è Error accessing D.G.SET in Odometer_spreadsheet_FG: D.G.SET\n",
            "‚è≥ Rate limit hit for bus D.G.SET, waiting 3.62s (retry 1/5)\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_FG: 435\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_FG: 409\n",
            "‚è≥ Rate limit hit for bus 435, waiting 3.41s (retry 1/5)\n",
            "‚è≥ Rate limit hit for bus 409, waiting 2.57s (retry 1/5)\n",
            "‚è≥ Rate limit hit for bus 444, waiting 5.06s (retry 2/5)\n",
            "‚è≥ Rate limit hit for bus 409, waiting 4.85s (retry 2/5)\n",
            "‚è≥ Rate limit hit for bus 368, waiting 5.30s (retry 2/5)\n",
            "‚è≥ Rate limit hit for bus 435, waiting 5.85s (retry 2/5)\n",
            "‚è≥ Rate limit hit for bus D.G.SET, waiting 4.43s (retry 2/5)\n",
            "‚è≥ Rate limit hit for bus 444, waiting 9.33s (retry 3/5)\n",
            "‚è≥ Rate limit hit for bus 409, waiting 8.05s (retry 3/5)\n",
            "‚è≥ Rate limit hit for bus D.G.SET, waiting 9.38s (retry 3/5)\n",
            "‚è≥ Rate limit hit for bus 368, waiting 8.61s (retry 3/5)\n",
            "‚è≥ Rate limit hit for bus 435, waiting 8.65s (retry 3/5)\n",
            "‚è≥ Rate limit hit for bus 409, waiting 17.95s (retry 4/5)\n",
            "‚è≥ Rate limit hit for bus 444, waiting 16.52s (retry 4/5)\n",
            "‚è≥ Rate limit hit for bus 368, waiting 17.76s (retry 4/5)\n",
            "‚è≥ Rate limit hit for bus D.G.SET, waiting 16.15s (retry 4/5)\n",
            "‚è≥ Rate limit hit for bus 435, waiting 17.54s (retry 4/5)\n",
            "‚è≥ Rate limit hit for bus 444, waiting 32.54s (retry 5/5)\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_BT: 409\n",
            "  ‚ö†Ô∏è Error accessing D.G.SET in Odometer_spreadsheet_BT: D.G.SET\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_RT: 409\n",
            "‚è≥ Rate limit hit for bus 409, waiting 3.00s (retry 1/5)\n",
            "  ‚ö†Ô∏è Error accessing D.G.SET in Odometer_spreadsheet_RT: D.G.SET\n",
            "  ‚ö†Ô∏è Error accessing D.G.SET in Odometer_spreadsheet_MB: D.G.SET\n",
            "‚è≥ Rate limit hit for bus D.G.SET, waiting 2.13s (retry 1/5)\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_MB: 368\n",
            "  ‚ö†Ô∏è Error accessing 368 in Odometer_spreadsheet_DP: 368\n",
            "  ‚ö†Ô∏è No values found for bus 368 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing AirComp. in Odometer_spreadsheet_SVP: AirComp.\n",
            "‚è≥ Rate limit hit for bus AirComp., waiting 3.85s (retry 1/5)\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_BT: 435\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_RT: 435\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_MB: 435\n",
            "  ‚ö†Ô∏è Error accessing 435 in Odometer_spreadsheet_DP: 435\n",
            "  ‚ö†Ô∏è No values found for bus 435 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 482 in Odometer_spreadsheet_SVP: 482\n",
            "  ‚ö†Ô∏è Error accessing D.G.SET in Odometer_spreadsheet_DP: D.G.SET\n",
            "  ‚ö†Ô∏è No values found for bus D.G.SET in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 482 in Odometer_spreadsheet_FG: 482\n",
            "  ‚ö†Ô∏è Error accessing 482 in Odometer_spreadsheet_BT: 482\n",
            "  ‚ö†Ô∏è Error accessing 552 in Odometer_spreadsheet_SVP: 552\n",
            "  ‚ö†Ô∏è Error accessing 482 in Odometer_spreadsheet_RT: 482\n",
            "  ‚ö†Ô∏è Error accessing 552 in Odometer_spreadsheet_FG: 552\n",
            "  ‚ö†Ô∏è Error accessing 482 in Odometer_spreadsheet_MB: 482\n",
            "  ‚ö†Ô∏è Error accessing 552 in Odometer_spreadsheet_BT: 552\n",
            "  ‚ö†Ô∏è Error accessing 482 in Odometer_spreadsheet_DP: 482\n",
            "  ‚ö†Ô∏è No values found for bus 482 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing 552 in Odometer_spreadsheet_RT: 552\n",
            "  ‚ö†Ô∏è Error accessing B/T in Odometer_spreadsheet_SVP: B/T\n",
            "  ‚ö†Ô∏è Error accessing 552 in Odometer_spreadsheet_MB: 552\n",
            "  ‚ö†Ô∏è Error accessing 552 in Odometer_spreadsheet_DP: 552\n",
            "  ‚ö†Ô∏è No values found for bus 552 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing B/T in Odometer_spreadsheet_FG: B/T\n",
            "  ‚ö†Ô∏è Error accessing B/T in Odometer_spreadsheet_BT: B/T\n",
            "  ‚ö†Ô∏è Error accessing B/T in Odometer_spreadsheet_RT: B/T\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_MB: 409\n",
            "  ‚ö†Ô∏è Error accessing B/T in Odometer_spreadsheet_MB: B/T\n",
            "  ‚ö†Ô∏è Error accessing 409 in Odometer_spreadsheet_DP: 409\n",
            "  ‚ö†Ô∏è No values found for bus 409 in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing B/T in Odometer_spreadsheet_DP: B/T\n",
            "  ‚ö†Ô∏è No values found for bus B/T in any spreadsheet\n",
            "  ‚ö†Ô∏è Error accessing AirComp. in Odometer_spreadsheet_FG: AirComp.\n",
            "  ‚ö†Ô∏è Error accessing AirComp. in Odometer_spreadsheet_BT: AirComp.\n",
            "  ‚ö†Ô∏è Error accessing AirComp. in Odometer_spreadsheet_RT: AirComp.\n",
            "  ‚ö†Ô∏è Error accessing AirComp. in Odometer_spreadsheet_MB: AirComp.\n",
            "  ‚ö†Ô∏è Error accessing AirComp. in Odometer_spreadsheet_DP: AirComp.\n",
            "  ‚ö†Ô∏è No values found for bus AirComp. in any spreadsheet\n",
            "‚ö†Ô∏è Max retries reached for bus 444 in Odometer_spreadsheet_SVP\n",
            "  ‚ö†Ô∏è Error accessing 444 in Odometer_spreadsheet_FG: 444\n",
            "  ‚ö†Ô∏è Error accessing 444 in Odometer_spreadsheet_BT: 444\n",
            "  ‚ö†Ô∏è Error accessing 444 in Odometer_spreadsheet_RT: 444\n",
            "  ‚ö†Ô∏è Error accessing 444 in Odometer_spreadsheet_MB: 444\n",
            "  ‚ö†Ô∏è Error accessing 444 in Odometer_spreadsheet_DP: 444\n",
            "  ‚ö†Ô∏è No values found for bus 444 in any spreadsheet\n",
            "\n",
            "‚úÖ Found values for 0 exact date matches\n",
            "‚úÖ Found values for 0 fallback date matches\n",
            "‚ùå Could not find values for 200 dates\n",
            "\n",
            "üìù Preparing batch updates for engine_oil_CH_BSIV_CH_MAS_rr...\n",
            "‚úÖ Prepared 0 cell updates\n",
            "‚úì No updates needed for this worksheet\n",
            "\n",
            "================================================================================\n",
            "üìä Processing worksheet: engine_oil_CK_BSVI_CK_MAS_rr (6/6)\n",
            "================================================================================\n",
            "‚è≥ Waiting 5.17s before processing next worksheet...\n",
            "\n",
            "üîÑ Processing worksheet: engine_oil_CK_BSVI_CK_MAS_rr\n",
            "üîç Starting data processing for EMPTY L cells only...\n",
            "üì• Loading worksheet data...\n",
            "‚úÖ Loaded 12 rows from worksheet\n",
            "üî¢ Mapping bus numbers and dates for empty L cells...\n",
            "‚úÖ Found 1 unique bus numbers with empty L cells\n",
            "‚úÖ Found 1 empty L cells to process\n",
            "\n",
            "üîç Searching for exact dates or closest earlier dates...\n",
            "  ‚ö†Ô∏è Error accessing 610 in Odometer_spreadsheet_SVP: 610\n",
            "  ‚ö†Ô∏è Error accessing 610 in Odometer_spreadsheet_FG: 610\n",
            "  ‚ö†Ô∏è Error accessing 610 in Odometer_spreadsheet_BT: 610\n",
            "  ‚ö†Ô∏è Error accessing 610 in Odometer_spreadsheet_RT: 610\n",
            "  ‚ö†Ô∏è Error accessing 610 in Odometer_spreadsheet_MB: 610\n",
            "  ‚ö†Ô∏è Error accessing 610 in Odometer_spreadsheet_DP: 610\n",
            "  ‚ö†Ô∏è No values found for bus 610 in any spreadsheet\n",
            "\n",
            "‚úÖ Found values for 0 exact date matches\n",
            "‚úÖ Found values for 0 fallback date matches\n",
            "‚ùå Could not find values for 1 dates\n",
            "\n",
            "üìù Preparing batch updates for engine_oil_CK_BSVI_CK_MAS_rr...\n",
            "‚úÖ Prepared 0 cell updates\n",
            "‚úì No updates needed for this worksheet\n",
            "\n",
            "‚úÖ All worksheets have been processed successfully!\n",
            "üí° Performance Summary:\n",
            "‚úì Processed 6 worksheets with LEAN mode (empty L cells only)\n",
            "‚úì Searched across 6 odometer spreadsheets\n",
            "‚úì Used parallel processing for bus data with ThreadPoolExecutor\n",
            "‚úì Implemented caching to reduce API calls\n",
            "‚úì Used batch updates to minimize API requests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below codes are redundent, No need to run, Use this If required in future"
      ],
      "metadata": {
        "id": "Uq1Go9jLsRov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# High speed, RR, code of 1.0.7 is fast but only for CH, if we incorporate CK, it will be super fast\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import math\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# List of all worksheets to process\n",
        "engine_oil_worksheets = [\n",
        "    'engine_oil_CH_BSIV_CH_MAS_rr',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_rr'\n",
        "]\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "# Function to process each worksheet\n",
        "def process_worksheet(worksheet_name):\n",
        "    print(f\"\\nüîÑ Processing worksheet: {worksheet_name}\")\n",
        "\n",
        "    # Get the worksheet object\n",
        "    worksheet = None\n",
        "    try:\n",
        "        # Assuming these are defined in your notebook environment\n",
        "        worksheet = eval(worksheet_name)  # This will use the already defined variable in your notebook\n",
        "    except:\n",
        "        print(f\"‚ùå Error: Worksheet '{worksheet_name}' not found or not accessible\")\n",
        "        return\n",
        "\n",
        "    # Clear data in range L2:M, Odometer value in Engine Oil and Fallback date removal\n",
        "    clear_range = 'L2:M'\n",
        "    print(f\"üßπ Clearing range {clear_range} in {worksheet_name}...\")\n",
        "    worksheet.batch_clear([clear_range])\n",
        "\n",
        "    print(\"üîç Starting data processing with date fallback search...\")\n",
        "\n",
        "    # üì• Load main sheet\n",
        "    print(\"üì• Loading worksheet data...\")\n",
        "    main_data = worksheet.get_all_values()\n",
        "    print(f\"‚úÖ Loaded {len(main_data)-1} rows from worksheet\")\n",
        "\n",
        "    # Step 1: Collect unique (bus, date) and row mapping\n",
        "    print(\"üî¢ Mapping bus numbers and dates...\")\n",
        "    bus_date_map = defaultdict(set)\n",
        "    row_map = {}  # maps row number ‚Üí (bus, date)\n",
        "\n",
        "    for i, row in enumerate(main_data[1:], start=2):\n",
        "        try:\n",
        "            date_str = row[1].strip()\n",
        "            bus_num = row[4].strip()\n",
        "            if date_str and bus_num:\n",
        "                bus_date_map[bus_num].add(date_str)\n",
        "                row_map[i] = (bus_num, date_str)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"‚úÖ Found {len(bus_date_map)} unique bus numbers\")\n",
        "    print(f\"‚úÖ Found {len(row_map)} rows to process\")\n",
        "\n",
        "    # Create a cache for worksheet data to avoid redundant fetches\n",
        "    bus_worksheet_cache = {}\n",
        "\n",
        "    # Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "    print(\"\\nüîç Searching for exact dates or closest earlier dates...\")\n",
        "    bus_date_value_map = {}\n",
        "    match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "    fallback_date_map = {}  # Store the actual fallback date used\n",
        "    success_count = 0\n",
        "    fallback_count = 0\n",
        "\n",
        "    # Function to process a single bus\n",
        "    def process_bus(bus_dates_tuple):\n",
        "        bus, dates = bus_dates_tuple\n",
        "        sheet_success = 0\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            # Check if we already have this bus's data in cache\n",
        "            if bus in bus_worksheet_cache:\n",
        "                sheet_data = bus_worksheet_cache[bus]\n",
        "            else:\n",
        "                # Fetch the bus worksheet data and store in cache\n",
        "                sheet = Odometer_spreadsheet_SVP.worksheet(bus)\n",
        "                sheet_data = sheet.get_all_values()\n",
        "                bus_worksheet_cache[bus] = sheet_data\n",
        "\n",
        "            # Create a dictionary for faster exact date lookups\n",
        "            date_value_lookup = {}\n",
        "            for row in sheet_data[1:]:\n",
        "                try:\n",
        "                    if len(row) > 12:\n",
        "                        date_str_key = row[1].strip()\n",
        "                        date_value_lookup[date_str_key] = row[12]  # Column M\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            for date_str in dates:\n",
        "                # Check for exact match using the lookup dictionary\n",
        "                exact_value = date_value_lookup.get(date_str)\n",
        "\n",
        "                if exact_value:\n",
        "                    results.append((bus, date_str, exact_value, \"exact\", \"\"))\n",
        "                    sheet_success += 1\n",
        "                else:\n",
        "                    # Try to find closest earlier date\n",
        "                    value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                    if value:\n",
        "                        results.append((bus, date_str, value, \"fallback\", fallback_date))\n",
        "                        sheet_success += 1\n",
        "\n",
        "            print(f\"  ‚úÖ Found {sheet_success}/{len(dates)} values for bus {bus}\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Could not process sheet '{bus}': {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    # Process buses in parallel using ThreadPoolExecutor\n",
        "    print(f\"üöÄ Processing {len(bus_date_map)} buses in parallel...\")\n",
        "\n",
        "    # Convert to list for ThreadPoolExecutor\n",
        "    bus_dates_list = list(bus_date_map.items())\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    # Adjust max_workers based on your system's capabilities\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        all_results = list(executor.map(process_bus, bus_dates_list))\n",
        "\n",
        "    # Process all results\n",
        "    for bus_results in all_results:\n",
        "        for bus, date_str, value, match_type, fallback_date in bus_results:\n",
        "            bus_date_value_map[(bus, date_str)] = value\n",
        "            match_type_map[(bus, date_str)] = match_type\n",
        "            fallback_date_map[(bus, date_str)] = fallback_date\n",
        "\n",
        "            if match_type == \"exact\":\n",
        "                success_count += 1\n",
        "            else:\n",
        "                fallback_count += 1\n",
        "\n",
        "    print(f\"\\n‚úÖ Found values for {success_count} exact date matches\")\n",
        "    print(f\"‚úÖ Found values for {fallback_count} fallback date matches\")\n",
        "    print(f\"‚ùå Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "    # Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "    print(f\"\\nüìù Preparing batch updates for {worksheet_name}...\")\n",
        "\n",
        "    # Prepare batch update for all cells at once\n",
        "    batch_updates = []\n",
        "    exact_match_cells = []\n",
        "    fallback_match_cells = []\n",
        "\n",
        "    for row_num, (bus, date_str) in row_map.items():\n",
        "        value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "        fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "\n",
        "        if value:\n",
        "            # Add to batch updates list (row, col, value)\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 12,  # Column L\n",
        "                'value': value\n",
        "            })\n",
        "\n",
        "            # Add fallback date update\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 13,  # Column M\n",
        "                'value': fallback_date\n",
        "            })\n",
        "\n",
        "            # Track which cells need which formatting\n",
        "            match_type = match_type_map.get((bus, date_str))\n",
        "            if match_type == \"exact\":\n",
        "                exact_match_cells.append(f\"L{row_num}\")\n",
        "            elif match_type == \"fallback\":\n",
        "                fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "    print(f\"‚úÖ Prepared {len(batch_updates)} cell updates\")\n",
        "\n",
        "    # Execute batch updates in chunks to avoid rate limits\n",
        "    updated_count = 0\n",
        "    chunk_size = 50  # Adjust based on API limits\n",
        "    chunks = math.ceil(len(batch_updates) / chunk_size)\n",
        "\n",
        "    print(f\"üîÑ Executing batch updates in {chunks} chunks...\")\n",
        "\n",
        "    for chunk_index in range(chunks):\n",
        "        start_idx = chunk_index * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, len(batch_updates))\n",
        "        current_chunk = batch_updates[start_idx:end_idx]\n",
        "\n",
        "        max_retries = 5\n",
        "        retry_count = 0\n",
        "        update_successful = False\n",
        "\n",
        "        while not update_successful and retry_count < max_retries:\n",
        "            try:\n",
        "                # Prepare the batch update request\n",
        "                cell_list = []\n",
        "\n",
        "                for update in current_chunk:\n",
        "                    cell = worksheet.cell(update['row'], update['col'])\n",
        "                    cell.value = update['value']\n",
        "                    cell_list.append(cell)\n",
        "\n",
        "                # Execute the batch update\n",
        "                worksheet.update_cells(cell_list, value_input_option='USER_ENTERED')\n",
        "\n",
        "                update_successful = True\n",
        "                updated_count += len(current_chunk) // 2  # Divide by 2 because we have 2 cells per row\n",
        "                print(f\"üìä Progress: Chunk {chunk_index+1}/{chunks} complete - {updated_count}/{len(batch_updates)//2} rows updated\")\n",
        "\n",
        "                # Add a small delay between chunks to avoid rate limits\n",
        "                time.sleep(1)\n",
        "\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                if \"429\" in str(e):\n",
        "                    wait_time = (2 ** retry_count) + random.random()\n",
        "                    print(f\"‚è≥ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"‚ùå Failed to update chunk {chunk_index+1}: {e}\")\n",
        "                    break\n",
        "\n",
        "        if not update_successful:\n",
        "            print(f\"‚ùå Failed to update chunk {chunk_index+1} after {max_retries} retries\")\n",
        "\n",
        "    # Apply formatting in batches (currently commented out)\n",
        "    print(\"\\nüé® Applying formatting to distinguish match types...\")\n",
        "    # You can uncomment and implement batch formatting logic if needed.\n",
        "\n",
        "    print(f\"\\n‚úÖ COMPLETE for {worksheet_name}: Updated {updated_count} rows in column L and column M\")\n",
        "    print(f\"üìä Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "    print(f\"‚ùå {len(row_map) - updated_count} rows could not be updated\")\n",
        "\n",
        "# Main execution\n",
        "print(\"üöÄ Starting to process all engine oil worksheets...\")\n",
        "\n",
        "# Create a global cache for bus worksheets to reuse across all worksheets\n",
        "global_bus_worksheet_cache = {}\n",
        "\n",
        "# Process each worksheet in sequence\n",
        "for worksheet_name in engine_oil_worksheets:\n",
        "    print(f\"\\n{'='*80}\\nüìä Processing worksheet: {worksheet_name}\\n{'='*80}\")\n",
        "    process_worksheet(worksheet_name)\n",
        "    # Add a delay between worksheets to avoid rate limiting\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\n‚úÖ All worksheets have been processed successfully!\")\n",
        "print(\"üí° Performance Summary:\")\n",
        "print(f\"‚úì Processed {len(engine_oil_worksheets)} worksheets with batch processing\")\n",
        "print(f\"‚úì Used parallel processing for bus data with ThreadPoolExecutor\")\n",
        "print(f\"‚úì Implemented caching to reduce API calls\")\n",
        "print(f\"‚úì Used batch updates to minimize API requests\")\n"
      ],
      "metadata": {
        "id": "Ui_8optlYNwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ATR , (RR, code of 1.0.7 is fast but only for CH, if we incorporate CK, and adopt for ATR and FG it will be super fast)\n",
        "\n",
        "\n",
        "# List of all worksheets to process\n",
        "engine_oil_worksheets = [\n",
        "    'engine_oil_CH_BSIV_CH_MAS_ATR',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_ATR'\n",
        "]\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "# Function to process each worksheet\n",
        "def process_worksheet(worksheet_name):\n",
        "    print(f\"\\nüîÑ Processing worksheet: {worksheet_name}\")\n",
        "\n",
        "    # Get the worksheet object\n",
        "    worksheet = None\n",
        "    try:\n",
        "        # Assuming these are defined in your notebook environment\n",
        "        worksheet = eval(worksheet_name)  # This will use the already defined variable in your notebook\n",
        "    except:\n",
        "        print(f\"‚ùå Error: Worksheet '{worksheet_name}' not found or not accessible\")\n",
        "        return\n",
        "\n",
        "    # Clear data in range L2:M, Odometer value in Engine Oil and Fallback date removal\n",
        "    clear_range = 'L2:M'\n",
        "    print(f\"üßπ Clearing range {clear_range} in {worksheet_name}...\")\n",
        "    worksheet.batch_clear([clear_range])\n",
        "\n",
        "    print(\"üîç Starting data processing with date fallback search...\")\n",
        "\n",
        "    # üì• Load main sheet\n",
        "    print(\"üì• Loading worksheet data...\")\n",
        "    main_data = worksheet.get_all_values()\n",
        "    print(f\"‚úÖ Loaded {len(main_data)-1} rows from worksheet\")\n",
        "\n",
        "    # Step 1: Collect unique (bus, date) and row mapping\n",
        "    print(\"üî¢ Mapping bus numbers and dates...\")\n",
        "    bus_date_map = defaultdict(set)\n",
        "    row_map = {}  # maps row number ‚Üí (bus, date)\n",
        "\n",
        "    for i, row in enumerate(main_data[1:], start=2):\n",
        "        try:\n",
        "            date_str = row[1].strip()\n",
        "            bus_num = row[4].strip()\n",
        "            if date_str and bus_num:\n",
        "                bus_date_map[bus_num].add(date_str)\n",
        "                row_map[i] = (bus_num, date_str)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"‚úÖ Found {len(bus_date_map)} unique bus numbers\")\n",
        "    print(f\"‚úÖ Found {len(row_map)} rows to process\")\n",
        "\n",
        "    # Create a cache for worksheet data to avoid redundant fetches\n",
        "    bus_worksheet_cache = {}\n",
        "\n",
        "    # Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "    print(\"\\nüîç Searching for exact dates or closest earlier dates...\")\n",
        "    bus_date_value_map = {}\n",
        "    match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "    fallback_date_map = {}  # Store the actual fallback date used\n",
        "    success_count = 0\n",
        "    fallback_count = 0\n",
        "\n",
        "    # Function to process a single bus\n",
        "    def process_bus(bus_dates_tuple):\n",
        "        bus, dates = bus_dates_tuple\n",
        "        sheet_success = 0\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            # Check if we already have this bus's data in cache\n",
        "            if bus in bus_worksheet_cache:\n",
        "                sheet_data = bus_worksheet_cache[bus]\n",
        "            else:\n",
        "                # Fetch the bus worksheet data and store in cache\n",
        "                sheet = Odometer_spreadsheet_SVP.worksheet(bus)\n",
        "                sheet_data = sheet.get_all_values()\n",
        "                bus_worksheet_cache[bus] = sheet_data\n",
        "\n",
        "            # Create a dictionary for faster exact date lookups\n",
        "            date_value_lookup = {}\n",
        "            for row in sheet_data[1:]:\n",
        "                try:\n",
        "                    if len(row) > 12:\n",
        "                        date_str_key = row[1].strip()\n",
        "                        date_value_lookup[date_str_key] = row[12]  # Column M\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            for date_str in dates:\n",
        "                # Check for exact match using the lookup dictionary\n",
        "                exact_value = date_value_lookup.get(date_str)\n",
        "\n",
        "                if exact_value:\n",
        "                    results.append((bus, date_str, exact_value, \"exact\", \"\"))\n",
        "                    sheet_success += 1\n",
        "                else:\n",
        "                    # Try to find closest earlier date\n",
        "                    value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                    if value:\n",
        "                        results.append((bus, date_str, value, \"fallback\", fallback_date))\n",
        "                        sheet_success += 1\n",
        "\n",
        "            print(f\"  ‚úÖ Found {sheet_success}/{len(dates)} values for bus {bus}\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Could not process sheet '{bus}': {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    # Process buses in parallel using ThreadPoolExecutor\n",
        "    print(f\"üöÄ Processing {len(bus_date_map)} buses in parallel...\")\n",
        "\n",
        "    # Convert to list for ThreadPoolExecutor\n",
        "    bus_dates_list = list(bus_date_map.items())\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    # Adjust max_workers based on your system's capabilities\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        all_results = list(executor.map(process_bus, bus_dates_list))\n",
        "\n",
        "    # Process all results\n",
        "    for bus_results in all_results:\n",
        "        for bus, date_str, value, match_type, fallback_date in bus_results:\n",
        "            bus_date_value_map[(bus, date_str)] = value\n",
        "            match_type_map[(bus, date_str)] = match_type\n",
        "            fallback_date_map[(bus, date_str)] = fallback_date\n",
        "\n",
        "            if match_type == \"exact\":\n",
        "                success_count += 1\n",
        "            else:\n",
        "                fallback_count += 1\n",
        "\n",
        "    print(f\"\\n‚úÖ Found values for {success_count} exact date matches\")\n",
        "    print(f\"‚úÖ Found values for {fallback_count} fallback date matches\")\n",
        "    print(f\"‚ùå Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "    # Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "    print(f\"\\nüìù Preparing batch updates for {worksheet_name}...\")\n",
        "\n",
        "    # Prepare batch update for all cells at once\n",
        "    batch_updates = []\n",
        "    exact_match_cells = []\n",
        "    fallback_match_cells = []\n",
        "\n",
        "    for row_num, (bus, date_str) in row_map.items():\n",
        "        value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "        fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "\n",
        "        if value:\n",
        "            # Add to batch updates list (row, col, value)\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 12,  # Column L\n",
        "                'value': value\n",
        "            })\n",
        "\n",
        "            # Add fallback date update\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 13,  # Column M\n",
        "                'value': fallback_date\n",
        "            })\n",
        "\n",
        "            # Track which cells need which formatting\n",
        "            match_type = match_type_map.get((bus, date_str))\n",
        "            if match_type == \"exact\":\n",
        "                exact_match_cells.append(f\"L{row_num}\")\n",
        "            elif match_type == \"fallback\":\n",
        "                fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "    print(f\"‚úÖ Prepared {len(batch_updates)} cell updates\")\n",
        "\n",
        "    # Execute batch updates in chunks to avoid rate limits\n",
        "    updated_count = 0\n",
        "    chunk_size = 50  # Adjust based on API limits\n",
        "    chunks = math.ceil(len(batch_updates) / chunk_size)\n",
        "\n",
        "    print(f\"üîÑ Executing batch updates in {chunks} chunks...\")\n",
        "\n",
        "    for chunk_index in range(chunks):\n",
        "        start_idx = chunk_index * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, len(batch_updates))\n",
        "        current_chunk = batch_updates[start_idx:end_idx]\n",
        "\n",
        "        max_retries = 5\n",
        "        retry_count = 0\n",
        "        update_successful = False\n",
        "\n",
        "        while not update_successful and retry_count < max_retries:\n",
        "            try:\n",
        "                # Prepare the batch update request\n",
        "                cell_list = []\n",
        "\n",
        "                for update in current_chunk:\n",
        "                    cell = worksheet.cell(update['row'], update['col'])\n",
        "                    cell.value = update['value']\n",
        "                    cell_list.append(cell)\n",
        "\n",
        "                # Execute the batch update\n",
        "                worksheet.update_cells(cell_list, value_input_option='USER_ENTERED')\n",
        "\n",
        "                update_successful = True\n",
        "                updated_count += len(current_chunk) // 2  # Divide by 2 because we have 2 cells per row\n",
        "                print(f\"üìä Progress: Chunk {chunk_index+1}/{chunks} complete - {updated_count}/{len(batch_updates)//2} rows updated\")\n",
        "\n",
        "                # Add a small delay between chunks to avoid rate limits\n",
        "                time.sleep(1)\n",
        "\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                if \"429\" in str(e):\n",
        "                    wait_time = (2 ** retry_count) + random.random()\n",
        "                    print(f\"‚è≥ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"‚ùå Failed to update chunk {chunk_index+1}: {e}\")\n",
        "                    break\n",
        "\n",
        "        if not update_successful:\n",
        "            print(f\"‚ùå Failed to update chunk {chunk_index+1} after {max_retries} retries\")\n",
        "\n",
        "    # Apply formatting in batches (currently commented out)\n",
        "    print(\"\\nüé® Applying formatting to distinguish match types...\")\n",
        "    # You can uncomment and implement batch formatting logic if needed.\n",
        "\n",
        "    print(f\"\\n‚úÖ COMPLETE for {worksheet_name}: Updated {updated_count} rows in column L and column M\")\n",
        "    print(f\"üìä Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "    print(f\"‚ùå {len(row_map) - updated_count} rows could not be updated\")\n",
        "\n",
        "# Main execution\n",
        "print(\"üöÄ Starting to process all engine oil worksheets...\")\n",
        "\n",
        "# Create a global cache for bus worksheets to reuse across all worksheets\n",
        "global_bus_worksheet_cache = {}\n",
        "\n",
        "# Process each worksheet in sequence\n",
        "for worksheet_name in engine_oil_worksheets:\n",
        "    print(f\"\\n{'='*80}\\nüìä Processing worksheet: {worksheet_name}\\n{'='*80}\")\n",
        "    process_worksheet(worksheet_name)\n",
        "    # Add a delay between worksheets to avoid rate limiting\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\n‚úÖ All worksheets have been processed successfully!\")\n",
        "print(\"üí° Performance Summary:\")\n",
        "print(f\"‚úì Processed {len(engine_oil_worksheets)} worksheets with batch processing\")\n",
        "print(f\"‚úì Used parallel processing for bus data with ThreadPoolExecutor\")\n",
        "print(f\"‚úì Implemented caching to reduce API calls\")\n",
        "print(f\"‚úì Used batch updates to minimize API requests\")\n"
      ],
      "metadata": {
        "id": "xX4H7u05a-I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FG_Working, Best Code\n",
        "\n",
        "# Modified to process multiple engine oil worksheets, Added batch processing done\n",
        "\n",
        "# Modified to process multiple engine oil worksheets with batch processing\n",
        "# With fallback date display in M Column, For ATR_MAS_Engine Oil\n",
        "\n",
        "# List of all worksheets to process\n",
        "engine_oil_worksheets = [\n",
        "    'engine_oil_CH_BSIV_CH_MAS_FG',\n",
        "    'engine_oil_CK_BSVI_CK_MAS_FG'\n",
        "]\n",
        "\n",
        "# Function to parse custom date format 'DD,MMMyy' like '13,Apr24'\n",
        "def parse_custom_date(date_str):\n",
        "    if not date_str or date_str == '':\n",
        "        return None\n",
        "\n",
        "    pattern = r'(\\d{1,2}),(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)(\\d{2})'\n",
        "    match = re.match(pattern, date_str)\n",
        "\n",
        "    if match:\n",
        "        day = int(match.group(1))\n",
        "        month_str = match.group(2)\n",
        "        year = int(match.group(3)) + 2000  # Assuming 20xx for the year\n",
        "\n",
        "        month_map = {\n",
        "            'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
        "            'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
        "        }\n",
        "\n",
        "        month = month_map[month_str]\n",
        "        return datetime(year, month, day)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Modified function to return both value and fallback date\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    # Parse all dates in the sheet\n",
        "    dates = []\n",
        "    parsed_dates = []\n",
        "    values = []\n",
        "\n",
        "    for row in sheet_data[1:]:  # Skip header\n",
        "        try:\n",
        "            if len(row) > value_column_index and len(row) > 1:\n",
        "                date_str = row[1].strip()\n",
        "                value = row[value_column_index]\n",
        "\n",
        "                parsed_date = parse_custom_date(date_str)\n",
        "                if parsed_date:\n",
        "                    dates.append(date_str)\n",
        "                    parsed_dates.append(parsed_date)\n",
        "                    values.append(value)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    # Parse target date\n",
        "    target_date = parse_custom_date(target_date_str)\n",
        "    if not target_date:\n",
        "        return None, None\n",
        "\n",
        "    # First check for exact match\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date == target_date:\n",
        "            return values[i], None  # Return value with no fallback date for exact matches\n",
        "\n",
        "    # If no exact match, find closest earlier date\n",
        "    closest_date = None\n",
        "    closest_value = None\n",
        "    max_date = None\n",
        "\n",
        "    for i, parsed_date in enumerate(parsed_dates):\n",
        "        if parsed_date < target_date and (max_date is None or parsed_date > max_date):\n",
        "            max_date = parsed_date\n",
        "            closest_date = dates[i]\n",
        "            closest_value = values[i]\n",
        "\n",
        "    return closest_value, closest_date  # Return both value and fallback date\n",
        "\n",
        "# Function to process each worksheet\n",
        "def process_worksheet(worksheet_name):\n",
        "    print(f\"\\nüîÑ Processing worksheet: {worksheet_name}\")\n",
        "\n",
        "    # Get the worksheet object\n",
        "    worksheet = None\n",
        "    try:\n",
        "        # Assuming these are defined in your notebook environment\n",
        "        worksheet = eval(worksheet_name)  # This will use the already defined variable in your notebook\n",
        "    except:\n",
        "        print(f\"‚ùå Error: Worksheet '{worksheet_name}' not found or not accessible\")\n",
        "        return\n",
        "\n",
        "    # Clear data in range L2:M, Odometer value in Engine Oil and Fallback date removal\n",
        "    clear_range = 'L2:M'\n",
        "    print(f\"üßπ Clearing range {clear_range} in {worksheet_name}...\")\n",
        "    worksheet.batch_clear([clear_range])\n",
        "\n",
        "    print(\"üîç Starting data processing with date fallback search...\")\n",
        "\n",
        "    # üì• Load main sheet\n",
        "    print(\"üì• Loading worksheet data...\")\n",
        "    main_data = worksheet.get_all_values()\n",
        "    print(f\"‚úÖ Loaded {len(main_data)-1} rows from worksheet\")\n",
        "\n",
        "    # Step 1: Collect unique (bus, date) and row mapping\n",
        "    print(\"üî¢ Mapping bus numbers and dates...\")\n",
        "    bus_date_map = defaultdict(set)\n",
        "    row_map = {}  # maps row number ‚Üí (bus, date)\n",
        "\n",
        "    for i, row in enumerate(main_data[1:], start=2):\n",
        "        try:\n",
        "            date_str = row[1].strip()\n",
        "            bus_num = row[4].strip()\n",
        "            if date_str and bus_num:\n",
        "                bus_date_map[bus_num].add(date_str)\n",
        "                row_map[i] = (bus_num, date_str)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"‚úÖ Found {len(bus_date_map)} unique bus numbers\")\n",
        "    print(f\"‚úÖ Found {len(row_map)} rows to process\")\n",
        "\n",
        "    # Create a cache for worksheet data to avoid redundant fetches\n",
        "    bus_worksheet_cache = {}\n",
        "\n",
        "    # Step 2: Fetch each bus worksheet once, collect all data and find exact or closest earlier date\n",
        "    print(\"\\nüîç Searching for exact dates or closest earlier dates...\")\n",
        "    bus_date_value_map = {}\n",
        "    match_type_map = {}  # Tracks whether each match is exact or fallback\n",
        "    fallback_date_map = {}  # Store the actual fallback date used\n",
        "    success_count = 0\n",
        "    fallback_count = 0\n",
        "\n",
        "    # Function to process a single bus\n",
        "    def process_bus(bus_dates_tuple):\n",
        "        bus, dates = bus_dates_tuple\n",
        "        sheet_success = 0\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            # Check if we already have this bus's data in cache\n",
        "            if bus in bus_worksheet_cache:\n",
        "                sheet_data = bus_worksheet_cache[bus]\n",
        "            else:\n",
        "                # Fetch the bus worksheet data and store in cache\n",
        "                sheet = Odometer_spreadsheet_FG.worksheet(bus)\n",
        "                sheet_data = sheet.get_all_values()\n",
        "                bus_worksheet_cache[bus] = sheet_data\n",
        "\n",
        "            # Create a dictionary for faster exact date lookups\n",
        "            date_value_lookup = {}\n",
        "            for row in sheet_data[1:]:\n",
        "                try:\n",
        "                    if len(row) > 12:\n",
        "                        date_str_key = row[1].strip()\n",
        "                        date_value_lookup[date_str_key] = row[12]  # Column M\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            for date_str in dates:\n",
        "                # Check for exact match using the lookup dictionary\n",
        "                exact_value = date_value_lookup.get(date_str)\n",
        "\n",
        "                if exact_value:\n",
        "                    results.append((bus, date_str, exact_value, \"exact\", \"\"))\n",
        "                    sheet_success += 1\n",
        "                else:\n",
        "                    # Try to find closest earlier date\n",
        "                    value, fallback_date = find_closest_date_value(sheet_data, date_str, value_column_index=12)\n",
        "                    if value:\n",
        "                        results.append((bus, date_str, value, \"fallback\", fallback_date))\n",
        "                        sheet_success += 1\n",
        "\n",
        "            print(f\"  ‚úÖ Found {sheet_success}/{len(dates)} values for bus {bus}\")\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Could not process sheet '{bus}': {str(e)}\")\n",
        "            return []\n",
        "\n",
        "    # Process buses in parallel using ThreadPoolExecutor\n",
        "    print(f\"üöÄ Processing {len(bus_date_map)} buses in parallel...\")\n",
        "\n",
        "    # Convert to list for ThreadPoolExecutor\n",
        "    bus_dates_list = list(bus_date_map.items())\n",
        "\n",
        "    # Use ThreadPoolExecutor for parallel processing\n",
        "    # Adjust max_workers based on your system's capabilities\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        all_results = list(executor.map(process_bus, bus_dates_list))\n",
        "\n",
        "    # Process all results\n",
        "    for bus_results in all_results:\n",
        "        for bus, date_str, value, match_type, fallback_date in bus_results:\n",
        "            bus_date_value_map[(bus, date_str)] = value\n",
        "            match_type_map[(bus, date_str)] = match_type\n",
        "            fallback_date_map[(bus, date_str)] = fallback_date\n",
        "\n",
        "            if match_type == \"exact\":\n",
        "                success_count += 1\n",
        "            else:\n",
        "                fallback_count += 1\n",
        "\n",
        "    print(f\"\\n‚úÖ Found values for {success_count} exact date matches\")\n",
        "    print(f\"‚úÖ Found values for {fallback_count} fallback date matches\")\n",
        "    print(f\"‚ùå Could not find values for {len(row_map) - (success_count + fallback_count)} dates\")\n",
        "\n",
        "    # Step 3: Update values into Column L of main sheet and fallback dates into Column M\n",
        "    print(f\"\\nüìù Preparing batch updates for {worksheet_name}...\")\n",
        "\n",
        "    # Prepare batch update for all cells at once\n",
        "    batch_updates = []\n",
        "    exact_match_cells = []\n",
        "    fallback_match_cells = []\n",
        "\n",
        "    for row_num, (bus, date_str) in row_map.items():\n",
        "        value = bus_date_value_map.get((bus, date_str), \"\")\n",
        "        fallback_date = fallback_date_map.get((bus, date_str), \"\")\n",
        "\n",
        "        if value:\n",
        "            # Add to batch updates list (row, col, value)\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 12,  # Column L\n",
        "                'value': value\n",
        "            })\n",
        "\n",
        "            # Add fallback date update\n",
        "            batch_updates.append({\n",
        "                'row': row_num,\n",
        "                'col': 13,  # Column M\n",
        "                'value': fallback_date\n",
        "            })\n",
        "\n",
        "            # Track which cells need which formatting\n",
        "            match_type = match_type_map.get((bus, date_str))\n",
        "            if match_type == \"exact\":\n",
        "                exact_match_cells.append(f\"L{row_num}\")\n",
        "            elif match_type == \"fallback\":\n",
        "                fallback_match_cells.append(f\"L{row_num}\")\n",
        "\n",
        "    print(f\"‚úÖ Prepared {len(batch_updates)} cell updates\")\n",
        "\n",
        "    # Execute batch updates in chunks to avoid rate limits\n",
        "    updated_count = 0\n",
        "    chunk_size = 50  # Adjust based on API limits\n",
        "    chunks = math.ceil(len(batch_updates) / chunk_size)\n",
        "\n",
        "    print(f\"üîÑ Executing batch updates in {chunks} chunks...\")\n",
        "\n",
        "    for chunk_index in range(chunks):\n",
        "        start_idx = chunk_index * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, len(batch_updates))\n",
        "        current_chunk = batch_updates[start_idx:end_idx]\n",
        "\n",
        "        max_retries = 5\n",
        "        retry_count = 0\n",
        "        update_successful = False\n",
        "\n",
        "        while not update_successful and retry_count < max_retries:\n",
        "            try:\n",
        "                # Prepare the batch update request\n",
        "                cell_list = []\n",
        "\n",
        "                for update in current_chunk:\n",
        "                    cell = worksheet.cell(update['row'], update['col'])\n",
        "                    cell.value = update['value']\n",
        "                    cell_list.append(cell)\n",
        "\n",
        "                # Execute the batch update\n",
        "                worksheet.update_cells(cell_list, value_input_option='USER_ENTERED')\n",
        "\n",
        "                update_successful = True\n",
        "                updated_count += len(current_chunk) // 2  # Divide by 2 because we have 2 cells per row\n",
        "                print(f\"üìä Progress: Chunk {chunk_index+1}/{chunks} complete - {updated_count}/{len(batch_updates)//2} rows updated\")\n",
        "\n",
        "                # Add a small delay between chunks to avoid rate limits\n",
        "                time.sleep(1)\n",
        "\n",
        "            except Exception as e:\n",
        "                retry_count += 1\n",
        "                if \"429\" in str(e):\n",
        "                    wait_time = (2 ** retry_count) + random.random()\n",
        "                    print(f\"‚è≥ Rate limit hit, waiting for {wait_time:.2f} seconds (retry {retry_count}/{max_retries})\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"‚ùå Failed to update chunk {chunk_index+1}: {e}\")\n",
        "                    break\n",
        "\n",
        "        if not update_successful:\n",
        "            print(f\"‚ùå Failed to update chunk {chunk_index+1} after {max_retries} retries\")\n",
        "\n",
        "    # Apply formatting in batches (currently commented out)\n",
        "    print(\"\\nüé® Applying formatting to distinguish match types...\")\n",
        "    # You can uncomment and implement batch formatting logic if needed.\n",
        "\n",
        "    print(f\"\\n‚úÖ COMPLETE for {worksheet_name}: Updated {updated_count} rows in column L and column M\")\n",
        "    print(f\"üìä Summary: {success_count} exact matches (normal format), {fallback_count} fallback matches (italic and right-aligned)\")\n",
        "    print(f\"‚ùå {len(row_map) - updated_count} rows could not be updated\")\n",
        "\n",
        "# Main execution\n",
        "print(\"üöÄ Starting to process all engine oil worksheets...\")\n",
        "\n",
        "# Create a global cache for bus worksheets to reuse across all worksheets\n",
        "global_bus_worksheet_cache = {}\n",
        "\n",
        "# Process each worksheet in sequence\n",
        "for worksheet_name in engine_oil_worksheets:\n",
        "    print(f\"\\n{'='*80}\\nüìä Processing worksheet: {worksheet_name}\\n{'='*80}\")\n",
        "    process_worksheet(worksheet_name)\n",
        "    # Add a delay between worksheets to avoid rate limiting\n",
        "    time.sleep(2)\n",
        "\n",
        "print(\"\\n‚úÖ All worksheets have been processed successfully!\")\n",
        "print(\"üí° Performance Summary:\")\n",
        "print(f\"‚úì Processed {len(engine_oil_worksheets)} worksheets with batch processing\")\n",
        "print(f\"‚úì Used parallel processing for bus data with ThreadPoolExecutor\")\n",
        "print(f\"‚úì Implemented caching to reduce API calls\")\n",
        "print(f\"‚úì Used batch updates to minimize API requests\")\n"
      ],
      "metadata": {
        "id": "ng3__2UKVfZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code for Generating report, bus number and as on date"
      ],
      "metadata": {
        "id": "Ghp56z_bBBxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If date is current date then it is returning the spreadsheet name, trying to correct, It is wokring, i will delete above code in version 1.0.9\n",
        "\n",
        "# High speed Report Generation, in Engine Oil Report Spreadsheet\n",
        "\n",
        "from datetime import datetime\n",
        "import re\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import functools\n",
        "import concurrent.futures\n",
        "import threading\n",
        "\n",
        "# === PERFORMANCE OPTIMIZATION SETUP ===\n",
        "print(\"üöÄ Initializing performance optimizations...\")\n",
        "\n",
        "# Cache for worksheet data to reduce API calls\n",
        "data_cache = {}\n",
        "cache_lock = threading.Lock()\n",
        "\n",
        "# LRU Cache decorator for expensive operations\n",
        "def lru_cache_with_expiry(maxsize=128, typed=False, ttl=600):\n",
        "    \"\"\"LRU Cache with expiry time\"\"\"\n",
        "    def decorator(func):\n",
        "        cache_dict = {}\n",
        "        cache_times = {}\n",
        "        cache_lock = threading.Lock()\n",
        "\n",
        "        @functools.wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            key = str(args) + str(kwargs)\n",
        "            current_time = time.time()\n",
        "\n",
        "            with cache_lock:\n",
        "                # Check if key exists and not expired\n",
        "                if key in cache_dict and current_time - cache_times[key] < ttl:\n",
        "                    return cache_dict[key]\n",
        "\n",
        "                # Call the function and cache result\n",
        "                result = func(*args, **kwargs)\n",
        "                cache_dict[key] = result\n",
        "                cache_times[key] = current_time\n",
        "\n",
        "                # Remove oldest entries if cache is too large\n",
        "                if len(cache_dict) > maxsize:\n",
        "                    oldest_key = min(cache_times, key=cache_times.get)\n",
        "                    cache_dict.pop(oldest_key)\n",
        "                    cache_times.pop(oldest_key)\n",
        "\n",
        "                return result\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Batch processing helper functions\n",
        "def chunk_list(lst, chunk_size):\n",
        "    \"\"\"Split list into chunks of specified size\"\"\"\n",
        "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "# Cached function to get worksheet data\n",
        "@lru_cache_with_expiry(maxsize=100, ttl=300)  # Cache for 5 minutes\n",
        "def get_worksheet_data(spreadsheet_name, worksheet_name):\n",
        "    \"\"\"Get worksheet data with caching\"\"\"\n",
        "    cache_key = f\"{spreadsheet_name}:{worksheet_name}\"\n",
        "\n",
        "    with cache_lock:\n",
        "        if cache_key in data_cache:\n",
        "            print(f\"üìã Cache hit for {cache_key}\")\n",
        "            return data_cache[cache_key]\n",
        "\n",
        "    # Function to find the actual worksheet object\n",
        "    def find_worksheet(spreadsheet_list, worksheet_name, spreadsheet_names):\n",
        "        for idx, spreadsheet in enumerate(spreadsheet_list):\n",
        "            try:\n",
        "                sheet = spreadsheet.worksheet(worksheet_name)\n",
        "                print(f\"üìë Found worksheet {worksheet_name} in {spreadsheet_names[idx]}\")\n",
        "                return sheet, spreadsheet_names[idx]\n",
        "            except Exception:\n",
        "                continue\n",
        "        return None, None\n",
        "\n",
        "    # Cache miss, need to retrieve data\n",
        "    try:\n",
        "        sheet, source = find_worksheet(odometer_spreadsheets, worksheet_name, spreadsheet_names)\n",
        "        if sheet:\n",
        "            data = sheet.get_all_values()\n",
        "\n",
        "            with cache_lock:\n",
        "                data_cache[cache_key] = (data, source)\n",
        "\n",
        "            return data, source\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error retrieving data for {worksheet_name}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# === STEP 1: CLEAR DATA ===\n",
        "print(\"\\nüßπ STEP 1: Clearing data...\")\n",
        "clear_range_all_OdometersheetID = 'A5:R200'\n",
        "clear_range_all_Report_EO1_Worksheet = ['B2:B200', 'AC2:AC200']\n",
        "\n",
        "OdometersheetID.batch_clear([clear_range_all_OdometersheetID])\n",
        "Report_EO1_Worksheet.batch_clear(clear_range_all_Report_EO1_Worksheet)\n",
        "\n",
        "# === STEP 2: PROCESS BUS DATA ===\n",
        "print(\"\\nüìä STEP 2: Processing bus data...\")\n",
        "\n",
        "# Function to process spreadsheet data in parallel\n",
        "def process_spreadsheet(cell_ref, position_index):\n",
        "    \"\"\"Process a single spreadsheet and return its data\"\"\"\n",
        "    odometer_id = OdometersheetID.acell(cell_ref).value\n",
        "    spreadsheet = gc.open_by_key(odometer_id)\n",
        "    bus_numbers = sorted([worksheet.title for worksheet in spreadsheet])\n",
        "    spreadsheet_name = spreadsheet.title\n",
        "    return {\n",
        "        'spreadsheet': spreadsheet,\n",
        "        'name': spreadsheet_name,\n",
        "        'buses': bus_numbers,\n",
        "        'position': position_index\n",
        "    }\n",
        "\n",
        "# Process all spreadsheets in parallel\n",
        "spreadsheet_info = {\n",
        "    'SVP': {'cell': 'A2', 'position': 0},\n",
        "    'FG': {'cell': 'B2', 'position': 1},\n",
        "    'BT': {'cell': 'C2', 'position': 2},\n",
        "    'RT': {'cell': 'D2', 'position': 3},\n",
        "    'MB': {'cell': 'E2', 'position': 4},\n",
        "    'DP': {'cell': 'F2', 'position': 5}\n",
        "}\n",
        "\n",
        "spreadsheet_data = {}\n",
        "odometer_spreadsheets = [None] * 6\n",
        "spreadsheet_names = [None] * 6\n",
        "\n",
        "# For Google Sheets API, we can't fully parallelize due to rate limits\n",
        "# But we can optimize the processing steps\n",
        "for key, info in spreadsheet_info.items():\n",
        "    data = process_spreadsheet(info['cell'], info['position'])\n",
        "    spreadsheet_data[key] = data\n",
        "    odometer_spreadsheets[info['position']] = data['spreadsheet']\n",
        "    spreadsheet_names[info['position']] = data['name']\n",
        "    print(f\"‚úÖ Processed {key} spreadsheet: {data['name']} with {len(data['buses'])} buses\")\n",
        "\n",
        "# Calculate starting rows for each section\n",
        "start_row_svp = 2\n",
        "start_row_fg = start_row_svp + len(spreadsheet_data['SVP']['buses'])\n",
        "start_row_bt = start_row_fg + len(spreadsheet_data['FG']['buses'])\n",
        "start_row_rt = start_row_bt + len(spreadsheet_data['BT']['buses'])\n",
        "start_row_mb = start_row_rt + len(spreadsheet_data['RT']['buses'])\n",
        "start_row_dp = start_row_mb + len(spreadsheet_data['MB']['buses'])\n",
        "\n",
        "# === STEP 3: UPDATE ODOMETERSHEETID WITH BUS NUMBERS ===\n",
        "print(\"\\nüìù STEP 3: Updating OdometersheetID with bus numbers...\")\n",
        "\n",
        "# Optimized batch update function\n",
        "def optimized_batch_update(worksheet, updates):\n",
        "    \"\"\"Process updates in optimal batch sizes\"\"\"\n",
        "    BATCH_SIZE = 100  # Adjust based on API limits\n",
        "\n",
        "    # Split updates into manageable chunks\n",
        "    chunked_updates = chunk_list(updates, BATCH_SIZE)\n",
        "\n",
        "    for chunk in chunked_updates:\n",
        "        try:\n",
        "            worksheet.batch_update(chunk)\n",
        "            time.sleep(0.5)  # Slight delay to avoid rate limiting\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Batch update error: {e}\")\n",
        "            # Fall back to smaller chunks if needed\n",
        "            for update in chunk:\n",
        "                try:\n",
        "                    worksheet.update(update['range'], update['values'])\n",
        "                    time.sleep(0.1)\n",
        "                except Exception as e2:\n",
        "                    print(f\"‚ö†Ô∏è Individual update error at {update['range']}: {e2}\")\n",
        "\n",
        "# Update spreadsheet names in row 4 (batch update)\n",
        "name_updates = [\n",
        "    {'range': 'A4', 'values': [[spreadsheet_data['SVP']['name']]]},\n",
        "    {'range': 'B4', 'values': [[spreadsheet_data['FG']['name']]]},\n",
        "    {'range': 'C4', 'values': [[spreadsheet_data['BT']['name']]]},\n",
        "    {'range': 'D4', 'values': [[spreadsheet_data['RT']['name']]]},\n",
        "    {'range': 'E4', 'values': [[spreadsheet_data['MB']['name']]]},\n",
        "    {'range': 'F4', 'values': [[spreadsheet_data['DP']['name']]]}\n",
        "]\n",
        "OdometersheetID.batch_update(name_updates)\n",
        "print(\"‚úÖ Updated all spreadsheet names in row 4\")\n",
        "\n",
        "# Generate all updates for bus numbers\n",
        "all_bus_updates = []\n",
        "\n",
        "# Helper function to create batch updates for a column\n",
        "def create_column_updates(column_letter, start_row, buses):\n",
        "    updates = []\n",
        "    for i, bus in enumerate(buses):\n",
        "        row = start_row + i\n",
        "        # Try to convert numeric strings to integers\n",
        "        try:\n",
        "            if isinstance(bus, str) and bus.isdigit():\n",
        "                bus = int(bus)\n",
        "        except:\n",
        "            pass\n",
        "        updates.append({\n",
        "            'range': f'{column_letter}{row}',\n",
        "            'values': [[bus]]\n",
        "        })\n",
        "    return updates\n",
        "\n",
        "# Create all updates for bus numbers\n",
        "all_bus_updates.extend(create_column_updates('A', 5, spreadsheet_data['SVP']['buses']))\n",
        "all_bus_updates.extend(create_column_updates('B', 5, spreadsheet_data['FG']['buses']))\n",
        "all_bus_updates.extend(create_column_updates('C', 5, spreadsheet_data['BT']['buses']))\n",
        "all_bus_updates.extend(create_column_updates('D', 5, spreadsheet_data['RT']['buses']))\n",
        "all_bus_updates.extend(create_column_updates('E', 5, spreadsheet_data['MB']['buses']))\n",
        "all_bus_updates.extend(create_column_updates('F', 5, spreadsheet_data['DP']['buses']))\n",
        "\n",
        "# Batch update OdometersheetID with bus numbers\n",
        "optimized_batch_update(OdometersheetID, all_bus_updates)\n",
        "print(f\"‚úÖ Updated {len(all_bus_updates)} bus entries in OdometersheetID\")\n",
        "\n",
        "# === STEP 4: UPDATE REPORT_EO1 WORKSHEET WITH ALL BUS NUMBERS ===\n",
        "print(\"\\nüìä STEP 4: Updating Report_EO1 with all bus numbers...\")\n",
        "\n",
        "# Combine all bus lists for ReportA_EO1\n",
        "all_buses_with_sources = []\n",
        "for key, data in spreadsheet_data.items():\n",
        "    for bus in data['buses']:\n",
        "        all_buses_with_sources.append((bus, data['name']))\n",
        "\n",
        "# Generate batch updates for Report_EO1\n",
        "report_EO1_updates = []\n",
        "for i, (bus, source) in enumerate(all_buses_with_sources):\n",
        "    row = i + 2  # Start from row 2\n",
        "    # Try to convert numeric strings to integers\n",
        "    try:\n",
        "        if isinstance(bus, str) and bus.isdigit():\n",
        "            bus = int(bus)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    report_EO1_updates.append({\n",
        "        'range': f'B{row}',\n",
        "        'values': [[bus]]\n",
        "    })\n",
        "    report_EO1_updates.append({\n",
        "        'range': f'AC{row}',\n",
        "        'values': [[source]]\n",
        "    })\n",
        "\n",
        "# Batch update Report_EO1\n",
        "optimized_batch_update(Report_EO1_Worksheet, report_EO1_updates)\n",
        "print(f\"‚úÖ Updated {len(all_buses_with_sources)} bus entries in Report_EO1 worksheet\")\n",
        "\n",
        "print(\"üéâ Bus data preparation completed successfully!\")\n",
        "\n",
        "# === STEP 5: SEARCH FOR ODOMETER VALUES ===\n",
        "print(\"\\nüîç STEP 5: Searching for odometer values...\")\n",
        "\n",
        "# Clear columns C and D\n",
        "Report_EO1_Worksheet.batch_clear([\"C2:D\"])\n",
        "\n",
        "# Get current date in expected format (e.g., \"05,May25\")\n",
        "current_date_str = datetime.now().strftime('%d,%b%y')\n",
        "\n",
        "# Get main data from Report_EO1\n",
        "main_data = Report_EO1_Worksheet.get_all_values()\n",
        "header, rows = main_data[0], main_data[1:]\n",
        "\n",
        "# Map each row to bus + date (using today's date)\n",
        "row_map = {}\n",
        "bus_set = set()\n",
        "for i, row in enumerate(rows, start=2):\n",
        "    try:\n",
        "        if len(row) > 1:  # Make sure row has at least 2 columns\n",
        "            bus = re.sub(r'[^a-zA-Z0-9]', '', str(row[1]).strip()).upper()  # Clean bus name\n",
        "            if bus:\n",
        "                row_map[i] = (bus, current_date_str)\n",
        "                bus_set.add(bus)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing row {i}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"üîé Total buses to process: {len(bus_set)}\")\n",
        "if bus_set:\n",
        "    print(\"Sample buses:\", list(bus_set)[:5])  # Log first 5 buses\n",
        "\n",
        "# Initialize lookup maps with thread safety\n",
        "bus_date_value_map = {}\n",
        "match_type_map = {}\n",
        "fallback_date_map = {}\n",
        "source_spreadsheet_map = {}\n",
        "map_lock = threading.Lock()\n",
        "\n",
        "# Function to find closest earlier date value\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=12):\n",
        "    \"\"\"Find closest earlier date with a value in the specified column\"\"\"\n",
        "    if not sheet_data:\n",
        "        return None, \"\"\n",
        "\n",
        "    try:\n",
        "        target_date = datetime.strptime(target_date_str, '%d,%b%y')\n",
        "        valid_rows = []\n",
        "\n",
        "        for row in sheet_data[1:]:  # Skip header\n",
        "            if len(row) <= value_column_index:\n",
        "                continue\n",
        "\n",
        "            date_cell = row[1].strip() if len(row) > 1 else \"\"\n",
        "            value_cell = row[value_column_index].strip() if len(row) > value_column_index else \"\"\n",
        "\n",
        "            if not date_cell or not value_cell:\n",
        "                continue\n",
        "\n",
        "            # Try multiple date formats\n",
        "            parsed_date = None\n",
        "            for fmt in ['%d,%b%y', '%d-%b-%y', '%d/%b/%y']:\n",
        "                try:\n",
        "                    parsed_date = datetime.strptime(date_cell, fmt)\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if parsed_date and parsed_date <= target_date and value_cell:\n",
        "                valid_rows.append((parsed_date, date_cell, value_cell))\n",
        "\n",
        "        if valid_rows:\n",
        "            valid_rows.sort(key=lambda x: x[0], reverse=True)  # Newest date first\n",
        "            best = valid_rows[0]\n",
        "            return best[2], best[1]  # value, fallback_date\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error in fallback for {target_date_str}: {e}\")\n",
        "\n",
        "    return None, \"\"\n",
        "\n",
        "# Process a single bus to find odometer value\n",
        "def process_bus_odometer(bus):\n",
        "    \"\"\"Process odometer data for a single bus\"\"\"\n",
        "    found = False\n",
        "\n",
        "    # Use the cached function to get worksheet data\n",
        "    data, source = get_worksheet_data(\"All\", bus)\n",
        "\n",
        "    if data:\n",
        "        found = True\n",
        "        # Check for exact date match\n",
        "        exact_match = False\n",
        "        for row in data[1:]:  # Skip header\n",
        "            if len(row) > 12 and row[1].strip() == current_date_str and row[12].strip():\n",
        "                odometer_val = row[12].strip()\n",
        "                if odometer_val and odometer_val.isdigit():  # Validate numeric\n",
        "                    with map_lock:\n",
        "                        bus_date_value_map[(bus, current_date_str)] = odometer_val\n",
        "                        match_type_map[(bus, current_date_str)] = \"exact\"\n",
        "                        fallback_date_map[(bus, current_date_str)] = current_date_str  # Store current date\n",
        "                        source_spreadsheet_map[(bus, current_date_str)] = source\n",
        "                    exact_match = True\n",
        "                    print(f\"üìå Bus {bus}: Exact match: {odometer_val} km on {current_date_str}\")\n",
        "                    break\n",
        "\n",
        "        if not exact_match:\n",
        "            # Fallback to closest date\n",
        "            val, fallback_date = find_closest_date_value(data, current_date_str, 12)\n",
        "            if val:\n",
        "                with map_lock:\n",
        "                    bus_date_value_map[(bus, current_date_str)] = val\n",
        "                    match_type_map[(bus, current_date_str)] = \"fallback\"\n",
        "                    fallback_date_map[(bus, current_date_str)] = fallback_date\n",
        "                    source_spreadsheet_map[(bus, current_date_str)] = source\n",
        "                print(f\"üîÑ Bus {bus}: Fallback match: {val} km on {fallback_date}\")\n",
        "\n",
        "    if not found:\n",
        "        print(f\"üö® Bus {bus} not found in ANY spreadsheet!\")\n",
        "\n",
        "    return found\n",
        "\n",
        "# Process buses in parallel batches\n",
        "MAX_WORKERS = 5  # Adjust based on API limits\n",
        "BATCH_SIZE = 10  # Process this many buses at once\n",
        "\n",
        "def process_buses_in_batches(buses):\n",
        "    \"\"\"Process buses in parallel batches\"\"\"\n",
        "    total = len(buses)\n",
        "    completed = 0\n",
        "\n",
        "    bus_chunks = chunk_list(list(buses), BATCH_SIZE)\n",
        "\n",
        "    for chunk in bus_chunks:\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(chunk))) as executor:\n",
        "            futures = {executor.submit(process_bus_odometer, bus): bus for bus in chunk}\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                bus = futures[future]\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    completed += 1\n",
        "                    if completed % 10 == 0 or completed == total:\n",
        "                        print(f\"Progress: {completed}/{total} buses processed ({completed/total:.1%})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Error processing bus {bus}: {e}\")\n",
        "\n",
        "        # Small delay between batches to avoid API rate limits\n",
        "        time.sleep(1)\n",
        "\n",
        "    print(f\"‚úÖ Completed processing all {total} buses\")\n",
        "\n",
        "# Process all buses in batches\n",
        "if bus_set:\n",
        "    process_buses_in_batches(bus_set)\n",
        "\n",
        "# Update Report_EO1 with logging\n",
        "print(\"\\nüìù Writing data to Report_EO1...\")\n",
        "updated_rows = []\n",
        "for row_idx, (bus, date_str) in row_map.items():\n",
        "    key = (bus, date_str)\n",
        "    val = bus_date_value_map.get(key, \"\")\n",
        "    fallback = fallback_date_map.get(key, \"\")\n",
        "    match_type = match_type_map.get(key, \"\")\n",
        "    source = source_spreadsheet_map.get(key, \"\")\n",
        "\n",
        "    # Improved logic for Column C (date) and Column D (value)\n",
        "    if match_type == \"exact\":\n",
        "        # For exact matches, use the current date (date_str)\n",
        "        col_c = date_str\n",
        "        col_d = val if val else \"\"\n",
        "    elif match_type == \"fallback\":\n",
        "        # For fallback matches, use the fallback date we found\n",
        "        col_c = fallback if fallback else \"\"\n",
        "        col_d = val if val else \"\"\n",
        "    else:\n",
        "        # No match found\n",
        "        col_c = \"\"\n",
        "        col_d = \"\"\n",
        "\n",
        "    # Add to batch update\n",
        "    updated_rows.append([col_c, col_d])\n",
        "\n",
        "# Prepare batch update\n",
        "if updated_rows:\n",
        "    # Split into manageable chunks\n",
        "    MAX_ROWS_PER_UPDATE = 1000  # Adjust based on API limits\n",
        "    row_chunks = chunk_list(updated_rows, MAX_ROWS_PER_UPDATE)\n",
        "\n",
        "    for i, chunk in enumerate(row_chunks):\n",
        "        start_row = 2 + i * MAX_ROWS_PER_UPDATE\n",
        "        end_row = start_row + len(chunk) - 1\n",
        "        range_to_update = f\"C{start_row}:D{end_row}\"\n",
        "\n",
        "        Report_EO1_Worksheet.update(range_to_update, chunk)\n",
        "        print(f\"‚úÖ Updated rows {start_row}-{end_row} in Report_EO1\")\n",
        "\n",
        "        # Small delay between batch updates\n",
        "        if i < len(row_chunks) - 1:\n",
        "            time.sleep(1)\n",
        "\n",
        "    print(f\"‚úÖ All {len(updated_rows)} rows updated successfully in Report_EO1!\")\n",
        "else:\n",
        "    print(\"‚ùå No updates made to Report_EO1.\")\n",
        "\n",
        "print(\"üéâ Complete script execution finished successfully!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sBULhR5luXmc",
        "outputId": "0e1ed054-2f6e-40ce-e065-6d51191b1358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing performance optimizations...\n",
            "\n",
            "üßπ STEP 1: Clearing data...\n",
            "\n",
            "üìä STEP 2: Processing bus data...\n",
            "‚úÖ Processed SVP spreadsheet: Odometer_SVP with 59 buses\n",
            "‚úÖ Processed FG spreadsheet: Odometer_FG with 20 buses\n",
            "‚úÖ Processed BT spreadsheet: Odometer_BT with 1 buses\n",
            "‚úÖ Processed RT spreadsheet: Odometer_RT with 1 buses\n",
            "‚úÖ Processed MB spreadsheet: Odometer_MB with 1 buses\n",
            "‚úÖ Processed DP spreadsheet: Odometer_DP with 1 buses\n",
            "\n",
            "üìù STEP 3: Updating OdometersheetID with bus numbers...\n",
            "‚úÖ Updated all spreadsheet names in row 4\n",
            "‚úÖ Updated 83 bus entries in OdometersheetID\n",
            "\n",
            "üìä STEP 4: Updating Report_EO1 with all bus numbers...\n",
            "‚úÖ Updated 83 bus entries in Report_EO1 worksheet\n",
            "üéâ Bus data preparation completed successfully!\n",
            "\n",
            "üîç STEP 5: Searching for odometer values...\n",
            "üîé Total buses to process: 83\n",
            "Sample buses: ['474', '495', '572', '584', '546']\n",
            "üìë Found worksheet 474 in Odometer_SVP\n",
            "üîÑ Bus 474: Fallback match: 373878 km on 20,May25\n",
            "üìë Found worksheet 495 in Odometer_SVP\n",
            "üîÑ Bus 495: Fallback match: 586440 km on 16,May25\n",
            "üìë Found worksheet 572 in Odometer_FG\n",
            "üîÑ Bus 572: Fallback match: 465564 km on 18,May25\n",
            "üìë Found worksheet 584 in Odometer_SVP\n",
            "üîÑ Bus 584: Fallback match: 190961 km on 10,Aug24\n",
            "üìë Found worksheet 546 in Odometer_SVP\n",
            "üîÑ Bus 546: Fallback match: 536047 km on 20,May25\n",
            "üìë Found worksheet 593 in Odometer_FG\n",
            "üîÑ Bus 593: Fallback match: 397381 km on 18,May25\n",
            "üìë Found worksheet 457 in Odometer_SVP\n",
            "üîÑ Bus 457: Fallback match: 412660 km on 20,May25\n",
            "üìë Found worksheet 550 in Odometer_SVP\n",
            "üîÑ Bus 550: Fallback match: 680832 km on 14,Oct24\n",
            "üìë Found worksheet 616 in Odometer_FG\n",
            "üîÑ Bus 616: Fallback match: 73304 km on 17,May25\n",
            "üìë Found worksheet 523 in Odometer_SVP\n",
            "üîÑ Bus 523: Fallback match: 281016 km on 23,Apr25\n",
            "Progress: 10/83 buses processed (12.0%)\n",
            "üìë Found worksheet 461 in Odometer_FG\n",
            "üîÑ Bus 461: Fallback match: 333224 km on 17,May25\n",
            "üìë Found worksheet 970 in Odometer_DP\n",
            "üîÑ Bus 970: Fallback match: 374592 km on 20,May25\n",
            "üìë Found worksheet 604 in Odometer_SVP\n",
            "üîÑ Bus 604: Fallback match: 117937 km on 20,May25\n",
            "üìë Found worksheet 574 in Odometer_SVP\n",
            "üîÑ Bus 574: Fallback match: 548919 km on 02,Dec24\n",
            "üìë Found worksheet 463 in Odometer_FG\n",
            "üîÑ Bus 463: Fallback match: 254649 km on 18,May25\n",
            "üìë Found worksheet 578 in Odometer_SVP\n",
            "üîÑ Bus 578: Fallback match: 475435 km on 19,May25\n",
            "üìë Found worksheet 507 in Odometer_FG\n",
            "üîÑ Bus 507: Fallback match: 401843 km on 18,May25\n",
            "üìë Found worksheet 613 in Odometer_SVP\n",
            "üîÑ Bus 613: Fallback match: 53915 km on 17,Mar25\n",
            "üìë Found worksheet 598 in Odometer_SVP\n",
            "üîÑ Bus 598: Fallback match: 117388 km on 19,May25\n",
            "üìë Found worksheet 577 in Odometer_SVP\n",
            "üîÑ Bus 577: Fallback match: 617797 km on 20,May25\n",
            "Progress: 20/83 buses processed (24.1%)\n",
            "üìë Found worksheet 615 in Odometer_FG\n",
            "üîÑ Bus 615: Fallback match: 58260 km on 25,Apr25\n",
            "üìë Found worksheet 535 in Odometer_SVP\n",
            "üîÑ Bus 535: Fallback match: 348104 km on 13,May25\n",
            "üìë Found worksheet 444 in Odometer_SVP\n",
            "üîÑ Bus 444: Fallback match: 304260 km on 20,May25\n",
            "üìë Found worksheet 475 in Odometer_SVP\n",
            "üîÑ Bus 475: Fallback match: 327218 km on 12,Apr25\n",
            "üìë Found worksheet 596 in Odometer_SVP\n",
            "üîÑ Bus 596: Fallback match: 98375 km on 20,May25\n",
            "üìë Found worksheet 575 in Odometer_SVP\n",
            "üîÑ Bus 575: Fallback match: 391243 km on 13,Nov24\n",
            "üìë Found worksheet 459 in Odometer_SVP\n",
            "üîÑ Bus 459: Fallback match: 160143 km on 20,May25\n",
            "üìë Found worksheet 548 in Odometer_SVP\n",
            "üîÑ Bus 548: Fallback match: 589252 km on 19,May25\n",
            "üìë Found worksheet 589 in Odometer_SVP\n",
            "üîÑ Bus 589: Fallback match: 197762 km on 04,Mar25\n",
            "üìë Found worksheet 530 in Odometer_SVP\n",
            "üîÑ Bus 530: Fallback match: 398272 km on 20,May25\n",
            "Progress: 30/83 buses processed (36.1%)\n",
            "üìë Found worksheet 489 in Odometer_SVP\n",
            "üîÑ Bus 489: Fallback match: 103604 km on 11,Oct16\n",
            "üìë Found worksheet 438 in Odometer_FG\n",
            "üîÑ Bus 438: Fallback match: 320141 km on 18,May25\n",
            "üìë Found worksheet 460 in Odometer_SVP\n",
            "üîÑ Bus 460: Fallback match: 367360 km on 06,Feb25\n",
            "üìë Found worksheet 518 in Odometer_SVP\n",
            "üîÑ Bus 518: Fallback match: 257082 km on 15,Apr20\n",
            "üìë Found worksheet 592 in Odometer_FG\n",
            "üîÑ Bus 592: Fallback match: 371276 km on 18,May25\n",
            "üìë Found worksheet 534 in Odometer_SVP\n",
            "üîÑ Bus 534: Fallback match: 310194 km on 20,May25\n",
            "üìë Found worksheet 508 in Odometer_SVP\n",
            "üîÑ Bus 508: Fallback match: 380534 km on 20,May25\n",
            "üìë Found worksheet 462 in Odometer_SVP\n",
            "üîÑ Bus 462: Fallback match: 394987 km on 20,May25\n",
            "üìë Found worksheet 560 in Odometer_FG\n",
            "üîÑ Bus 560: Fallback match: 582071 km on 18,May25\n",
            "üìë Found worksheet 511 in Odometer_SVP\n",
            "üîÑ Bus 511: Fallback match: 250716 km on 13,May25\n",
            "Progress: 40/83 buses processed (48.2%)\n",
            "üìë Found worksheet 562 in Odometer_FG\n",
            "üîÑ Bus 562: Fallback match: 592136 km on 18,May25\n",
            "üìë Found worksheet 471 in Odometer_SVP\n",
            "üîÑ Bus 471: Fallback match: 403341 km on 20,May25\n",
            "üìë Found worksheet 564 in Odometer_SVP\n",
            "üîÑ Bus 564: Fallback match: 573079 km on 16,May24\n",
            "üìë Found worksheet 493 in Odometer_FG\n",
            "üîÑ Bus 493: Fallback match: 284199 km on 01,May25\n",
            "üìë Found worksheet 597 in Odometer_SVP\n",
            "üîÑ Bus 597: Fallback match: 123458 km on 20,May25\n",
            "üìë Found worksheet 563 in Odometer_SVP\n",
            "üîÑ Bus 563: Fallback match: 734815 km on 20,May25\n",
            "üìë Found worksheet 441 in Odometer_SVP\n",
            "üîÑ Bus 441: Fallback match: 278164 km on 12,Apr25\n",
            "üìë Found worksheet 478 in Odometer_FG\n",
            "üîÑ Bus 478: Fallback match: 290808 km on 17,May25\n",
            "üìë Found worksheet 605 in Odometer_SVP\n",
            "üîÑ Bus 605: Fallback match: 102304 km on 20,May25\n",
            "üìë Found worksheet 599 in Odometer_SVP\n",
            "üîÑ Bus 599: Fallback match: 102967 km on 20,May25\n",
            "Progress: 50/83 buses processed (60.2%)\n",
            "üìë Found worksheet 595 in Odometer_SVP\n",
            "üîÑ Bus 595: Fallback match: 281717 km on 17,May25\n",
            "üìë Found worksheet 573 in Odometer_FG\n",
            "üîÑ Bus 573: Fallback match: 541489 km on 18,May25\n",
            "üìë Found worksheet 587 in Odometer_SVP\n",
            "üîÑ Bus 587: Fallback match: 298025 km on 19,May25\n",
            "üìë Found worksheet 561 in Odometer_FG\n",
            "üîÑ Bus 561: Fallback match: 572860 km on 18,May25\n",
            "üìë Found worksheet 469 in Odometer_SVP\n",
            "üîÑ Bus 469: Fallback match: 236883 km on 19,May25\n",
            "üìë Found worksheet 528 in Odometer_SVP\n",
            "üîÑ Bus 528: Fallback match: 302399 km on 25,Apr25\n",
            "üìë Found worksheet 585 in Odometer_SVP\n",
            "üîÑ Bus 585: Fallback match: 362461 km on 21,May25\n",
            "üìë Found worksheet 476 in Odometer_SVP\n",
            "üîÑ Bus 476: Fallback match: 388548 km on 15,May25\n",
            "üìë Found worksheet 536 in Odometer_SVP\n",
            "üîÑ Bus 536: Fallback match: 328571 km on 13,May25\n",
            "üìë Found worksheet 603 in Odometer_SVP\n",
            "üîÑ Bus 603: Fallback match: 101060 km on 20,May25\n",
            "Progress: 60/83 buses processed (72.3%)\n",
            "üìë Found worksheet 547 in Odometer_SVP\n",
            "üîÑ Bus 547: Fallback match: 705606 km on 20,May25\n",
            "üìë Found worksheet 617 in Odometer_FG\n",
            "üîÑ Bus 617: Fallback match: 68670 km on 18,May25\n",
            "üìë Found worksheet 516 in Odometer_FG\n",
            "üîÑ Bus 516: Fallback match: 290707 km on 18,May25\n",
            "üìë Found worksheet 473 in Odometer_SVP\n",
            "üîÑ Bus 473: Fallback match: 335615 km on 31,Jan25\n",
            "üìë Found worksheet 504 in Odometer_SVP\n",
            "üîÑ Bus 504: Fallback match: 378532 km on 19,May25\n",
            "üìë Found worksheet 588 in Odometer_SVP\n",
            "üîÑ Bus 588: Fallback match: 289266 km on 21,May25\n",
            "üìë Found worksheet 538 in Odometer_SVP\n",
            "üîÑ Bus 538: Fallback match: 341993 km on 13,May25\n",
            "üìë Found worksheet 590 in Odometer_SVP\n",
            "üîÑ Bus 590: Fallback match: 434243 km on 01,May25\n",
            "üìë Found worksheet 999 in Odometer_BT\n",
            "üîÑ Bus 999: Fallback match: 345158 km on 29,Mar25\n",
            "üìë Found worksheet 515 in Odometer_SVP\n",
            "üîÑ Bus 515: Fallback match: 474742 km on 14,Feb25\n",
            "Progress: 70/83 buses processed (84.3%)\n",
            "üìë Found worksheet 514 in Odometer_SVP\n",
            "üîÑ Bus 514: Fallback match: 182345 km on 14,May25\n",
            "üìë Found worksheet 479 in Odometer_FG\n",
            "üîÑ Bus 479: Fallback match: 425966 km on 18,May25\n",
            "üìë Found worksheet 521 in Odometer_SVP\n",
            "üîÑ Bus 521: Fallback match: 307526 km on 13,May25\n",
            "üìë Found worksheet 472 in Odometer_SVP\n",
            "üîÑ Bus 472: Fallback match: 396134 km on 19,May25\n",
            "üìë Found worksheet 437 in Odometer_FG\n",
            "üîÑ Bus 437: Fallback match: 251769 km on 13,May25\n",
            "üìë Found worksheet 440 in Odometer_SVP\n",
            "üîÑ Bus 440: Fallback match: 259274 km on 23,Apr25\n",
            "üìë Found worksheet 442 in Odometer_SVP\n",
            "üîÑ Bus 442: Fallback match: 277083 km on 20,May25\n",
            "üìë Found worksheet 529 in Odometer_FG\n",
            "üîÑ Bus 529: Fallback match: 360760 km on 18,Feb25\n",
            "üìë Found worksheet 614 in Odometer_SVP\n",
            "üîÑ Bus 614: Fallback match: 63296 km on 19,May25\n",
            "üìë Found worksheet 990 in Odometer_RT\n",
            "üîÑ Bus 990: Fallback match: 278164 km on 03,Mar25\n",
            "Progress: 80/83 buses processed (96.4%)\n",
            "üìë Found worksheet 612 in Odometer_SVP\n",
            "üîÑ Bus 612: Fallback match: 62698 km on 20,May25\n",
            "üìë Found worksheet 980 in Odometer_MB\n",
            "üîÑ Bus 980: Fallback match: 361040 km on 05,Apr25\n",
            "üìë Found worksheet 486 in Odometer_SVP\n",
            "üîÑ Bus 486: Fallback match: 379760 km on 28,Mar25\n",
            "Progress: 83/83 buses processed (100.0%)\n",
            "‚úÖ Completed processing all 83 buses\n",
            "\n",
            "üìù Writing data to Report_EO1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-307866c0d17e>:447: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  Report_EO1_Worksheet.update(range_to_update, chunk)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Updated rows 2-84 in Report_EO1\n",
            "‚úÖ All 83 rows updated successfully in Report_EO1!\n",
            "üéâ Complete script execution finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code is for HSD balance"
      ],
      "metadata": {
        "id": "OMZvBtJbBZ5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here i will try to get the HSD balance on current date, If the date is Current date then Error in HSD, instead of G column it takes M column\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "import re\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import functools\n",
        "import concurrent.futures\n",
        "import threading\n",
        "\n",
        "# === PERFORMANCE OPTIMIZATION SETUP ===\n",
        "print(\"üöÄ Initializing performance optimizations...\")\n",
        "\n",
        "# Cache for worksheet data to reduce API calls\n",
        "data_cache = {}\n",
        "cache_lock = threading.Lock()\n",
        "\n",
        "# LRU Cache decorator for expensive operations\n",
        "def lru_cache_with_expiry(maxsize=128, typed=False, ttl=600):\n",
        "    \"\"\"LRU Cache with expiry time\"\"\"\n",
        "    def decorator(func):\n",
        "        cache_dict = {}\n",
        "        cache_times = {}\n",
        "        cache_lock = threading.Lock()\n",
        "\n",
        "        @functools.wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            key = str(args) + str(kwargs)\n",
        "            current_time = time.time()\n",
        "\n",
        "            with cache_lock:\n",
        "                # Check if key exists and not expired\n",
        "                if key in cache_dict and current_time - cache_times[key] < ttl:\n",
        "                    return cache_dict[key]\n",
        "\n",
        "                # Call the function and cache result\n",
        "                result = func(*args, **kwargs)\n",
        "                cache_dict[key] = result\n",
        "                cache_times[key] = current_time\n",
        "\n",
        "                # Remove oldest entries if cache is too large\n",
        "                if len(cache_dict) > maxsize:\n",
        "                    oldest_key = min(cache_times, key=cache_times.get)\n",
        "                    cache_dict.pop(oldest_key)\n",
        "                    cache_times.pop(oldest_key)\n",
        "\n",
        "                return result\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# Batch processing helper functions\n",
        "def chunk_list(lst, chunk_size):\n",
        "    \"\"\"Split list into chunks of specified size\"\"\"\n",
        "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
        "\n",
        "# Cached function to get worksheet data\n",
        "@lru_cache_with_expiry(maxsize=100, ttl=300)  # Cache for 5 minutes\n",
        "def get_worksheet_data(spreadsheet_name, worksheet_name):\n",
        "    \"\"\"Get worksheet data with caching\"\"\"\n",
        "    cache_key = f\"{spreadsheet_name}:{worksheet_name}\"\n",
        "\n",
        "    with cache_lock:\n",
        "        if cache_key in data_cache:\n",
        "            print(f\"üìã Cache hit for {cache_key}\")\n",
        "            return data_cache[cache_key]\n",
        "\n",
        "    # Function to find the actual worksheet object\n",
        "    def find_worksheet(spreadsheet_list, worksheet_name, spreadsheet_names):\n",
        "        for idx, spreadsheet in enumerate(spreadsheet_list):\n",
        "            try:\n",
        "                sheet = spreadsheet.worksheet(worksheet_name)\n",
        "                print(f\"üìë Found worksheet {worksheet_name} in {spreadsheet_names[idx]}\")\n",
        "                return sheet, spreadsheet_names[idx]\n",
        "            except Exception:\n",
        "                continue\n",
        "        return None, None\n",
        "\n",
        "    # Cache miss, need to retrieve data\n",
        "    try:\n",
        "        sheet, source = find_worksheet(odometer_spreadsheets, worksheet_name, spreadsheet_names)\n",
        "        if sheet:\n",
        "            data = sheet.get_all_values()\n",
        "\n",
        "            with cache_lock:\n",
        "                data_cache[cache_key] = (data, source)\n",
        "\n",
        "            return data, source\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error retrieving data for {worksheet_name}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# === STEP 1: CLEAR DATA HSD from AF Coloumn\n",
        "print(\"\\nüßπ STEP 1: Clearing data...\")\n",
        "\n",
        "\n",
        "clear_range_HSD_Report_EO1_Worksheet = ['AF2:AF200', 'AG2:AG200']\n",
        "\n",
        "Report_EO1_Worksheet.batch_clear(clear_range_HSD_Report_EO1_Worksheet)\n",
        "\n",
        "\n",
        "# === STEP 5: SEARCH FOR HSD Balance VALUES ===\n",
        "print(\"\\nüîç STEP 5: Searching for HSD Balance values...\")\n",
        "\n",
        "\n",
        "# Get current date in expected format (e.g., \"05,May25\")\n",
        "current_date_str = datetime.now().strftime('%d,%b%y')\n",
        "\n",
        "# Get main data from Report_EO1\n",
        "main_data = Report_EO1_Worksheet.get_all_values()\n",
        "header, rows = main_data[0], main_data[1:]\n",
        "\n",
        "# Map each row to bus + date (using today's date)\n",
        "row_map = {}\n",
        "bus_set = set()\n",
        "for i, row in enumerate(rows, start=2):\n",
        "    try:\n",
        "        if len(row) > 1:  # Make sure row has at least 2 columns\n",
        "            bus = re.sub(r'[^a-zA-Z0-9]', '', str(row[1]).strip()).upper()  # Clean bus name\n",
        "            if bus:\n",
        "                row_map[i] = (bus, current_date_str)\n",
        "                bus_set.add(bus)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing row {i}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"üîé Total buses to process: {len(bus_set)}\")\n",
        "if bus_set:\n",
        "    print(\"Sample buses:\", list(bus_set)[:5])  # Log first 5 buses\n",
        "\n",
        "# Initialize lookup maps with thread safety\n",
        "bus_date_value_map = {}\n",
        "match_type_map = {}\n",
        "fallback_date_map = {}\n",
        "source_spreadsheet_map = {}\n",
        "map_lock = threading.Lock()\n",
        "\n",
        "# Function to find closest earlier date value\n",
        "def find_closest_date_value(sheet_data, target_date_str, value_column_index=6):\n",
        "    \"\"\"Find closest earlier date with a value in the specified column\"\"\"\n",
        "    if not sheet_data:\n",
        "        return None, \"\"\n",
        "\n",
        "    try:\n",
        "        target_date = datetime.strptime(target_date_str, '%d,%b%y')\n",
        "        valid_rows = []\n",
        "\n",
        "        for row in sheet_data[1:]:  # Skip header\n",
        "            if len(row) <= value_column_index:\n",
        "                continue\n",
        "\n",
        "            date_cell = row[1].strip() if len(row) > 1 else \"\"\n",
        "            value_cell = row[value_column_index].strip() if len(row) > value_column_index else \"\"\n",
        "\n",
        "            if not date_cell or not value_cell:\n",
        "                continue\n",
        "\n",
        "            # Try multiple date formats\n",
        "            parsed_date = None\n",
        "            for fmt in ['%d,%b%y', '%d-%b-%y', '%d/%b/%y']:\n",
        "                try:\n",
        "                    parsed_date = datetime.strptime(date_cell, fmt)\n",
        "                    break\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if parsed_date and parsed_date <= target_date and value_cell:\n",
        "                valid_rows.append((parsed_date, date_cell, value_cell))\n",
        "\n",
        "        if valid_rows:\n",
        "            valid_rows.sort(key=lambda x: x[0], reverse=True)  # Newest date first\n",
        "            best = valid_rows[0]\n",
        "            return best[2], best[1]  # value, fallback_date\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error in fallback for {target_date_str}: {e}\")\n",
        "\n",
        "    return None, \"\"\n",
        "\n",
        "\n",
        "# Process a single bus to find odometer value\n",
        "def process_bus_odometer(bus):\n",
        "    \"\"\"Process odometer data for a single bus\"\"\"\n",
        "    found = False\n",
        "\n",
        "    # Use the cached function to get worksheet data\n",
        "    data, source = get_worksheet_data(\"All\", bus)\n",
        "\n",
        "    if data:\n",
        "        found = True\n",
        "        # Check for exact date match\n",
        "        exact_match = False\n",
        "        for row in data[1:]:  # Skip header\n",
        "            # Corrected: Look at Column G (index 6) for HSD balance\n",
        "            if len(row) > 6 and row[1].strip() == current_date_str and row[6].strip():\n",
        "                hsd_val = row[6].strip() # Get value from Column G (index 6)\n",
        "                # No validation on value type is performed here\n",
        "                with map_lock:\n",
        "                    bus_date_value_map[(bus, current_date_str)] = hsd_val\n",
        "                    match_type_map[(bus, current_date_str)] = \"exact\"\n",
        "                    fallback_date_map[(bus, current_date_str)] = current_date_str  # Store current date\n",
        "                    source_spreadsheet_map[(bus, current_date_str)] = source\n",
        "                exact_match = True\n",
        "                print(f\"üìå Bus {bus}: Exact match: {hsd_val} on {current_date_str}\")\n",
        "                break\n",
        "\n",
        "        if not exact_match:\n",
        "            # Fallback to closest date, still using column 6 for HSD\n",
        "            val, fallback_date = find_closest_date_value(data, current_date_str, 6)\n",
        "            if val:\n",
        "                with map_lock:\n",
        "                    bus_date_value_map[(bus, current_date_str)] = val\n",
        "                    match_type_map[(bus, current_date_str)] = \"fallback\"\n",
        "                    fallback_date_map[(bus, current_date_str)] = fallback_date\n",
        "                    source_spreadsheet_map[(bus, current_date_str)] = source\n",
        "                print(f\"üîÑ Bus {bus}: Fallback match: {val} on {fallback_date}\")\n",
        "\n",
        "    if not found:\n",
        "        print(f\"üö® Bus {bus} not found in ANY spreadsheet!\")\n",
        "\n",
        "    return found\n",
        "\n",
        "\n",
        "# Process buses in parallel batches\n",
        "MAX_WORKERS = 5  # Adjust based on API limits\n",
        "BATCH_SIZE = 10  # Process this many buses at once\n",
        "\n",
        "def process_buses_in_batches(buses):\n",
        "    \"\"\"Process buses in parallel batches\"\"\"\n",
        "    total = len(buses)\n",
        "    completed = 0\n",
        "\n",
        "    bus_chunks = chunk_list(list(buses), BATCH_SIZE)\n",
        "\n",
        "    for chunk in bus_chunks:\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=min(MAX_WORKERS, len(chunk))) as executor:\n",
        "            futures = {executor.submit(process_bus_odometer, bus): bus for bus in chunk}\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                bus = futures[future]\n",
        "                try:\n",
        "                    result = future.result()\n",
        "                    completed += 1\n",
        "                    if completed % 10 == 0 or completed == total:\n",
        "                        print(f\"Progress: {completed}/{total} buses processed ({completed/total:.1%})\")\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Error processing bus {bus}: {e}\")\n",
        "\n",
        "        # Small delay between batches to avoid API rate limits\n",
        "        time.sleep(1)\n",
        "\n",
        "    print(f\"‚úÖ Completed processing all {total} buses\")\n",
        "\n",
        "# Process all buses in batches\n",
        "if bus_set:\n",
        "    process_buses_in_batches(bus_set)\n",
        "\n",
        "# Update Report_EO1 with logging\n",
        "print(\"\\nüìù Writing data to Report_EO1...\")\n",
        "updated_rows = []\n",
        "for row_idx, (bus, date_str) in row_map.items():\n",
        "    key = (bus, date_str)\n",
        "    val = bus_date_value_map.get(key, \"\")\n",
        "    fallback = fallback_date_map.get(key, \"\")\n",
        "    match_type = match_type_map.get(key, \"\")\n",
        "    source = source_spreadsheet_map.get(key, \"\")\n",
        "\n",
        "    # Improved logic for Column C (date) and Column D (value)\n",
        "    if match_type == \"exact\":\n",
        "        # For exact matches, use the current date (date_str)\n",
        "        col_c = date_str\n",
        "        col_d = val if val else \"\"\n",
        "    elif match_type == \"fallback\":\n",
        "        # For fallback matches, use the fallback date we found\n",
        "        col_c = fallback if fallback else \"\"\n",
        "        col_d = val if val else \"\"\n",
        "    else:\n",
        "        # No match found\n",
        "        col_c = \"\"\n",
        "        col_d = \"\"\n",
        "\n",
        "    # Add to batch update\n",
        "    updated_rows.append([col_c, col_d])\n",
        "\n",
        "# Prepare batch update\n",
        "if updated_rows:\n",
        "    # Split into manageable chunks\n",
        "    MAX_ROWS_PER_UPDATE = 1000  # Adjust based on API limits\n",
        "    row_chunks = chunk_list(updated_rows, MAX_ROWS_PER_UPDATE)\n",
        "\n",
        "    for i, chunk in enumerate(row_chunks):\n",
        "        start_row = 2 + i * MAX_ROWS_PER_UPDATE\n",
        "        end_row = start_row + len(chunk) - 1\n",
        "        range_to_update = f\"AF{start_row}:AG{end_row}\"\n",
        "\n",
        "        Report_EO1_Worksheet.update(range_to_update, chunk)\n",
        "        print(f\"‚úÖ Updated rows {start_row}-{end_row} in Report_EO1\")\n",
        "\n",
        "        # Small delay between batch updates\n",
        "        if i < len(row_chunks) - 1:\n",
        "            time.sleep(1)\n",
        "\n",
        "    print(f\"‚úÖ All {len(updated_rows)} rows updated successfully in Report_EO1!\")\n",
        "else:\n",
        "    print(\"‚ùå No updates made to Report_EO1.\")\n",
        "\n",
        "print(\"üéâ Complete script execution finished successfully!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7H4g7iF1fZDE",
        "outputId": "bbe92cc4-53b9-4f62-df3f-1efebad5db40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Initializing performance optimizations...\n",
            "\n",
            "üßπ STEP 1: Clearing data...\n",
            "\n",
            "üîç STEP 5: Searching for HSD Balance values...\n",
            "üîé Total buses to process: 83\n",
            "Sample buses: ['474', '495', '572', '584', '546']\n",
            "üìë Found worksheet 474 in Odometer_SVP\n",
            "üîÑ Bus 474: Fallback match: 30 on 20,May25\n",
            "üìë Found worksheet 495 in Odometer_SVP\n",
            "üîÑ Bus 495: Fallback match: 42 on 16,May25\n",
            "üìë Found worksheet 572 in Odometer_FG\n",
            "üîÑ Bus 572: Fallback match: 26 on 18,May25\n",
            "üìë Found worksheet 584 in Odometer_SVP\n",
            "üîÑ Bus 584: Fallback match: 54 on 10,Aug24\n",
            "üìë Found worksheet 546 in Odometer_SVP\n",
            "üîÑ Bus 546: Fallback match: 221 on 20,May25\n",
            "üìë Found worksheet 593 in Odometer_FG\n",
            "üîÑ Bus 593: Fallback match: 45 on 18,May25\n",
            "üìë Found worksheet 457 in Odometer_SVP\n",
            "üîÑ Bus 457: Fallback match: 35 on 20,May25\n",
            "üìë Found worksheet 550 in Odometer_SVP\n",
            "üîÑ Bus 550: Fallback match: 0 on 14,Oct24\n",
            "üìë Found worksheet 616 in Odometer_FG\n",
            "üîÑ Bus 616: Fallback match: 41 on 17,May25\n",
            "üìë Found worksheet 523 in Odometer_SVP\n",
            "üîÑ Bus 523: Fallback match: 38 on 23,Apr25\n",
            "Progress: 10/83 buses processed (12.0%)\n",
            "üìë Found worksheet 461 in Odometer_FG\n",
            "üîÑ Bus 461: Fallback match: 22 on 17,May25\n",
            "üìë Found worksheet 970 in Odometer_DP\n",
            "üîÑ Bus 970: Fallback match: 62 on 20,May25\n",
            "üìë Found worksheet 604 in Odometer_SVP\n",
            "üîÑ Bus 604: Fallback match: 80 on 20,May25\n",
            "üìë Found worksheet 574 in Odometer_SVP\n",
            "üîÑ Bus 574: Fallback match: 162 on 02,Dec24\n",
            "üìë Found worksheet 463 in Odometer_FG\n",
            "üìë Found worksheet 578 in Odometer_SVP\n",
            "üîÑ Bus 578: Fallback match: 56 on 19,May25\n",
            "üìë Found worksheet 507 in Odometer_FG\n",
            "üîÑ Bus 507: Fallback match: 30 on 18,May25\n",
            "üìë Found worksheet 613 in Odometer_SVP\n",
            "üîÑ Bus 613: Fallback match: 160 on 17,Mar25\n",
            "üìë Found worksheet 598 in Odometer_SVP\n",
            "üîÑ Bus 598: Fallback match: 75 on 19,May25\n",
            "üìë Found worksheet 577 in Odometer_SVP\n",
            "üîÑ Bus 577: Fallback match: 195 on 20,May25\n",
            "Progress: 20/83 buses processed (24.1%)\n",
            "üìë Found worksheet 615 in Odometer_FG\n",
            "üìë Found worksheet 535 in Odometer_SVP\n",
            "üîÑ Bus 535: Fallback match: 82 on 13,May25\n",
            "üìë Found worksheet 444 in Odometer_SVP\n",
            "üîÑ Bus 444: Fallback match: 78 on 20,May25\n",
            "üìë Found worksheet 475 in Odometer_SVP\n",
            "üîÑ Bus 475: Fallback match: 68 on 24,Dec24\n",
            "üìë Found worksheet 596 in Odometer_SVP\n",
            "üîÑ Bus 596: Fallback match: 138 on 20,May25\n",
            "üìë Found worksheet 575 in Odometer_SVP\n",
            "üîÑ Bus 575: Fallback match: 72 on 13,Nov24\n",
            "üìë Found worksheet 459 in Odometer_SVP\n",
            "üîÑ Bus 459: Fallback match: 53 on 20,May25\n",
            "üìë Found worksheet 548 in Odometer_SVP\n",
            "üîÑ Bus 548: Fallback match: 28 on 19,May25\n",
            "üìë Found worksheet 589 in Odometer_SVP\n",
            "üîÑ Bus 589: Fallback match: 112 on 04,Mar25\n",
            "üìë Found worksheet 530 in Odometer_SVP\n",
            "üîÑ Bus 530: Fallback match: 76 on 20,May25\n",
            "Progress: 30/83 buses processed (36.1%)\n",
            "üìë Found worksheet 489 in Odometer_SVP\n",
            "üìë Found worksheet 438 in Odometer_FG\n",
            "üîÑ Bus 438: Fallback match: 23 on 18,May25\n",
            "üìë Found worksheet 460 in Odometer_SVP\n",
            "üîÑ Bus 460: Fallback match: 45 on 06,Feb25\n",
            "üìë Found worksheet 518 in Odometer_SVP\n",
            "üìë Found worksheet 592 in Odometer_FG\n",
            "üîÑ Bus 592: Fallback match: 36 on 18,May25\n",
            "üìë Found worksheet 534 in Odometer_SVP\n",
            "üîÑ Bus 534: Fallback match: 50 on 20,May25\n",
            "üìë Found worksheet 508 in Odometer_SVP\n",
            "üîÑ Bus 508: Fallback match: 105 on 20,May25\n",
            "üìë Found worksheet 462 in Odometer_SVP\n",
            "üîÑ Bus 462: Fallback match: 63 on 20,May25\n",
            "üìë Found worksheet 560 in Odometer_FG\n",
            "üîÑ Bus 560: Fallback match: 29 on 18,May25\n",
            "üìë Found worksheet 511 in Odometer_SVP\n",
            "üîÑ Bus 511: Fallback match: 43 on 13,May25\n",
            "Progress: 40/83 buses processed (48.2%)\n",
            "üìë Found worksheet 562 in Odometer_FG\n",
            "üîÑ Bus 562: Fallback match: 37 on 18,May25\n",
            "üìë Found worksheet 471 in Odometer_SVP\n",
            "üîÑ Bus 471: Fallback match: 34 on 20,May25\n",
            "üìë Found worksheet 564 in Odometer_SVP\n",
            "üîÑ Bus 564: Fallback match: 43 on 16,May24\n",
            "üìë Found worksheet 493 in Odometer_FG\n",
            "üìë Found worksheet 597 in Odometer_SVP\n",
            "üîÑ Bus 597: Fallback match: 64 on 20,May25\n",
            "üìë Found worksheet 563 in Odometer_SVP\n",
            "üîÑ Bus 563: Fallback match: 60 on 20,May25\n",
            "üìë Found worksheet 441 in Odometer_SVP\n",
            "üîÑ Bus 441: Fallback match: 21 on 03,Mar25\n",
            "üìë Found worksheet 478 in Odometer_FG\n",
            "üîÑ Bus 478: Fallback match: 20 on 17,May25\n",
            "üìë Found worksheet 605 in Odometer_SVP\n",
            "üîÑ Bus 605: Fallback match: 114 on 20,May25\n",
            "üìë Found worksheet 599 in Odometer_SVP\n",
            "üîÑ Bus 599: Fallback match: 191 on 20,May25\n",
            "Progress: 50/83 buses processed (60.2%)\n",
            "üìë Found worksheet 595 in Odometer_SVP\n",
            "üîÑ Bus 595: Fallback match: 84 on 17,May25\n",
            "üìë Found worksheet 573 in Odometer_FG\n",
            "üîÑ Bus 573: Fallback match: 35 on 18,May25\n",
            "üìë Found worksheet 587 in Odometer_SVP\n",
            "üîÑ Bus 587: Fallback match: 53 on 19,May25\n",
            "üìë Found worksheet 561 in Odometer_FG\n",
            "üîÑ Bus 561: Fallback match: 93 on 18,May25\n",
            "üìë Found worksheet 469 in Odometer_SVP\n",
            "üîÑ Bus 469: Fallback match: 57 on 19,May25\n",
            "üìë Found worksheet 528 in Odometer_SVP\n",
            "üîÑ Bus 528: Fallback match: 57 on 25,Apr25\n",
            "üìë Found worksheet 585 in Odometer_SVP\n",
            "üîÑ Bus 585: Fallback match: 82 on 21,May25\n",
            "üìë Found worksheet 476 in Odometer_SVP\n",
            "üîÑ Bus 476: Fallback match: 87 on 15,May25\n",
            "üìë Found worksheet 536 in Odometer_SVP\n",
            "üîÑ Bus 536: Fallback match: 56 on 13,May25\n",
            "üìë Found worksheet 603 in Odometer_SVP\n",
            "üîÑ Bus 603: Fallback match: 228 on 20,May25\n",
            "Progress: 60/83 buses processed (72.3%)\n",
            "üìë Found worksheet 547 in Odometer_SVP\n",
            "üîÑ Bus 547: Fallback match: 88 on 20,May25\n",
            "üìë Found worksheet 617 in Odometer_FG\n",
            "üîÑ Bus 617: Fallback match: 28 on 18,May25\n",
            "üìë Found worksheet 516 in Odometer_FG\n",
            "üîÑ Bus 516: Fallback match: 25 on 18,May25\n",
            "üìë Found worksheet 473 in Odometer_SVP\n",
            "üîÑ Bus 473: Fallback match: 92 on 31,Jan25\n",
            "üìë Found worksheet 504 in Odometer_SVP\n",
            "üîÑ Bus 504: Fallback match: 72 on 19,May25\n",
            "üìë Found worksheet 588 in Odometer_SVP\n",
            "üîÑ Bus 588: Fallback match: 154 on 21,May25\n",
            "üìë Found worksheet 538 in Odometer_SVP\n",
            "üîÑ Bus 538: Fallback match: 71 on 13,May25\n",
            "üìë Found worksheet 590 in Odometer_SVP\n",
            "üîÑ Bus 590: Fallback match: 69 on 01,May25\n",
            "üìë Found worksheet 999 in Odometer_BT\n",
            "üîÑ Bus 999: Fallback match: 87 on 29,Mar25\n",
            "üìë Found worksheet 515 in Odometer_SVP\n",
            "üîÑ Bus 515: Fallback match: 67 on 14,Feb25\n",
            "Progress: 70/83 buses processed (84.3%)\n",
            "üìë Found worksheet 514 in Odometer_SVP\n",
            "üîÑ Bus 514: Fallback match: 77 on 14,May25\n",
            "üìë Found worksheet 479 in Odometer_FG\n",
            "üîÑ Bus 479: Fallback match: 29 on 18,May25\n",
            "üìë Found worksheet 521 in Odometer_SVP\n",
            "üîÑ Bus 521: Fallback match: 75 on 13,May25\n",
            "üìë Found worksheet 472 in Odometer_SVP\n",
            "üîÑ Bus 472: Fallback match: 92 on 19,May25\n",
            "üìë Found worksheet 437 in Odometer_FG\n",
            "üìë Found worksheet 440 in Odometer_SVP\n",
            "üîÑ Bus 440: Fallback match: 28 on 23,Apr25\n",
            "üìë Found worksheet 442 in Odometer_SVP\n",
            "üîÑ Bus 442: Fallback match: 64 on 20,May25\n",
            "üìë Found worksheet 529 in Odometer_FG\n",
            "üìë Found worksheet 614 in Odometer_SVP\n",
            "üîÑ Bus 614: Fallback match: 138 on 19,May25\n",
            "üìë Found worksheet 990 in Odometer_RT\n",
            "üîÑ Bus 990: Fallback match: 21 on 03,Mar25\n",
            "Progress: 80/83 buses processed (96.4%)\n",
            "üìë Found worksheet 612 in Odometer_SVP\n",
            "üîÑ Bus 612: Fallback match: 212 on 20,May25\n",
            "üìë Found worksheet 980 in Odometer_MB\n",
            "üîÑ Bus 980: Fallback match: 42 on 05,Apr25\n",
            "üìë Found worksheet 486 in Odometer_SVP\n",
            "üîÑ Bus 486: Fallback match: 36 on 28,Mar25\n",
            "Progress: 83/83 buses processed (100.0%)\n",
            "‚úÖ Completed processing all 83 buses\n",
            "\n",
            "üìù Writing data to Report_EO1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-0097cc5dcb85>:296: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  Report_EO1_Worksheet.update(range_to_update, chunk)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Updated rows 2-84 in Report_EO1\n",
            "‚úÖ All 83 rows updated successfully in Report_EO1!\n",
            "üéâ Complete script execution finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code gone back to old working offroad, need to analyse the code and actual offroad"
      ],
      "metadata": {
        "id": "bsrVjeqmB0hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Off road retain this\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "import time\n",
        "from collections import defaultdict\n",
        "import concurrent.futures\n",
        "import threading\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "DATE_FORMATS = ['%d,%b%y', '%d-%b-%y', '%d/%b/%y', '%d,%b %y', '%d %b %y']\n",
        "MAX_WORKERS = 5\n",
        "BATCH_SIZE = 10\n",
        "MAX_CELL_CHARS = 50000\n",
        "MAX_DATES_PER_CELL = 365\n",
        "\n",
        "# === CORE FUNCTIONS ===\n",
        "def parse_date(date_str):\n",
        "    \"\"\"Parse date from multiple possible formats\"\"\"\n",
        "    date_str = date_str.strip().replace(' ', '')\n",
        "    for fmt in DATE_FORMATS:\n",
        "        try:\n",
        "            return datetime.strptime(date_str, fmt).date()\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "def format_date_list(dates):\n",
        "    \"\"\"Format dates as DD,MonYY with length check\"\"\"\n",
        "    date_str = \";\".join(d.strftime('%d,%b%y') for d in sorted(dates))\n",
        "    if len(date_str) > MAX_CELL_CHARS:\n",
        "        print(f\"‚ö†Ô∏è Truncating long date list ({len(date_str)} chars)\")\n",
        "        date_str = date_str[:MAX_CELL_CHARS]\n",
        "        last_semicolon = date_str.rfind(';')\n",
        "        if last_semicolon > 0:\n",
        "            date_str = date_str[:last_semicolon]\n",
        "    return date_str\n",
        "\n",
        "def get_bus_odometer_data(bus):\n",
        "    \"\"\"Retrieve and clean odometer data with operational days info\"\"\"\n",
        "    try:\n",
        "        for spreadsheet in odometer_spreadsheets:\n",
        "            try:\n",
        "                sheet = spreadsheet.worksheet(bus)\n",
        "                data = sheet.get_all_values()\n",
        "                if data and len(data) > 1:\n",
        "                    clean_data = []\n",
        "                    for row in data[1:]:\n",
        "                        if len(row) >= 13:\n",
        "                            date_str = row[1].strip()  # Column B (date)\n",
        "                            odo_str = row[12].strip()  # Column M (odometer)\n",
        "                            op_days_str = row[2].strip() if len(row) > 2 else '1'  # Column C (operational days)\n",
        "\n",
        "                            # Default to 1 if blank or invalid\n",
        "                            try:\n",
        "                                op_days = int(op_days_str) if op_days_str and op_days_str.isdigit() else 1\n",
        "                            except:\n",
        "                                op_days = 1\n",
        "\n",
        "                            odo_str = ''.join(c for c in odo_str if c.isdigit())\n",
        "                            if date_str and odo_str and odo_str.isdigit():\n",
        "                                date = parse_date(date_str)\n",
        "                                if date:\n",
        "                                    clean_data.append((date, int(odo_str), op_days))\n",
        "                    return clean_data\n",
        "            except:\n",
        "                continue\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error getting data for {bus}: {e}\")\n",
        "        return []\n",
        "\n",
        "def calculate_non_operating_days(bus_data, current_date):\n",
        "    \"\"\"Calculate non-operating days with new Column C condition\"\"\"\n",
        "    current_date = current_date.date()\n",
        "\n",
        "    # Define the three time periods (exclusive of current date)\n",
        "    periods = {\n",
        "        'week': {'start': current_date - timedelta(days=7), 'end': current_date - timedelta(days=1)},\n",
        "        'month': {'start': current_date - timedelta(days=30), 'end': current_date - timedelta(days=1)},\n",
        "        'year': {'start': current_date - timedelta(days=365), 'end': current_date - timedelta(days=1)}\n",
        "    }\n",
        "\n",
        "    results = {p: {'count': 0, 'dates': set()} for p in periods}\n",
        "\n",
        "    if not bus_data or len(bus_data) < 2:\n",
        "        return results, periods\n",
        "\n",
        "    # Sort data by date\n",
        "    bus_data.sort()\n",
        "\n",
        "    # Process operational days information\n",
        "    operational_dates = set()\n",
        "    for i in range(len(bus_data)):\n",
        "        date, odo, op_days = bus_data[i]\n",
        "        operational_dates.add(date)\n",
        "\n",
        "        # If operational days > 1, mark subsequent days as operational\n",
        "        if op_days > 1:\n",
        "            for day in range(1, op_days):\n",
        "                operational_date = date + timedelta(days=day)\n",
        "                operational_dates.add(operational_date)\n",
        "\n",
        "    # Get date range from first date to yesterday\n",
        "    first_date = bus_data[0][0]\n",
        "    last_date_to_check = current_date - timedelta(days=1)\n",
        "    all_dates = [first_date + timedelta(days=x)\n",
        "                for x in range((last_date_to_check - first_date).days + 1)]\n",
        "\n",
        "    # Classify each date\n",
        "    for date in all_dates:\n",
        "        # If date is not in operational dates, it's non-operating\n",
        "        if date not in operational_dates:\n",
        "            # Add to appropriate periods\n",
        "            for period, range_info in periods.items():\n",
        "                if range_info['start'] <= date <= range_info['end']:\n",
        "                    results[period]['dates'].add(date)\n",
        "\n",
        "    # Finalize results\n",
        "    for period in results:\n",
        "        # Filter dates within the period range\n",
        "        period_dates = [d for d in results[period]['dates']\n",
        "                      if periods[period]['start'] <= d <= periods[period]['end']]\n",
        "        results[period]['dates'] = sorted(period_dates)\n",
        "        results[period]['count'] = len(period_dates)\n",
        "\n",
        "    return results, periods\n",
        "\n",
        "# === MAIN EXECUTION ===\n",
        "def main():\n",
        "    # Define current_date at the start of main\n",
        "    current_date = datetime.now()\n",
        "\n",
        "    print(\"\\nüßπ STEP 1: Clearing existing data...\")\n",
        "    Report_EO1_Worksheet.batch_clear(['AH2:AM200'])\n",
        "    print(\"‚úÖ Cleared columns AH-AM\")\n",
        "\n",
        "    print(\"\\nüìÖ STEP 2: Loading bus list...\")\n",
        "    main_data = Report_EO1_Worksheet.get_all_values()\n",
        "    row_map = {}\n",
        "    for i, row in enumerate(main_data[1:], start=2):\n",
        "        try:\n",
        "            bus = re.sub(r'[^a-zA-Z0-9]', '', str(row[1]).strip()).upper()\n",
        "            if bus:\n",
        "                row_map[i] = bus\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error processing row {i}: {e}\")\n",
        "\n",
        "    print(f\"üîç Found {len(row_map)} buses to process\")\n",
        "\n",
        "    print(\"\\nüöå STEP 3: Calculating non-operating days...\")\n",
        "    non_op_days_map = defaultdict(dict)\n",
        "    lock = threading.Lock()\n",
        "\n",
        "    def process_bus(bus, row_idx):\n",
        "        try:\n",
        "            bus_data = get_bus_odometer_data(bus)\n",
        "            if not bus_data:\n",
        "                print(f\"‚ö†Ô∏è No data for {bus}\")\n",
        "                return\n",
        "\n",
        "            results, periods = calculate_non_operating_days(bus_data, current_date)\n",
        "\n",
        "            with lock:\n",
        "                non_op_days_map[row_idx] = {\n",
        "                    'bus': bus,\n",
        "                    'week': results['week'],\n",
        "                    'month': results['month'],\n",
        "                    'year': results['year'],\n",
        "                    'periods': periods\n",
        "                }\n",
        "\n",
        "            print(f\"‚úÖ {bus}: Week={results['week']['count']}, Month={results['month']['count']}, Year={results['year']['count']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to process {bus}: {e}\")\n",
        "\n",
        "    # Process in parallel batches\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        futures = []\n",
        "        for row_idx, bus in row_map.items():\n",
        "            futures.append(executor.submit(process_bus, bus, row_idx))\n",
        "            if len(futures) >= BATCH_SIZE:\n",
        "                concurrent.futures.wait(futures)\n",
        "                futures = []\n",
        "                time.sleep(1)\n",
        "\n",
        "        if futures:\n",
        "            concurrent.futures.wait(futures)\n",
        "\n",
        "    print(\"\\nüìù STEP 4: Updating worksheet with results...\")\n",
        "    update_data = []\n",
        "    for row_idx, bus in row_map.items():\n",
        "        results = non_op_days_map.get(row_idx, {\n",
        "            'week': {'count': 0, 'dates': []},\n",
        "            'month': {'count': 0, 'dates': []},\n",
        "            'year': {'count': 0, 'dates': []}\n",
        "        })\n",
        "\n",
        "        update_data.append([\n",
        "            results['week']['count'],\n",
        "            results['month']['count'],\n",
        "            results['year']['count'],\n",
        "            format_date_list(results['week']['dates']),\n",
        "            format_date_list(results['month']['dates']),\n",
        "            format_date_list(results['year']['dates'])\n",
        "        ])\n",
        "\n",
        "    # Batch update with error handling\n",
        "    for i in range(0, len(update_data), 50):\n",
        "        batch = update_data[i:i+50]\n",
        "        range_start = i + 2\n",
        "        range_end = range_start + len(batch) - 1\n",
        "\n",
        "        try:\n",
        "            Report_EO1_Worksheet.update(\n",
        "                values=batch,\n",
        "                range_name=f'AH{range_start}:AM{range_end}'\n",
        "            )\n",
        "            print(f\"‚úÖ Updated rows {range_start}-{range_end}\")\n",
        "            time.sleep(1)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to update rows {range_start}-{range_end}: {e}\")\n",
        "            # Fallback to updating just counts\n",
        "            try:\n",
        "                simple_batch = [[row[0], row[1], row[2]] for row in batch]\n",
        "                Report_EO1_Worksheet.update(\n",
        "                    values=simple_batch,\n",
        "                    range_name=f'AH{range_start}:AJ{range_end}'\n",
        "                )\n",
        "                print(f\"‚úÖ Updated counts only for rows {range_start}-{range_end}\")\n",
        "            except Exception as e2:\n",
        "                print(f\"‚ùå Completely failed to update rows {range_start}-{range_end}: {e2}\")\n",
        "\n",
        "    # Update headers with period information\n",
        "    if non_op_days_map:\n",
        "        first_bus_data = next(iter(non_op_days_map.values()))\n",
        "        periods = first_bus_data['periods']\n",
        "\n",
        "        week_start = periods[\"week\"][\"start\"].strftime(\"%d.%b%y\")\n",
        "        week_end = periods[\"week\"][\"end\"].strftime(\"%d.%b%y\")\n",
        "        month_start = periods[\"month\"][\"start\"].strftime(\"%d.%b%y\")\n",
        "        month_end = periods[\"month\"][\"end\"].strftime(\"%d.%b%y\")\n",
        "        year_start = periods[\"year\"][\"start\"].strftime(\"%d.%b%y\")\n",
        "        year_end = periods[\"year\"][\"end\"].strftime(\"%d.%b%y\")\n",
        "\n",
        "        header_updates = [\n",
        "            {'range': 'AH1', 'values': [[f'Offroad Days in Week\\n({week_start} to {week_end})']]},\n",
        "            {'range': 'AI1', 'values': [[f'Offroad Days in Month\\n({month_start} to {month_end})']]},\n",
        "            {'range': 'AJ1', 'values': [[f'Offroad Days in Year\\n({year_start} to {year_end})']]},\n",
        "            {'range': 'AK1', 'values': [['Week Offroad Dates']]},\n",
        "            {'range': 'AL1', 'values': [['Month Offroad Dates']]},\n",
        "            {'range': 'AM1', 'values': [['Year Offroad Dates']]}\n",
        "        ]\n",
        "\n",
        "        Report_EO1_Worksheet.batch_update(header_updates)\n",
        "        print(\"‚úÖ Updated header information with date ranges\")\n",
        "\n",
        "    print(\"\\nüéâ Done! Non-operating days calculation complete.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "IZYWAjQqAnp_",
        "outputId": "9998924c-952d-4f10-cd22-7cb8f926913c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üßπ STEP 1: Clearing existing data...\n",
            "‚úÖ Cleared columns AH-AM\n",
            "\n",
            "üìÖ STEP 2: Loading bus list...\n",
            "üîç Found 83 buses to process\n",
            "\n",
            "üöå STEP 3: Calculating non-operating days...\n",
            "‚úÖ 457: Week=2, Month=13, Year=208\n",
            "‚úÖ 441: Week=7, Month=30, Year=262\n",
            "‚úÖ 444: Week=2, Month=8, Year=249\n",
            "‚úÖ 440: Week=7, Month=28, Year=189\n",
            "‚úÖ 442: Week=5, Month=15, Year=243\n",
            "‚úÖ 469: Week=6, Month=25, Year=228\n",
            "‚úÖ 460: Week=7, Month=30, Year=198\n",
            "‚úÖ 462: Week=3, Month=25, Year=173\n",
            "‚úÖ 459: Week=5, Month=9, Year=290\n",
            "‚úÖ 471: Week=2, Month=9, Year=224\n",
            "‚úÖ 474: Week=4, Month=17, Year=253\n",
            "‚úÖ 473: Week=7, Month=30, Year=302\n",
            "‚úÖ 476: Week=6, Month=13, Year=168\n",
            "‚úÖ 475: Week=7, Month=30, Year=286\n",
            "‚úÖ 472: Week=3, Month=11, Year=149\n",
            "‚úÖ 489: Week=0, Month=0, Year=0\n",
            "‚úÖ 486: Week=7, Month=30, Year=291\n",
            "‚úÖ 504: Week=6, Month=18, Year=316\n",
            "‚úÖ 495: Week=5, Month=8, Year=122\n",
            "‚úÖ 508: Week=2, Month=12, Year=194\n",
            "‚úÖ 514: Week=7, Month=12, Year=214\n",
            "‚úÖ 518: Week=0, Month=0, Year=0\n",
            "‚úÖ 515: Week=7, Month=30, Year=186\n",
            "‚úÖ 511: Week=7, Month=21, Year=163\n",
            "‚úÖ 521: Week=7, Month=17, Year=214\n",
            "‚úÖ 523: Week=7, Month=29, Year=257\n",
            "‚úÖ 528: Week=7, Month=27, Year=245\n",
            "‚úÖ 534: Week=1, Month=5, Year=140\n",
            "‚úÖ 530: Week=6, Month=20, Year=278\n",
            "‚úÖ 535: Week=7, Month=12, Year=96\n",
            "‚úÖ 538: Week=7, Month=11, Year=162\n",
            "‚úÖ 547: Week=5, Month=17, Year=266\n",
            "‚úÖ 548: Week=5, Month=15, Year=205\n",
            "‚úÖ 546: Week=3, Month=15, Year=194\n",
            "‚úÖ 536: Week=7, Month=15, Year=126\n",
            "‚úÖ 550: Week=7, Month=30, Year=289\n",
            "‚úÖ 564: Week=7, Month=30, Year=365\n",
            "‚úÖ 575: Week=7, Month=30, Year=297\n",
            "‚úÖ 574: Week=7, Month=30, Year=277\n",
            "‚úÖ 563: Week=3, Month=15, Year=210\n",
            "‚úÖ 584: Week=7, Month=30, Year=354\n",
            "‚úÖ 577: Week=1, Month=9, Year=162\n",
            "‚úÖ 587: Week=4, Month=14, Year=181\n",
            "‚úÖ 578: Week=4, Month=15, Year=206\n",
            "‚úÖ 585: Week=1, Month=2, Year=70\n",
            "‚úÖ 588: Week=2, Month=3, Year=109\n",
            "‚úÖ 589: Week=7, Month=30, Year=256\n",
            "‚úÖ 590: Week=7, Month=26, Year=214\n",
            "‚úÖ 596: Week=5, Month=17, Year=181\n",
            "‚úÖ 595: Week=5, Month=16, Year=192\n",
            "‚úÖ 599: Week=4, Month=13, Year=192\n",
            "‚úÖ 598: Week=4, Month=12, Year=154\n",
            "‚úÖ 597: Week=5, Month=18, Year=163\n",
            "‚úÖ 603: Week=3, Month=12, Year=163\n",
            "‚úÖ 604: Week=3, Month=16, Year=196\n",
            "‚úÖ 613: Week=7, Month=30, Year=100\n",
            "‚úÖ 612: Week=2, Month=6, Year=107\n",
            "‚úÖ 605: Week=5, Month=13, Year=169\n",
            "‚úÖ 614: Week=2, Month=3, Year=124\n",
            "‚úÖ 437: Week=7, Month=11, Year=177\n",
            "‚úÖ 478: Week=4, Month=7, Year=103\n",
            "‚úÖ 461: Week=4, Month=11, Year=100\n",
            "‚úÖ 479: Week=3, Month=3, Year=34\n",
            "‚úÖ 463: Week=6, Month=26, Year=361\n",
            "‚úÖ 438: Week=3, Month=3, Year=77\n",
            "‚úÖ 493: Week=7, Month=21, Year=221\n",
            "‚úÖ 516: Week=3, Month=4, Year=76\n",
            "‚úÖ 507: Week=3, Month=3, Year=69\n",
            "‚úÖ 529: Week=7, Month=30, Year=139\n",
            "‚úÖ 560: Week=3, Month=3, Year=94\n",
            "‚úÖ 573: Week=3, Month=3, Year=33\n",
            "‚úÖ 572: Week=3, Month=3, Year=5\n",
            "‚úÖ 561: Week=3, Month=3, Year=56\n",
            "‚úÖ 592: Week=3, Month=3, Year=3\n",
            "‚úÖ 562: Week=3, Month=7, Year=184\n",
            "‚úÖ 593: Week=3, Month=4, Year=39\n",
            "‚úÖ 615: Week=7, Month=27, Year=61\n",
            "‚úÖ 617: Week=3, Month=4, Year=41\n",
            "‚úÖ 616: Week=4, Month=5, Year=12\n",
            "‚úÖ 999: Week=7, Month=30, Year=129\n",
            "‚úÖ 990: Week=7, Month=30, Year=265\n",
            "‚úÖ 980: Week=7, Month=30, Year=174\n",
            "‚úÖ 970: Week=6, Month=29, Year=201\n",
            "\n",
            "üìù STEP 4: Updating worksheet with results...\n",
            "‚úÖ Updated rows 2-51\n",
            "‚úÖ Updated rows 52-84\n",
            "‚úÖ Updated header information with date ranges\n",
            "\n",
            "üéâ Done! Non-operating days calculation complete.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOh+BEYJZ0XrVdoH2YL5SP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}